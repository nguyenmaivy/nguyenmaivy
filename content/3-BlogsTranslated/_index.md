---
title: "Translated Blogs"

weight: 3
chapter: false
pre: " <b> 3. </b> "
---

###  [Blog 1 - Backup Amazon Elastic Kubernetes Service (EKS) resources using NetApp Trident Protect](3.1-Blog1/)
This blog post introduces the NetApp Trident Protect tool, a free solution designed for data protection, disaster recovery, and the migration of containerized workloads in the Amazon EKS environment. The article explains why EKS clusters require robust backup mechanisms to guard against human error, system failures, and region failures—risks that Kubernetes does not inherently protect against—including the backup of critical components like namespaces, Persistent Volumes, and configuration resources. Trident Protect allows users to perform on-demand or scheduled backups of Kubernetes resources to external storage backends such as Amazon S3, leveraging Kubernetes' native API and the tridentctl-protect CLI. Finally, the article provides a step-by-step guide for deploying a sample environment using Terraform, integrating Trident Protect with Amazon FSx for NetApp ONTAP to execute practical data protection and migration tasks.

###  [Blog 2 - AI-Driven Development Life Cycle: Reimagining Software Engineering](3.2-Blog2/)
This blog post introduces AI-Driven Development Life Cycle (AI-DLC), a new methodology proposed by AWS that reshapes software engineering by placing Artificial Intelligence (AI) at the center of the entire development lifecycle. AI-DLC is designed to address the limitations of current approaches (AI-assisted and AI-autonomous) by combining AI Execution with Human Supervision and Dynamic Team Collaboration. Accordingly, AI creates detailed work plans, seeks clarification, and executes solutions only after receiving human validation. The development process is divided into three phases: Inception (AI converts business intent into requirements), Construction (AI recommends architecture, models, code, and tests), and Operations (AI manages Infrastructure as Code and deployment). AI-DLC also replaces traditional “sprints” with “bolts”—shorter, more intense work cycles measured in hours or days. The core benefits of this approach are increased development velocity, innovation, quality, and improved developer experience, helping teams focus on problem solving instead of repetitive tasks.

###  [Blog 3 - Overcome development disarray with Amazon Q Developer CLI custom agents](3.3-Blog3/)
This blog introduces new Custom Agents in the Amazon Q Developer CLI, a feature designed to help developers efficiently manage the complexity and clutter of diverse development environments, especially in multi-tier applications. The core problem is that traditional AI assistants often have to guess context when using multiple tools (e.g., confusing a "table" in Figma with a "table" in PostgreSQL). Custom Agents allow developers to create specialized, optimized agents configured with specific tools, contexts, and permissions for each task (e.g., a separate Agent for the front-end and one for the back-end). By easily switching between Agents using the q chat --agent [name] command, this feature reduces cognitive overhead, ensuring Amazon Q Developer provides more accurate and relevant answers, increasing productivity and quality of work.


###  [Blog 4 - How Zapier runs isolated tasks on AWS Lambda and upgrades functions at scale](3.4-Blog4/)
This blog explains how Zapier operates hundreds of thousands of isolated AWS Lambda functions to power user-created Zaps, ensuring strict tenant isolation, high scalability, and minimal operational overhead. By leveraging AWS Lambda’s Firecracker-based microVMs and an Amazon EKS–powered control plane, Zapier creates and manages functions dynamically for each Zap. A major challenge discussed is upgrading Lambda runtimes at scale as older runtimes reach end of life, requiring strong security compliance without disrupting customer experience. Zapier addressed this through a three-phase approach: cleaning unused functions with CloudWatch and Trusted Advisor, prioritizing critical and high-traffic functions for upgrades, and empowering engineering teams with Terraform modules and a custom Lambda runtime canary tool. This automated framework safely shifts traffic to upgraded versions, monitors errors, performs rollbacks if needed, and ultimately reduced outdated Lambda usage by 95%, ensuring secure, resilient, and continuously up-to-date serverless infrastructure.

###  [Blog 5 - How HashiCorp made cross-Region switchover seamless with Amazon Application Recovery Controller](3.5-Blog5/)
This blog describes how HashiCorp transformed its disaster recovery process by adopting Amazon Application Recovery Controller (ARC) to enable fast, reliable, cross-Region failover for its cloud platform. Previously dependent on complex, error-prone manual procedures, HashiCorp’s SRE team centralized the failover workflow using a custom orchestration service integrated with ARC’s globally available control plane. By redesigning DNS routing with Route 53 health checks, automating regional context signaling, and establishing rigorous disaster-recovery testing, HashiCorp now achieves seamless, consistent failover within minutes. ARC’s automation and resilience significantly improved recovery time, reduced operational risk, and strengthened the enterprise-grade reliability of HashiCorp Cloud Platform. 

###  [Blog 6 - Implementing message prioritization with quorum queues on Amazon MQ for RabbitMQ](3.6-Blog6/)
This blog explains how to implement message prioritization when migrating from classic RabbitMQ queues—which have built-in priority support—to quorum queues on Amazon MQ for RabbitMQ, which do not support native priorities. It outlines why prioritization matters for time-critical business workflows and presents two main strategies: using separate quorum queues for each priority level or implementing custom consumer-side logic based on message metadata. These approaches allow organizations to maintain high availability and consistency while ensuring high-priority messages are processed first in quorum-based architectures.

###  [Blog 7 - Streamlining AWS Serverless workflows: From AWS Lambda orchestration to AWS Step Functions](3.7-Blog7/)
This blog discusses AWS Lambda as an orchestration delivery model and how to redesign serverless solutions using AWS Step Functions with unified primitives. Step Functions is a serverless service that you can use to build application delivery, automate workflows, orchestrate microservices, and create data streams and machine learning (ML). Step Functions provides primitives over 200 AWS services in addition to external APIs. You can use these properties to develop production-ready solutions with less effort, reduce coding complexity, improve long-term maintainability, and minimize technical debt when operating at larger scales.

###  [Blog 8 - Getting Started with Healthcare Data Lakes: Using Microservices](3.8-Blog8/)
This blog post highlights that as cloud adoption continues to accelerate, organizations are realizing that going to the cloud is just the beginning. The challenge – and the foundation for implementation – is using cloud optimization to deliver maximum business value. At AWS, we are committed to helping customers navigate this process successfully. Let’s explore some of the insights and best practices on the importance of cloud optimization shared in the new MIT Technology Review publication, Driving Business Value by Optimizing the Cloud.

###  [Blog 9 - Introducing v2 of Powertools for AWS Lambda (Java)](3.9-Blog9/)
This blog introduces the new version of Powertools for AWS Lambda (Java) with support for GraalVM native images. You'll learn how GraalVM reduces cold starts by up to 75%, how modular design reduces memory usage, and the benefits of core utilities like logging, metrics, and tracing. The article also covers migration steps from version 1, configuring native compilation, and ensuring compliance with serverless development standards.
