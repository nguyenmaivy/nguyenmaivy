[{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Hoàng Mai Vy\nSố điện thoại: 0862498257\nEmail: vynguyen08257@gmail.com\nTrường: Đại học Sài Gòn\nNgành: Công nghệ thông tin\nLớp: AWS092025\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 29/9/2025 đến ngày 22/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Sao lưu tài nguyên Amazon Elastic Kubernetes Service (EKS) bằng NetApp Trident Protect Kubernetes là một nền tảng điều phối container mã nguồn mở tự động hóa việc triển khai, mở rộng và quản lý ứng dụng được container hóa. Cho phép người dùng chạy ứng dụng và tác vụ trên Kubernetes, bảo vệ tài nguyên và dữ liệu do vô tình xóa hoặc lỗi phần cứng là rất quan trọng để duy trì tính liên tục của hoạt động kinh doanh và đáp ứng các yêu cầu về tuân thủ. Trong khi Kubernetes cung cấp tính sẵn sàng cao thông qua bảng điều khiển và dự phòng worker node, nó vốn không bảo vệ khỏi lỗi do con người, như là vô tình xóa namespaces, deployments, hoặc lưu trữ thực tế (persistent volumes), nó cũng không chống lại các lỗi khu vực (regional) hoặc hỏng dữ liệu.\nSự phức tạp kiến trúc microservices hiện đại và quy mô ngày càng tăng của các triển khai Kubernetes làm quan trọng hóa việc duy trì các bản sao lưu định kỳ và đã được kiểm tra rằng có thể khôi phục một cách nhất quán trong các môi trường khác nhau and Amazon Web Services (AWS) Regions. Bao gồm sao lưu thành phần thiết yếu như là toàn bộ namespaces, persistent volumes chứa dữ liệu ứng dụng, tài nguyên tùy chỉnh, và đối tượng cấu hình. Nếu không có cơ chế sao lưu thích hợp, các tổ chức có thể đối mặt nguy cơ gián đoạn kéo dài, mất mát dữ liệu và khả năng vi phạm các thỏa thuận mức độ dịch vụ (SLAs). Những điều này có thể dẫn đến tác động tài chính đáng kể và mất niềm tin từ khách hàng. Bài viết này sẽ giới thiệu một công cụ bảo vệ dữ liệu mới và cung cấp giới thiệu từng bước để thực hiện thử nghiệm tính khả thi (proof-of-concept) trong môi trường Kubernetes.\nNetApp Trident Protect Nó cung cấp khả năng tự động thông qua Kubernetes-native API và CLI tridentctl-protect mạnh mẽ, cho phép chương trình truy cập tích hợp liền mạch với luồng công việc hiện có. Người cùng AWS có thể sử dụng Trident Protect để xử lý các hoạt động phục hồi sau thảm họa giữa các cụm, di chuyển các dịch vụ có trạng thái giữa các dịch vụ lưu trữ, hoặc chuyển các tài nguyên đang chạy trên cụm Kubernetes tự quản lý sang dịch vụ Amazon Elastic Kubernetes Service (Amazon EKS). Kiến trúc sao lưu EKS và Trident được hiển thị trong Ảnh 1.\nHình 1. Kiến trúc sao lưu Amazon EKS và Trident.\nAmazon FSx for NetApp ONTAP là dịch vụ lưu trữ chia sẻ được quản lý toàn phần, được xây dựng trên hệ thống tập tin ONTAP phổ biến của NetApp. Nó cung cấp cho người dùng quyền truy cập vào các tính năng và dịch vụ lưu trữ cấp doanh nghiệp của ONTAP, chẳng hạn như thin provisioning (cấp phát mỏng), data deduplication (khử trùng lặp dữ liệu), và chức năng Snapshot (bản sao dữ liệu) những chức năng thúc đẩy tính linh hoạt của NetApp trong việc cấp phát lưu trữ và bảo vệ dữ liệu.\nTrong bài viết này, chúng tôi sẽ tập trung vào việc sử dụng Trident Protect với ứng dụng mẫu cửa hàng bán lẻ trên AWS của chúng tôi để xử lý các tác vụ bảo vệ và di chuyển dữ liệu đang chạy trên một cụm AKS. Chúng tôi còn đi sâu vào một số tùy chọn sao lưu, khôi phục và di chuyển dữ liệu giúp bạn quyết định triển khai cái gì là tốt nhất cho môi trường tổ chức của mình. Kiến trúc sau đây tạo các bản sao lưu trong AWS Region cục bộ, nơi có thể sử dụng để khôi phục các namespaces khác trong cùng một cụm và di chuyển dữ liệu từ các dịch vụ lưu trữ khác nhau của AWS.\nKiến trúc phần mềm Ứng dụng mẫu cửa hàng bán lẻ đơn giản trên AWS được xây dựng từ các microservices và được hỗ trợ bởi một số dịch vụ có trạng thái. Tổng cộng chúng sử dụng bốn Persistent Volume Claims (PVC) cho mỗi stack như trong Hình 2.\nAssets: Dùng để phục vụ các tài nguyên tĩnh như là hình ảnh liên quan đến danh mục sản phẩm-cần volume RWX như NFS. Orders: Tiếp nhận và xử lý các đơn đặt hàng của người dùng, được hỗ trợ bởi MySQL DB và RabbitMQ-cần hai volume lưu trữ khối RWO. Catalog: Danh sách và chi tiết sản phẩm được hỗ trợ bởi MySQL DB-cần volume lưu trữ khối RWO. Hình 2. Ứng dụng mẫu cửa hàng bán lẻ đơn giản.\nCác điều kiện tiên quyết Để cấp phát tài nguyên thủ công được sử dụng trong hướng dẫn này, danh sách sau đây cung cấp các thành phần và phiên bản sử dụng. Ngoài ra, sử dụng cấp phát tài nguyên TerraForm để tự động toàn bộ việc triển khai được giới thiệu trong Bước 1 của hướng dẫn.\nCụm Amazon EKS được triển khai phiên bản 1.32 Pod Identity add-on phiên bản v1.3.4 NetApp Trident CSI add-on phiên bản 25.06 Amazon EBS CSI add-on phiên bản v1.40.0-eksbuild.1 Snapshot controller add-on phiên bản v8.0.0 Tạo VolumeSnapshotClass (Lớp Ảnh chụp nhanh Volume) cho Amazon Elastic Block Storage (Amazon EBS) và FSx for ONTAP (các manifest mẫu đã được cấp phát như một phần của triển khai Terraform). Load balancer controller version 2.11.0 Triển khai hệ thống file FSx for ONTAP Hướng dẫn Tạo kiến trúc cần thiết với Terraform Clone kho lưu trữ mẫu từ GitHub và tạo tất cả các tài nguyên liên quan bằng cách sử dụng mã Terraform trong kho lưu trữ đó:\ngit clone https://github.com/aws-samples/sample-eks-backup-with-trident-protect.git cd sample-eks-backup-with-trident-protect/terraform terraform init terraform apply -auto-approve LƯU Ý: Script Terraform sẽ nhắc bạn nhập một địa chỉ IP công cộng (public IP address). Đây là địa chỉ của máy chủ (host) sẽ truy cập vào giao diện người dùng (UI) của ứng dụng mẫu.\nvar.ui_service_public_ip The public IP addess of the host that will access the sample application \u0026gt;UI from the web browser Enter a value: A.B.C.D/32 Quá trình triển khai này có thể mất 20-25 phút để hoàn tất. Khi kết thúc, đầu ra của lệnh sẽ trông giống như sau:\nfsx-management-ip = toset([ \u0026#34;10.0.1.13\u0026#34;, ]) fsx-ontap-id = \u0026#34;fs-a1b2c3d4e5f6g7h8i\u0026#34; fsx-svm-name = \u0026#34;ekssvm\u0026#34; region = \u0026#34;us-east-1\u0026#34; secret_arn = \u0026#34;arn:aws:secretsmanager:us-east-1:0123456789ab:secret:fsxn-password-secret-8DKLpwTi-8DLlwE\u0026#34; zz_update_kubeconfig_command = \u0026#34;aws eks update-kubeconfig --name eks-protect-8DKLpwTi --alias eks-primary --region us-east-1\u0026#34; Tiếp theo, hãy sao chép và chạy lệnh Giao diện Dòng lệnh AWS (AWS CLI) từ đầu ra update_kubeconfig_command và kiểm tra xem bạn có thể truy cập được cụm (cluster) hay không bằng cách chạy lệnh kubectl get nodes\nNAME STATUS ROLES AGE VERSION ip-10-0-1-120.ec2.internal Ready \u0026lt;none\u0026gt; 2m15s v1.32.1-eks-5d632ec ip-10-0-1-125.ec2.internal Ready \u0026lt;none\u0026gt; 95m v1.32.1-eks-5d632ec ip-10-0-2-42.ec2.internal Ready \u0026lt;none\u0026gt; 95m v1.32.1-eks-5d632ec ip-10-0-2-95.ec2.internal Ready \u0026lt;none\u0026gt; 2m9s v1.32.1-eks-5d632ec Triển khai Trident Protect từ cụm EKS Chạy các lệnh sau đây để cài đặt Trident Protect:\nQUAN TRỌNG: Hãy đảm bảo rằng bạn đã thay đổi clusterName thành tên cụm EKS của bạn trong môi trường.\nhelm repo add netapp-trident-protect https://netapp.github.io/trident-protect-helm-chart helm install trident-protect netapp-trident-protect/trident-protect --set clusterName=eks-protect-ymd8hvHr --version 100.2506.0 --create-namespace --namespace trident-protect Mong đợi output:\n\u0026#34;netapp-trident-protect\u0026#34; has been added to your repositories NAME: trident-protect LAST DEPLOYED: Tue Jul 22 19:44:30 2025 NAMESPACE: trident-protect STATUS: deployed REVISION: 1 TEST SUITE: None Tạo S3 bucket Nếu bạn đã có sẵn một S3 bucket , bạn có thể sử dụng nó. Nếu không, hãy làm theo các bước dưới đây để tạo một S3 bucket mới. Thay thế \u0026lt;bucket_name\u0026gt; và \u0026lt;aws_region\u0026gt; bằng các giá trị của bạn:\naws s3 mb s3://\u0026lt;bucket_name\u0026gt; --region \u0026lt;aws_region\u0026gt; Tạo EKS Secret để lưu trữ thông tin đăng nhập người dùng – Tùy chọn EKS Pod Identity là phương thức được khuyến nghị để xác thực IAM, và đã được cấu hình như một phần của quá trình triển khai Terraform ban đầu. Nếu bạn không muốn sử dụng EKS Pod Identity cho việc xác thực IAM, thì hãy tạo một Secret để lưu trữ accessKey và secretKey của người dùng Trident Protect AWS. Đảm bảo rằng thông tin đăng nhập người dùng bạn cung cấp có quyền truy cập cần thiết vào S3 bucket—tham khảo chính sách Amazon S3 mẫu (Amazon S3 policy statement).\nSử dụng ví dụ sau để tạo Secret:\nkubectl create secret generic \u0026lt;secret-name\u0026gt; \\ --from-literal=accessKeyID=\u0026lt;accessKey\u0026gt; \\ --from-literal=secretAccessKey=\u0026lt;seceretKey\u0026gt; \\ -n trident-protect Tạo Trident Protect AppVault Hãy tạo Trident Protect AppVault. AppVault này sẽ trỏ đến S3 bucket—nơi cả snapshots lẫn nội dung sao lưu (bao gồm dữ liệu và metadata) được lưu trữ. AppVault được tạo trong namespace chuyên biệt trident-protect (đã tạo ở Bước 2), và có thể được bảo mật bằng role-based access control (RBAC) để hạn chế quyền truy cập vào các đối tượng đặc quyền chỉ dành cho quản trị viên.\nTất cả các tác vụ còn lại sẽ được tạo trong namespace (không gian tên) ứng dụng gốc hoặc namespace đích trong trường hợp là các ví dụ khôi phục. Để tạo AppVault, hãy sử dụng tệp cấu hình mẫu protect-vault.yaml.\ncd \u0026lt;repo\u0026gt;/manifests Cập nhật các tham số sau đây:\nproviderConfig.s3.bucketName: Tên S3 bucket (thùng chứa S3). providerConfig.s3.endpoint: Endpoint S3 nếu bucket không nằm trong Vùng (Region) us-east-1. useIAM: Sử dụng EKS Pod Identity để xác thực IAM. providerCredentials.accessKeyID.name: Tên EKS Secret từ bước trước. providerCredentials.secretAccessKey.name: Tên EKS Secret từ bước trước. QUAN TRỌNG: Khi sử dụng useIAM: true với EKS Pod Identity, không được thiết lập (set) các tham số providerCredentials.accessKeyID.name và providerCredentials.secretAccessKey.name.\napiVersion: protect.trident.netapp.io/v1 kind: AppVault metadata: name: amazon-s3-trident-protect-src-bucket namespace: trident-protect spec: properties: dataMoverPasswordSecretRef: my-optional-data-mover-secret providerType: AWS providerConfig: s3: bucketName: trident-protect-blog endpoint: s3.amazonaws.com useIAM: true # providerCredentials: # accessKeyID: # valueFromSecret: # key: accessKeyID # name: s3-secret # secretAccessKey: # valueFromSecret: # key: secretAccessKey # name: s3-secret Chạy lệnh dưới đây để tạo AppValut:\nkubectl create -f protect-vault.yaml Để kiểm tra Appvault được tạo thành công chưa, chạy lệnh:\nkubectl get appvault -n trident-protect Kết quả mong đợi:\nNAME STATE ERROR MESSAGE AGE eks-protect-vault Available 4s Tạo Trident Protect Application Để thực hiện các hoạt động bảo vệ dữ liệu trên các ứng dụng Amazon EKS của bạn, bạn cần tạo một tài nguyên Trident Protect Application. Một Application có thể được định nghĩa theo các cách sau:\nLà một namespace, theo đó mọi thứ thuộc về namespace đó phải được bảo vệ. Là một tập hợp con của một namespace dựa trên labels (nhãn), nếu bạn chỉ muốn bảo vệ một phần của namespace (ví dụ: chỉ các PVC). Nó có thể mở rộng (span) qua nhiều namespace. Một Application cũng có thể tính đến các tài nguyên trên toàn cụm (cluster-wide resources). Để định nghĩa các namespaces mà tài nguyên ứng dụng tồn tại, hãy sử dụng spec.includedNamespaces và chỉ định labels của namespace hoặc tên namespace. Bạn có thể sử dụng tệp cấu hình mẫu trident-application.yaml này để định nghĩa một Application cho sample-app.\napiVersion: protect.trident.netapp.io/v1 kind: Application metadata: name: sample-app namespace: tenant0 spec: includedNamespaces: - namespace: tenant0 Chạy lệnh sau đây để tạo Application:\ncd \u0026lt;repo\u0026gt;/manifests kubectl create -f trident-application.yaml Để kiểm tra ứng dụng đã được tạo thành công chạy lệnh dưới đây:\nkubectl get application -n tenant0 Kết quả mong đợi:\nNAME PROTECTION STATE AGE sample-app None 14s Hướng dẫn Sao lưu, Khôi phục và Di chuyển (Dữ liệu/Ứng dụng) Tạo sao lưu ứng dụng\nTrident Protect có sẵn một số tùy chọn bảo vệ dữ liệu sau:\nOn-demand snapshot: Ảnh chụp nhanh theo yêu cầu On-demand backup: Sao lưu theo yêu cầu Data protection schedule: Lịch trình bảo vệ dữ liệu Application replication: Nhân bản ứng dụng Application migration: Di chuyển ứng dụng Trong bài viết này, chúng tôi tập trung vào sao lưu theo yêu cầu (on-demand backup) và di chuyển ứng dụng (application migration). Tuy nhiên, bạn có thể đọc thêm về cách sử dụng các tùy chọn bảo vệ dữ liệu khác trong các tài liệu tham khảo đã đề cập trước đó.\nĐể tạo một bản sao lưu theo yêu cầu cho ứng dụng mẫu, bạn cần tạo một tài nguyên backup cho Application mà bạn vừa định nghĩa và trỏ nó đến AppVault đã tạo trên Amazon S3. Bạn có thể sử dụng tệp cấu hình mẫu trident-backup.yaml sau đây:\napiVersion: protect.trident.netapp.io/v1 kind: Backup metadata: namespace: tenant0 name: sample-app-backup-1 spec: applicationRef: sample-app appVaultRef: eks-protect-vault Chạy lệnh dưới đây để tạo sao lưu:\ncd \u0026lt;repo\u0026gt;/manifests kubectl create -f trident-backup.yaml Để kiểm tra xem Bản sao lưu đã được tạo thành công hay chưa, hãy chạy lệnh sau đây:\nkubectl get backup -n tenant0 Kết quả mong đợi:\nNAME APP RECLAIM POLICY STATE ERROR AGE sample-app-backup-1 sample-app Retain Completed 9m33s QUAN TRỌNG: Trạng thái của bản sao lưu có thể hiển thị là Running (Đang chạy) trong khi quá trình sao lưu đang diễn ra. Hãy chờ cho đến khi trạng thái chuyển sang Completed (Đã hoàn thành). Nếu trạng thái là Failed (Thất bại), hãy sử dụng lệnh kubectl describe backup -n tenant0 sample-app-backup-1 để xem thêm chi tiết về lỗi đó.\nNếu bạn kiểm tra Application Protection State, trạng thái đó hiện được đặt là Partial (Một phần) vì bạn chỉ mới thiết lập một bản sao lưu theo yêu cầu (on-demand backup) cho ứng dụng của mình, nhưng chưa có lịch trình sao lưu (backup schedule) nào. Bạn có thể sử dụng lệnh kubectl describe application -n tenant0 để kiểm tra trạng thái này.\nTrident Protect có sẵn một số tùy chọn khôi phục sau:\nKhôi phục từ Backup Khôi phục từ bản sao lưu sang một namespace khác. Khôi phục từ bản sao lưu về namespace gốc. Khôi phục từ bản sao lưu sang một cụm. Khôi phục từ Snapshot Khôi phục từ snapshot sang một namespace khác. Khôi phục từ snapshot về namespace gốc. Trong bài viết này, chúng tôi tập trung vào việc khôi phục bản sao lưu của ứng dụng mẫu (sample-app) sang một namespace khác trên cùng một cụm EKS. Bạn có thể đọc thêm về cách sử dụng các tùy chọn khôi phục khác trong các tài liệu tham khảo đã đề cập trước đó. Dưới đây là phần ôn tập về trường spec của tài nguyên BackupRestore (Sao lưu-Khôi phục):\nspec.appArchivePath: Đường dẫn lưu trữ ứng dụng (Archive Path) trong AppVault—nơi chứa nội dung bản sao lưu. Bạn có thể truy xuất Archive Path bằng cách chạy lệnh sau đây trên tài nguyên backup của bạn:\nkubectl get backup sample-app-backup-1 -n tenant0 -o jsonpath=\u0026#39;{.status.appArchivePath}\u0026#39; spec.appVaultRef: Tên của AppVault—nơi chứa nội dung bản sao lưu. spec.namespaceMapping: Ánh xạ namespace nguồn của hoạt động khôi phục tới namespace đích. Bạn có thể sử dụng tệp cấu hình mẫu trident-protect-backup-restore.yaml sau đây:\napiVersion: protect.trident.netapp.io/v1 kind: BackupRestore metadata: name: sample-app-restore-1 namespace: tenant1 spec: appArchivePath: \u0026lt;APP ARCHIVE PATH\u0026gt; appVaultRef: eks-protect-vault namespaceMapping: - source: tenant0 destination: tenant1 resourceFilter: resourceSelectionCriteria: \u0026#34;Exclude\u0026#34; resourceMatchers: - kind: TargetGroupBinding Nếu bạn cần chọn chỉ các tài nguyên cụ thể trong ứng dụng để khôi phục, hãy sử dụng cơ chế lọc (filtering) sau để bao gồm (Include) hoặc loại trừ (Exclude) các tài nguyên được đánh dấu bằng các labels (nhãn) cụ thể.\nresourceFilter.resourceSelectionCriteria: Sử dụng Include (Bao gồm) hoặc Exclude (Loại trừ) để bao gồm hoặc loại trừ một tài nguyên được định nghĩa trong resourceMatchers. resourceFilter.resourceMatchers: resourceMatchers[].group: Group (Nhóm) của tài nguyên cần lọc resourceMatchers[].kind: Kind (Loại) của tài nguyên cần lọc resourceMatchers[].version: Version (Phiên bản) của tài nguyên cần lọc resourceMatchers[].names: Tên trong trường metadata.name của tài nguyên cần lọc resourceMatchers[].namespaces: Namespaces trong trường metadata.name của tài nguyên cần lọc resourceMatchers[].labelSelectors: Chuỗi bộ chọn label trong trường metadata.name của tài nguyên Ví dụ, bạn có thể sử dụng đoạn mã mẫu này để bao gồm (include) các tài nguyên trong tệp cấu hình BackupRestore của bạn:\nspec: resourceFilter: resourceSelectionCriteria: \u0026#34;Include\u0026#34; resourceMatchers: - group: my-resource-group-1 kind: my-resource-kind-1 version: my-resource-version-1 names: [\u0026#34;my-resource-names\u0026#34;] namespaces: [\u0026#34;my-resource-namespaces\u0026#34;] labelSelectors: [\u0026#34;trident.netapp.io/os=linux\u0026#34;] LƯU Ý: Quá trình khôi phục ứng dụng sử dụng dịch vụ loại LoadBalancer (Cân bằng tải) trong Amazon EKS. Do đó, bạn nên loại trừ các tài nguyên TargetGroupBinding để AWS Load Balancer Controller có thể tạo một TargetGroupBinding mới cho namespace mới mà không xung đột với ứng dụng hiện có trên cụm.\nChạy lệnh sau đây để tạo BackupRestore:\ncd \u0026lt;repo\u0026gt;/manifestskubectl create -f trident-protect-backup-restore.yaml Để kiểm tra xem tài nguyên BackupRestore đã được tạo thành công hay chưa, hãy chạy lệnh sau đây:\nkubectl get backuprestore -n tenant1 Kết quả mong đợi:\nNAME STATE ERROR AGE sample-app-restore-1 Completed 115s QUAN TRỌNG: Trạng thái của BackupRestore có thể hiển thị là Running (Đang chạy) trong khi quá trình khôi phục đang diễn ra. Hãy chờ cho đến khi trạng thái chuyển sang Completed (Đã hoàn thành). Nếu trạng thái là Failed (Thất bại), hãy sử dụng lệnh kubectl describe backuprestore -n tenant1 sample-app-restore-1 để xem thêm chi tiết về lỗi đó.\nSau khi quá trình khôi phục hoàn tất, bạn có thể xác minh ứng dụng đã được khôi phục đang hoạt động bằng cách truy cập endpoint của dịch vụ UI (giao diện người dùng) trong trình duyệt của bạn. Bạn có thể lấy endpoint của dịch vụ UI bằng cách chạy lệnh sau đây.\nkubectl get svc ui -n tenant1 --output jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].hostname}\u0026#39; Nếu mọi thứ đều thành công, bạn sẽ thấy giao diện người dùng (UI) trông giống như Hình 3:\n![alt text](\nHình 3. Ứng dụng cửa hàng bán lẻ đã được khôi phục.\nDi chuyển giữa các dịch vụ lưu trữ\nTrong bước này, bạn sẽ di chuyển một phần các dịch vụ có trạng thái của ứng dụng mẫu từ dịch vụ lưu trữ này sang dịch vụ lưu trữ khác. Bạn nên thực hiện điều này bằng cách sử dụng tính năng storageClassMapping của tài nguyên Trident Protect BackupRestore. Bạn sẽ di chuyển cơ sở dữ liệu MySQL của dịch vụ catalog từ một Volume EBS sang một Volume FSx for ONTAP sử dụng LUN được trình bày qua iSCSI.\nĐể làm điều đó, bạn sẽ thực thi hai tài nguyên BackupRestore. Một tài nguyên sẽ khôi phục tất cả các tài nguyên và dữ liệu của ứng dụng mẫu ngoại trừ catalog-mysql statefulset; và tài nguyên còn lại sẽ khôi phục và di chuyển riêng catalog-mysql statefulset từ Amazon EBS sang lưu trữ khối FSx for ONTAP.\nHãy xem xét tệp cấu hình mẫu trident-protect-migrate.yaml. Sử dụng resourceFilter để loại trừ và bao gồm các tài nguyên khỏi quá trình khôi phục, và sử dụng storageClassMapping để di chuyển các tài nguyên có trạng thái sang các hệ thống lưu trữ bên dưới khác.\nresourceFilter: resourceSelectionCriteria: \u0026#34;Exclude\u0026#34; resourceMatchers: - kind: StatefulSet names: [\u0026#34;catalog-mysql\u0026#34;] - kind: TargetGroupBinding QUAN TRỌNG: Hãy đảm bảo bạn cập nhật trường spec.appArchivePath trên cả hai tài nguyên [BackupRestore]. Bạn có thể truy xuất Đường dẫn Lưu trữ bằng cách chạy lệnh sau đây trên bản sao lưu của bạn:\nkubectl get backup sample-app-backup-1 -n tenant0 -o jsonpath=\u0026#39;{.status.appArchivePath}\u0026#39; Bạn có thể kiểm tra ứng dụng nguồn và thấy rằng volume (khối lưu trữ) ban đầu đang sử dụng Amazon EBS bằng cách dùng chính lệnh đó:\nkubectl get pvc data-catalog-mysql-0 -n tenant0 Kết quả mong đợi:\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS VOLUMEATTRIBUTESCLASS AGE data-catalog-mysql-0 Bound pvc-0d795501-aca2-4e10-98b5-111ecc3aef2c 30Gi RWO ebs-csi \u0026lt;unset\u0026gt; 71m Chạy lệnh sau đây để tạo các tài nguyên BackupRestore cần thiết cho quá trình di chuyển:\ncd \u0026lt;repo\u0026gt;/manifests kubectl create -f trident-protect-migrate.yaml Để kiểm tra xem các tài nguyên BackupRestore đã được tạo thành công hay chưa, hãy chạy lệnh sau đây:\nkubectl get backuprestore -n tenant2 QUAN TRỌNG: Trạng thái của tài nguyên BackupRestore có thể hiển thị là running (Đang chạy) trong khi quá trình khôi phục đang diễn ra. Hãy chờ cho đến khi trạng thái chuyển sang Completed (Đã hoàn thành). Nếu trạng thái là Failed (Thất bại), hãy sử dụng lệnh kubectl describe backuprestore -n tenant2 sample-app-migrate-# để xem thêm chi tiết về lỗi đó.\nKết quả mong đợi: NAME STATE ERROR AGE sample-app-migrate-1 Completed 26m sample-app-migrate-2 Completed 38s Bạn có thể kiểm tra xem PVC (Persistent Volume Claim) của catalog-mysql đã được di chuyển từ Amazon EBS sang FSx for ONTAP hay chưa bằng cách chạy lệnh sau đây:\nkubectl get pvc data-catalog-mysql-0 -n tenant2 Kết quả mong đợi:\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS VOLUMEATTRIBUTESCLASS AGE data-catalog-mysql-0 Bound pvc-8e45fa11-13ad-490d-b70c-d649b6fef4e9 30Gi RWO trident-csi-san \u0026lt;unset\u0026gt; 118s Sau khi quá trình di chuyển (migration) hoàn tất, bạn có thể xác minh ứng dụng đã di chuyển đang hoạt động bình thường bằng cách truy cập endpoint của dịch vụ UI (giao diện người dùng) trong trình duyệt của bạn. Bạn có thể lấy endpoint của dịch vụ UI bằng cách chạy lệnh sau đây:\nkubectl get svc ui -n tenant2 --output jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].hostname}\u0026#39; Nếu mọi thứ đều thành công, bạn sẽ thấy giao diện người dùng (UI) trông giống như Hình 4:\n![alt text](\nHình 4. Ứng dụng cửa hàng bán lẻ đã được khôi phục sau khi di chuyển PVC.\nTuyệt vời! Bạn đã hoàn thành và nắm vững các kiến thức cơ bản về sao lưu (backup), khôi phục (recovery) và di chuyển (migration) ứng dụng trên Amazon EKS sử dụng NetApp Trident Protect. Hướng dẫn này có thể được sử dụng như một thực tiễn tốt nhất để triển khai việc bảo vệ, di chuyển và phục hồi sau thảm họa (disaster recovery) trong môi trường của bạn.\nDọn dẹp Để tránh các khoản phí không cần thiết, hãy đảm bảo rằng bạn đã xóa tất cả các tài nguyên đã được tạo bằng Terraform bằng cách chạy kịch bản sau đây từ terminal (cửa sổ lệnh) của bạn:\nsh ../scripts/cleanup.sh Nếu bạn đã tạo một S3 bucket mới cho bài tập này, thì hãy dọn dẹp bằng cách đi tới giao diện điều khiển Amazon S3 (Amazon S3 console), xóa hết nội dung (emptying) của bucket, và xóa bucket đó.\nKết luận Tóm lại, NetApp Trident Protect cung cấp một giải pháp mạnh mẽ để hợp lý hóa (streamlining) việc bảo vệ dữ liệu cho các môi trường Kubernetes. Phương pháp này đáp ứng nhu cầu thiết yếu về các chiến lược sao lưu toàn diện trong các kiến trúc cloud-native (ứng dụng đám mây). NetApp Trident Protect cho phép người dùng tạo và quản lý một cách hiệu quả các bản sao lưu của toàn bộ namespaces , persistent volumes (khối lưu trữ lâu dài) và các tài nguyên Amazon EKS thiết yếu khác, qua đó đảm bảo tính liên tục của hoạt động kinh doanh và tuân thủ các yêu cầu về bảo vệ dữ liệu.\nHướng dẫn từng bước được trình bày trong bài viết này đã chứng minh sự dễ dàng trong việc thiết lập và sử dụng NetApp Trident Protect với Amazon EKS, Amazon FSx for NetApp ONTAP và Amazon EBS. Cảm ơn bạn đã đọc bài viết này. Hãy để lại bất kỳ nhận xét hoặc câu hỏi nào của bạn trong phần bình luận.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Vòng đời phát triển dựa trên AI: Tái định hình ngành kỹ thuật phần mềm Các nhà lãnh đạo kinh doanh và công nghệ luôn nỗ lực để nâng cao năng suất, tăng tốc độ phát triển, thúc đẩy thử nghiệm, rút ngắn thời gian đưa sản phẩm ra thị trường (TTM), và cải thiện trải nghiệm của lập trình viên. Những mục tiêu “ngôi sao dẫn đường” này thúc đẩy sự đổi mới trong các phương pháp phát triển phần mềm. Sự đổi mới này ngày càng được thúc đẩy bởi trí tuệ nhân tạo. Đặc biệt, các công cụ AI tạo sinh như Amazon Q Developer và Kiro đã bắt đầu cách mạng hóa cách phần mềm được tạo ra. Hiện tại, các tổ chức đang ứng dụng AI vào phát triển phần mềm theo hai hướng chính: phát triển hỗ trợ bởi AI, nơi AI hỗ trợ các nhiệm vụ cụ thể như viết tài liệu, gợi ý mã và kiểm thử; và phát triển tự động hóa bởi AI, nơi AI được kỳ vọng tạo ra toàn bộ ứng dụng dựa trên yêu cầu người dùng mà không cần sự can thiệp của con người. Cả hai hướng tiếp cận này đều cho kết quả chưa tối ưu về tốc độ và chất lượng phần mềm — và đây chính là vấn đề mà AI-DLC đặt mục tiêu giải quyết.\nTại sao chúng ta cần một cách tiếp cận mang tính chuyển đổi đối với AI trong phần mềm? Phương pháp phát triển phần mềm hiện tại được xây dựng cho các quy trình dài hạn, do con người dẫn dắt, nơi product owner, developer và architect dành phần lớn thời gian cho các hoạt động không cốt lõi như lập kế hoạch, họp hành, và thực hiện các nghi thức trong vòng đời phát triển phần mềm (SDLC). Việc chỉ đơn thuần tích hợp AI như một trợ lý không chỉ hạn chế khả năng của nó mà còn củng cố những điểm kém hiệu quả đã lỗi thời. Để thực sự khai thác sức mạnh của AI và đạt được các mục tiêu năng suất mang tính chiến lược, chúng ta cần tái hình dung toàn bộ cách tiếp cận vòng đời phát triển phần mềm.\nĐể đạt được kết quả mang tính đột phá, chúng ta cần đặt AI vào vai trò cộng tác viên và đồng đội trung tâm trong quy trình phát triển, đồng thời tận dụng khả năng của nó xuyên suốt vòng đời phần mềm. Đây là lý do chúng tôi giới thiệu AI-Driven Development Lifecycle (AI-DLC) — một phương pháp mới được thiết kế nhằm tích hợp hoàn toàn khả năng của AI vào mọi khía cạnh của quá trình phát triển phần mềm.\nAI Driven Development Life Cycle (AI-DLC) là gì? AI-DLC là một cách tiếp cận mới trong phát triển phần mềm, lấy AI làm trung tâm và tập trung vào hai yếu tố quan trọng:\nThực thi được hỗ trợ bởi AI với sự giám sát của con người: AI xây dựng kế hoạch làm việc chi tiết một cách có hệ thống, chủ động yêu cầu làm rõ và hướng dẫn khi cần, đồng thời chuyển các quyết định quan trọng cho con người. Điều này rất cần thiết bởi chỉ con người mới có sự hiểu biết sâu về bối cảnh và yêu cầu kinh doanh để đưa ra lựa chọn chính xác. Cộng tác nhóm năng động: Trong khi AI xử lý các nhiệm vụ thường xuyên và tẻ nhạt, đội ngũ con người tập trung làm việc trong môi trường cộng tác để giải quyết vấn đề theo thời gian thực, sáng tạo và đưa ra quyết định nhanh chóng. Sự chuyển dịch từ làm việc riêng lẻ sang hợp tác năng lượng cao giúp tăng tốc đổi mới và tốc độ triển khai. Hai yếu tố này cho phép bạn phát triển phần mềm nhanh hơn mà không phải đánh đổi chất lượng.\nAI-DLC hoạt động như thế nào? Cốt lõi của AI-DLC là AI bắt đầu và điều hướng quy trình làm việc thông qua một mô hình tư duy mới: Mô hình này hoạt động theo khuôn mẫu: AI tạo ra kế hoạch, đặt câu hỏi làm rõ để hiểu bối cảnh, và chỉ triển khai giải pháp sau khi nhận được xác nhận từ con người. Quy trình này được lặp lại liên tục cho mọi hoạt động trong vòng đời phát triển phần mềm (SDLC), giúp tạo ra một tầm nhìn thống nhất và phương pháp tiếp cận nhất quán cho tất cả các quy trình phát triển.\nVới mô hình tư duy này làm nền tảng, quá trình phát triển phần mềm trong AI-DLC diễn ra qua ba giai đoạn đơn giản:\nGiai đoạn Khởi tạo (Inception): AI chuyển đổi mục tiêu kinh doanh thành yêu cầu chi tiết, user stories và các đơn vị công việc thông qua “Mob Elaboration” – nơi cả nhóm cùng tham gia xác nhận câu hỏi và đề xuất của AI. Giai đoạn Xây dựng (Construction): Dựa trên bối cảnh đã được xác thực ở giai đoạn Khởi tạo, AI đề xuất kiến trúc logic, mô hình miền (domain models), giải pháp mã nguồn và kiểm thử thông qua “Mob Construction” – nơi nhóm đưa ra làm rõ về các quyết định kỹ thuật và lựa chọn kiến trúc theo thời gian thực. Giai đoạn Vận hành (Operations): AI sử dụng toàn bộ bối cảnh đã tích lũy từ các giai đoạn trước để quản lý hạ tầng dưới dạng mã (infrastructure as code) và triển khai hệ thống, với sự giám sát của đội ngũ. Mỗi giai đoạn cung cấp ngữ cảnh phong phú hơn cho giai đoạn tiếp theo, giúp AI đưa ra các đề xuất ngày càng chính xác và hiệu quả hơn.\nAI lưu trữ và duy trì ngữ cảnh liên tục xuyên suốt các giai đoạn bằng cách lưu kế hoạch, yêu cầu và các tài liệu thiết kế vào kho dự án của bạn, giúp công việc được tiếp tục liền mạch qua nhiều phiên làm việc khác nhau.\nAI-DLC giới thiệu thuật ngữ và nghi thức mới để phản ánh cách tiếp cận cộng tác cao và do AI dẫn dắt. Các “sprint” truyền thống được thay thế bằng “bolt” – các chu kỳ làm việc ngắn hơn, cường độ cao hơn, tính theo giờ hoặc ngày thay vì tuần; các Epics được thay thế bằng Units of Work. Sự thay đổi thuật ngữ này nhấn mạnh trọng tâm của phương pháp: tốc độ và khả năng triển khai liên tục. Tương tự, các thuật ngữ Agile quen thuộc khác cũng được tái định nghĩa để phù hợp với quy trình lấy AI làm trung tâm, tạo ra một hệ thống ngôn ngữ phản ánh đúng phương pháp đổi mới trong phát triển phần mềm này.\nLợi ích của phương pháp này là gì? Tốc độ (Velocity): Lợi ích quan trọng nhất mà AI-DLC mang lại là tăng tốc độ phát triển. AI nhanh chóng tạo và tinh chỉnh các tài liệu như yêu cầu, user stories, thiết kế, mã nguồn và kiểm thử, giúp product owner, kiến trúc sư và lập trình viên hoàn thành công việc trong vài giờ hoặc vài ngày thay vì hàng tuần như trước. Đổi mới (Innovation): Nhờ AI đảm nhiệm phần lớn khối lượng công việc nặng, đội ngũ có thêm thời gian tập trung vào đổi mới, khám phá các giải pháp sáng tạo và mở rộng giới hạn của những gì có thể thực hiện. Chất lượng (Quality): Thông qua việc liên tục làm rõ yêu cầu, đội ngũ xây dựng chính xác những gì họ mong muốn thay vì một phiên bản diễn giải mơ hồ của AI. Kết quả là sản phẩm phù hợp hơn với mục tiêu kinh doanh. AI nâng cao chất lượng bằng cách nhất quán áp dụng các tiêu chuẩn riêng của tổ chức — như quy tắc viết mã, mẫu thiết kế, yêu cầu bảo mật — đồng thời tạo ra bộ kiểm thử toàn diện. Tích hợp AI xuyên suốt quy trình giúp cải thiện tính thống nhất và khả năng truy vết từ yêu cầu đến triển khai. Khả năng phản ứng với thị trường (Market Responsiveness): Nhờ chu kỳ phát triển nhanh, AI-DLC cho phép phản hồi nhanh với nhu cầu thị trường và phản hồi của người dùng, từ đó thích ứng với yêu cầu hiệu quả hơn. Trải nghiệm lập trình viên (Developer Experience): AI-DLC thay đổi trải nghiệm của lập trình viên bằng cách chuyển trọng tâm từ việc viết mã lặp đi lặp lại sang giải quyết các vấn đề cốt lõi. AI giảm gánh nặng nhận thức bằng cách xử lý công việc thủ công, trong khi lập trình viên có được hiểu biết sâu hơn về nghiệp vụ và thấy rõ tác động trực tiếp của công việc họ đối với giá trị kinh doanh — từ đó tăng mức độ hài lòng. Làm thế nào để bắt đầu với phương pháp này? Hãy bắt đầu hành trình AI-DLC của bạn thông qua ba hướng tiếp cận rõ ràng: đọc bản white paper chi tiết về AI-DLC, tìm hiểu cách Amazon Q Developer rules và các quy trình tùy chỉnh Kiro có thể giúp bạn triển khai AI-DLC một cách nhất quán trong tổ chức, hoặc liên hệ với đội ngũ AWS của bạn để trao đổi về cách điều chỉnh AI-DLC phù hợp với nhu cầu đặc thù của tổ chức.\nTương lai của phát triển phần mềm đã bắt đầu. Chúng tôi rất háo hức được giúp bạn tận dụng AI không chỉ để xây dựng hệ thống nhanh hơn mà còn đảm bảo tính chính xác và chất lượng thông qua sự giám sát và cộng tác quan trọng của con người. Hãy bắt đầu hành trình AI-DLC của bạn ngay hôm nay và tham gia cộng đồng ngày càng lớn mạnh của các tổ chức đang chuyển đổi phương pháp phát triển của họ thông qua đổi mới do AI dẫn dắt.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Khắc phục sự rối loạn trong phát triển với các tác nhân tùy chỉnh của Amazon Q Developer CLI. Là một nhà phát triển đã tận dụng sức mạnh của Giao thức Ngữ cảnh Mô hình (MCP) để nâng cao quy trình làm việc, tôi vô cùng hào hứng khi thấy Amazon Q Developer CLI bổ sung các tác nhân tùy chỉnh (custom agents). Tính năng mới này đưa các khả năng mà tôi đã quen thuộc lên một tầm cao mới, cho phép tôi quản lý các ngữ cảnh phát triển khác nhau một cách liền mạch và dễ dàng chuyển đổi giữa chúng.\nTrong bài viết trước, tôi đã thảo luận về cách các máy chủ MCP đã cách mạng hóa phương thức tôi tương tác với các dịch vụ AWS, cơ sở dữ liệu và các công cụ thiết yếu khác. Việc tích hợp MCP vào Amazon Q Developer cho phép tôi truy vấn các lược đồ cơ sở dữ liệu, tự động hóa việc triển khai cơ sở hạ tầng, và nhiều hơn thế nữa. Tuy nhiên, khi tôi bắt đầu xử lý nhiều dự án, mỗi dự án lại có các stack công nghệ và yêu cầu riêng biệt, tôi nhận thấy mình cần một phương pháp tiếp cận có cấu trúc hơn để quản lý các môi trường phát triển đa dạng này.\nĐây chính là lúc các tác nhân tùy chỉnh xuất hiện. Với tính năng mới này, tôi có thể tạo và sử dụng một tác nhân tùy chỉnh bằng cách kết hợp các công cụ, lời nhắc (prompt), ngữ cảnh và quyền công cụ cụ thể cho các tác vụ phù hợp với từng giai đoạn phát triển. Trong bài viết này, tôi sẽ giải thích cách cấu hình một tác nhân tùy chỉnh cho phát triển front-end và back-end, giúp tôi dễ dàng tối ưu hóa Amazon Q Developer cho từng nhiệm vụ.\nBối Cảnh Hãy tưởng tượng tôi đang làm việc trên một ứng dụng web đa tầng. Ứng dụng này có giao diện front-end React viết bằng Typescript và giao diện back-end FastAPI viết bằng Python. Ngoài tôi ra, nhóm còn có một nhà thiết kế sử dụng Figma và một quản trị viên cơ sở dữ liệu quản lý database PostgreSQL. Có những khác biệt tinh tế trong cách tôi giao tiếp với nhà thiết kế và quản trị viên cơ sở dữ liệu. Ví dụ, khi tôi thảo luận về một \u0026ldquo;table\u0026rdquo; (bảng) với nhà thiết kế, tôi có khả năng đang đề cập đến một bảng HTML và cách trang web được cấu trúc. Tuy nhiên, khi tôi thảo luận về một \u0026ldquo;table\u0026rdquo; với quản trị viên cơ sở dữ liệu, tôi có khả năng đang nói về một bảng SQL và cách dữ liệu được lưu trữ.\nTrong quá khứ, tôi đã cấu hình cả máy chủ Figma Dev Mode MCP và máy chủ Amazon Aurora PostgreSQL MCP trong môi trường của mình. Mặc dù điều này cho phép tôi dễ dàng làm việc với mã front-end hoặc back-end, nhưng nó đã tạo ra một số thách thức. Nếu tôi hỏi Amazon Q Developer: \u0026ldquo;Tôi có bao nhiêu tables?\u0026rdquo;, Amazon Q Developer sẽ phải đoán xem tôi đang nói về bảng HTML hay bảng SQL. Nếu câu hỏi là về HTML, nó nên sử dụng máy chủ Figma. Nếu câu hỏi là về SQL, nó nên sử dụng máy chủ Aurora. Đây không phải là một hạn chế kỹ thuật, mà là một hạn chế về ngôn ngữ. Giống như việc tôi phải điều chỉnh các giả định của mình khi nói chuyện với nhà thiết kế và quản trị viên cơ sở dữ liệu, Amazon Q Developer cũng phải thực hiện những điều chỉnh tương tự.\nGiải pháp là các tác nhân tùy chỉnh (custom agents) của Amazon Q Developer CLI. Các tác nhân tùy chỉnh cho phép tôi tối ưu hóa cấu hình của Q Developer cho từng tình huống. Hãy cùng tìm hiểu qua cấu hình front-end và back-end của tôi để hiểu rõ tác động.\nTác Nhân Front-end Tác nhân tùy chỉnh front-end của tôi được tối ưu hóa cho việc phát triển web front-end sử dụng React và Figma. Ví dụ mã sau đây là cấu hình cho tác nhân front-end của tôi, được lưu trữ tại ~/.aws/amazonq/cli-agents/front-end.json. Hãy cùng thảo luận về các phần chính của cấu hình này.\nmcpServers – Tại đây, tôi đã cấu hình Máy chủ Figma Dev Mode MCP. Máy chủ này đơn giản là giao tiếp với Ứng dụng Thiết kế Web Figma được cài đặt cục bộ. Lưu ý rằng điều này sẽ thay thế cấu hình MCP đã được lưu trữ trong ~/.aws/amazonq/mcp.json. tools và allowedTools – Hai phần này có liên quan đến nhau, vì vậy tôi sẽ thảo luận chúng cùng lúc. tools định nghĩa các công cụ có sẵn cho Amazon Q Developer trong khi allowedTools định nghĩa các công cụ được tin cậy, nói cách khác, Q Developer có thể sử dụng tất cả các công cụ đã được cấu hình, và nó không cần phải hỏi ý kiến tôi để sử dụng fs_read, fs_write, và @Figma. @Figma cho phép Amazon Q Developer sử dụng tất cả các công cụ Figma mà không cần hỏi xin phép. Chi tiết hơn sẽ có trong phần tiếp theo. resources – Tại đây tôi đã cấu hình các tệp nên được thêm vào ngữ cảnh (context). Tôi đã bao gồm tệp README.md (được lưu trữ trong thư mục dự án) và các tùy chọn riêng của tôi cho React (được lưu trữ trong hồ sơ cá nhân). Bạn có thể đọc thêm trong phần quản lý ngữ cảnh của hướng dẫn sử dụng. hooks – Ngoài các tài nguyên, tôi cũng đã bao gồm một hook. Hook này sẽ chạy một lệnh và chèn kết quả của nó vào ngữ cảnh tại thời điểm chạy (runtime). Trong ví dụ này, tôi đang thêm git status hiện tại. Bạn có thể đọc thêm trong phần hook ngữ cảnh của hướng dẫn sử dụng. { \u0026#34;name\u0026#34;: \u0026#34;front-end\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Optimized for front-end web development using React and Figma\u0026#34;, \u0026#34;mcpServers\u0026#34;: { \u0026#34;Figma\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;npx\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;mcp-remote\u0026#34;, \u0026#34;http://127.0.0.1:3845/sse\u0026#34; ] } }, \u0026#34;tools\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;allowedTools\u0026#34;: [ \u0026#34;fs_read\u0026#34;, \u0026#34;fs_write\u0026#34;, \u0026#34;report_issues\u0026#34;, \u0026#34;@Figma\u0026#34; ], \u0026#34;resources\u0026#34;: [ \u0026#34;file://README.md\u0026#34;, \u0026#34;file://~/.aws/amazonq/react-preferences.md\u0026#34; ], \u0026#34;hooks\u0026#34;: { \u0026#34;agentSpawn\u0026#34;: [ { \u0026#34;command\u0026#34;: \u0026#34;git status\u0026#34; } ] } } Tác Nhân Back-end Tác nhân tùy chỉnh back-end của tôi được tối ưu hóa cho việc phát triển back-end với Python và PostgreSQL. Ví dụ mã sau đây là cấu hình cho tác nhân back-end của tôi, được lưu trữ tại ~/.aws/amazonq/cli-agents/back-end.json. Thay vì mô tả lại các phần như đã làm trước đó, tôi sẽ tập trung vào sự khác biệt giữa tác nhân front-end và back-end.\nmcpServers – Ở đây, tôi đã cấu hình Máy chủ Amazon Aurora PostgreSQL MCP. Điều này cho phép Amazon Q Developer truy vấn cơ sở dữ liệu dev của tôi để tìm hiểu về lược đồ (schema). Hãy chú ý rằng tôi đã cấu hình một kết nối chỉ đọc (read-only) để đảm bảo rằng tôi không vô tình cập nhật cơ sở dữ liệu. tools và allowedTools – Một lần nữa, tôi đã cho phép Amazon Q Developer sử dụng tất cả các công cụ. Tuy nhiên, hãy lưu ý rằng tôi hạn chế hơn về những công cụ được tin cậy. Amazon Q Developer sẽ cần hỏi xin phép để sử dụng fs_write (ghi tệp) hoặc @PostgreSQL/run_query (chạy truy vấn SQL). Lưu ý rằng tôi có thể cho phép toàn bộ máy chủ MCP (như tôi đã làm với Figma) hoặc các công cụ cụ thể (như tôi đã làm ở đây). resources – Tương tự, tôi đã bao gồm tệp README.md (được lưu trữ trong thư mục dự án) và các tùy chọn riêng của tôi cho Python và SQL (cả hai đều được lưu trữ trong hồ sơ cá nhân). Lưu ý rằng tôi cũng có thể sử dụng các mẫu glob (glob patterns) ở đây. Ví dụ, file://.amazonq/rules/**/*.md sẽ bao gồm các quy tắc được tạo bởi các plugin IDE của Amazon Q Developer. hooks – Cuối cùng, tôi cũng đã đưa vào hook cho cả front-end và back-end. Tuy nhiên, tôi có thể đã đưa vào các tùy chọn dành riêng cho dự án như npm run cho front-end và pip freeze cho back-end. { \u0026#34;name\u0026#34;: \u0026#34;back-end\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Optimized for back-end development with Python and PostgreSQL\u0026#34;, \u0026#34;mcpServers\u0026#34;: { \u0026#34;PostgreSQL\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;uvx\u0026#34;, \u0026#34;args\u0026#34;: [ \u0026#34;awslabs.postgres-mcp-server@latest\u0026#34;, \u0026#34;--resource_arn\u0026#34;, \u0026#34;arn:aws:rds:us-east-1:xxxxxxxxxxxx:cluster:xxxxxx\u0026#34;, \u0026#34;--secret_arn\u0026#34;, \u0026#34;arn:aws:secretsmanager:us-east-1:xxxxxxxxxxxx:secret:rds!cluster-xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxx-xxxxxx\u0026#34;, \u0026#34;--database\u0026#34;, \u0026#34;dev\u0026#34;, \u0026#34;--region\u0026#34;, \u0026#34;us-east-1\u0026#34;, \u0026#34;--readonly\u0026#34;, \u0026#34;True\u0026#34; ] } }, \u0026#34;tools\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;allowedTools\u0026#34;: [ \u0026#34;fs_read\u0026#34;, \u0026#34;report_issues\u0026#34;, \u0026#34;@PostgreSQL/get_table_schema\u0026#34; ], \u0026#34;resources\u0026#34;: [ \u0026#34;file://README.md\u0026#34;, \u0026#34;file://~/.aws/amazonq/python-preferences.md\u0026#34;, \u0026#34;file://~/.aws/amazonq/sql-preferences.md\u0026#34; ], \u0026#34;hooks\u0026#34;: { \u0026#34;agentSpawn\u0026#34;: [ { \u0026#34;command\u0026#34;: \u0026#34;git status\u0026#34; } ] } } Sử Dụng Các Tác Nhân Tùy Chỉnh Sức mạnh thực sự của các tác nhân (agents) trở nên rõ ràng khi tôi cần chuyển đổi giữa các ngữ cảnh phát triển khác nhau này. Giờ đây, tôi chỉ cần chạy lệnh q chat --agent front-end khi tôi làm việc với React và Figma, hoặc q chat --agent back-end khi tôi làm việc với Python và SQL. Amazon Q Developer sẽ tự động cấu hình tác nhân chính xác với tất cả các tùy chọn cá nhân của tôi.\nTrong hình ảnh sau đây, bạn có thể thấy rõ sự khác biệt trong cấu hình của Amazon Q Developer CLI. Hãy chú ý rằng tác nhân Front-end có thêm công cụ Figma, trong khi Tác nhân Back-end có thêm công cụ PostgreSQL. Ngoài ra tác nhân Front-end tin cậy (trusts) fs_write và tất cả các công cụ Figma trong khi tác nhân Back-end sẽ hỏi xin phép để sử dụng fs_write và chỉ tin cậy một trong hai công cụ PostgreSQL.\nTương tự, hãy xem cấu hình ngữ cảnh ở cả tác tử front-end và back-end. Trong hình dưới đây, tôi đã thêm các tùy chọn yêu thích của mình cho React trong việc phát triển front-end, và các tùy chọn về Python và SQL cho việc phát triển back-end.\nNhư bạn có thể thấy, các tác tử tùy chỉnh cho phép tôi tối ưu hóa Amazon Q Developer CLI cho từng nhiệm vụ. Tất nhiên, tác tử front-end và back-end chỉ là một ví dụ. Bạn có thể có tác tử dành cho lập trình và kiểm thử, tác tử cho khoa học dữ liệu và phân tích, v.v. Các tác tử tùy chỉnh cho phép bạn điều chỉnh cấu hình phù hợp với hầu hết mọi nhiệm vụ.\nKết luận Các tác tử tùy chỉnh của Amazon Q Developer CLI đại diện cho một bước tiến đáng kể trong việc quản lý các môi trường phát triển phức tạp. Bằng cách cho phép các lập trình viên chuyển đổi liền mạch giữa các ngữ cảnh khác nhau, chúng loại bỏ gánh nặng tư duy khi phải tự tay cấu hình lại công cụ và quyền truy cập cho từng nhiệm vụ. Bạn đã sẵn sàng tối ưu hóa quy trình phát triển của mình chưa? Hãy bắt đầu với Amazon Q Developer ngay hôm nay.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.4-blog4/","title":"Blog 4","tags":[],"description":"","content":"Cách Zapier chạy các tác vụ riêng biệt trên AWS Lambda và nâng cấp các chức năng ở quy mô lớn Tác giả: Anton Aleksandrov, Raúl Negrón-Otero, Ankush Kalra, Vítek Urbanec và Chandresh Patel Xuất bản: Ngày 25 tháng 07 năm 2025 Advanced (300), Amazon CloudWatch, Amazon Elastic Kubernetes Service, Architecture, AWS Lambda, Customer Solutions, Monitoring and observability, Serverless\nZapier là nhà cung cấp dịch vụ tự động hóa không cần mã hàng đầu, với khách hàng sử dụng giải pháp của họ để tự động hóa quy trình làm việc và di chuyển dữ liệu trên hơn 8.000 ứng dụng như Slack, Salesforce, Asana và Dropbox. Zapier vận hành các quy trình tự động hóa này thông qua các tích hợp được gọi là Zap, được triển khai bằng kiến ​​trúc serverless chạy trên Amazon Web Services (AWS). Mỗi Zap được hỗ trợ bởi một hàm AWS Lambda.\nTrong bài viết này, bạn sẽ tìm hiểu cách Zapier xây dựng kiến ​​trúc serverless của mình, tập trung vào ba khía cạnh chính: sử dụng hàm Lambda để xây dựng các Zap riêng biệt, vận hành hơn một trăm nghìn hàm Lambda thông qua cơ sở hạ tầng mặt phẳng điều khiển của Zapier, và tăng cường khả năng bảo mật đồng thời giảm thiểu nỗ lực bảo trì bằng cách đưa các nâng cấp hàm tự động và quy trình dọn dẹp vào kiến ​​trúc nền tảng của họ.\nKiến trúc môi trường thời gian chạy an toàn và biệt lập Các Zap do người dùng Zapier tạo ra triển khai logic nghiệp vụ dành riêng cho từng đối tượng thuê, do đó chúng yêu cầu sự cô lập tính toán giữa các đối tượng thuê. Mã triển khai một Zap không thể chia sẻ môi trường thực thi với mã triển khai một Zap khác. Hơn nữa, cùng một loại Zap được sử dụng bởi hai đối tượng thuê khác nhau cũng không thể chia sẻ môi trường thực thi.\nĐể đạt được mức độ cô lập cần thiết, đội ngũ kỹ thuật của Zapier đã áp dụng AWS Lambda , một dịch vụ điện toán serverless chạy code để phản hồi các sự kiện và tự động quản lý tài nguyên điện toán đám mây. Chi phí vận hành tối thiểu, tính khả dụng cao tích hợp sẵn , khả năng mở rộng tự động, mức độ cô lập cao và mô hình trả tiền theo mức sử dụng đã khiến Lambda trở thành lựa chọn hoàn hảo cho trường hợp sử dụng này. Hiện tại, kiến ​​trúc của Zapier đang chạy hơn một trăm nghìn hàm Lambda để hỗ trợ quy trình tích hợp của khách hàng.\nVì được hỗ trợ bởi các microVM Firecracker mã nguồn mở, mỗi hàm được cô lập hoàn toàn với các hàm khác. Hơn nữa, mỗi môi trường thực thi thuộc về cùng một hàm (đôi khi được gọi là các thể hiện hàm) cũng được cô lập khỏi các môi trường thực thi khác. Sơ đồ cấu trúc kiến ​​trúc sau đây sử dụng các đường màu đỏ để biểu diễn ranh giới cô lập. Mỗi môi trường thực thi của mỗi hàm đều được cô lập với các môi trường ngang hàng và có các tài nguyên ảo riêng như đĩa, bộ nhớ và CPU. Để biết thêm chi tiết, vui lòng đọc phần. Bảo mật trong AWS Lambda\n*Hình 1. *\nMặt phẳng điều khiển của Zapier được thiết kế dựa trên Amazon Elastic Kubernetes Service (Amazon EKS). Một cơ sở dữ liệu được chỉ định sẽ được sử dụng để duy trì kho dữ liệu chức năng được cập nhật. Bất cứ khi nào người dùng tạo một Zap mới, mặt phẳng điều khiển sẽ tạo một hàm Lambda tương ứng và lưu trữ tham chiếu trong cơ sở dữ liệu kho dữ liệu. Khi một Zap được kích hoạt, mặt phẳng điều khiển sẽ truy xuất thông tin về hàm Lambda liên quan và gọi hàm đó để tạo điều kiện thuận lợi cho quy trình tích hợp, như minh họa trong sơ đồ sau.\n*Hình 2. *\nHiểu về quy trình ngừng sử dụng runtime Khi xây dựng kiến ​​trúc sử dụng hệ thống điện toán không máy chủ truyền thống, các kỹ sư đám mây là những người chịu trách nhiệm cập nhật hệ điều hành và phần mềm trên các phiên bản điện toán của họ, đồng thời áp dụng các bản vá bảo mật và bảo trì. Với kiến ​​trúc serverless và các hàm Lambda, các bản vá bảo mật và nâng cấp runtime nhỏ được AWS tự động xử lý, điều này có nghĩa là khách hàng có thể tập trung vào việc mang lại giá trị kinh doanh thay vì gánh nặng quản lý cơ sở hạ tầng không chuyên biệt.\nKhi một phiên bản runtime được quản lý Lambda chính kết thúc vòng đời, AWS sẽ khởi tạo quy trình ngừng sử dụng thông qua AWS Health Dashboard và gửi email trực tiếp đến các khách hàng bị ảnh hưởng. Vì các runtime đã ngừng sử dụng cuối cùng sẽ mất quyền truy cập vào các bản cập nhật bảo mật và hỗ trợ, các tổ chức phải nâng cấp lên các phiên bản runtime được hỗ trợ để tránh các rủi ro bảo mật tiềm ẩn. Tìm hiểu thêm về mô hình chia sẻ trách nhiệm, việc sử dụng runtime sau khi ngừng sử dụng và nhận thông báo ngừng sử dụng runtime\nDo cơ sở người dùng và độ phức tạp về kiến ​​trúc của Zapier - và do đó số lượng Zap - ngày càng tăng, việc duy trì tất cả các chức năng trên các phiên bản runtime chính mới nhất trở thành một nhiệm vụ tốn nhiều công sức. Các yếu tố góp phần hàng đầu là:\nSố lượng hàm lớn. Vào thời kỳ đỉnh cao, nền tảng Zapier đã chạy Zap bằng hàng trăm nghìn hàm Lambda riêng biệt. Khoảng 35% trong số các hàm này sử dụng một môi trường thời gian chạy đã được lên lịch ngừng hoạt động trong 12 tháng tới.\nZapier đã thiết kế môi trường mặt phẳng dữ liệu của họ theo hướng tạm thời – mặt phẳng điều khiển tạo và xóa các hàm Lambda theo yêu cầu và quản lý vòng đời của chúng một cách linh hoạt. Việc xác định chủ sở hữu cụ thể cho từng hàm bị ảnh hưởng không phải lúc nào cũng đơn giản.\nBảo mật là tối quan trọng tại Zapier và việc nâng cấp thời gian chạy của các hàm bị ảnh hưởng trước ngày ngừng hoạt động là điều bắt buộc. Không có thời điểm nào các hàm Zapier có thể sử dụng thời gian chạy sau ngày ngừng hoạt động. Đây là một nhiệm vụ đòi hỏi thêm tài nguyên.\nQuá trình nâng cấp không nên có bất kỳ tác động nào đến trải nghiệm của khách hàng cuối. Không có thời điểm nào trải nghiệm của khách hàng bị ảnh hưởng.\nVới thời gian triển khai ngắn, khối lượng công việc lớn và các yêu cầu nghiêm ngặt về việc không ảnh hưởng đến trải nghiệm của khách hàng, nhóm Kỹ thuật Nền tảng của Zapier đã đảm nhận thử thách này để duy trì trạng thái bảo mật cao trong kiến ​​trúc nền tảng của họ.\nÁp dụng giải pháp Giải pháp này bao gồm ba luồng công việc:\nGiảm thiểu rủi ro bằng cách phân tích kiến ​​trúc, xác định và dọn dẹp các chức năng không sử dụng. Ưu tiên nâng cấp bằng cách xác định các chức năng quan trọng và có tác động lớn nhất. Trao quyền cho các nhóm kỹ thuật bằng các công cụ và kiến ​​thức tự động để hợp lý hóa quy trình nâng cấp trong tương lai. Xác định và dọn dẹp các chức năng không sử dụng Bước đầu tiên trong việc hợp lý hóa quy trình nâng cấp là xác định và loại bỏ các chức năng không sử dụng. Điều này đã giảm tổng số chức năng trong kiến ​​trúc của Zapier cần nâng cấp, loại bỏ khối lượng công việc không cần thiết cho nhóm. Zapier bắt đầu bằng cách bổ sung thông tin thời gian chạy vào kho chức năng bằng cách sử dụng AWS Trusted Advisor và Amazon Cloud IntelligenceTrusted Advisor dashboards, như minh họa trong sơ đồ sau.\n*Hình 3. *\nĐiều này có nghĩa là nhóm có thể xây dựng một danh mục chi tiết các chức năng đang chạy trên các môi trường thời gian chạy sắp bị loại bỏ. Sử dụng Amazon CloudWatch, nhóm nền tảng của Zapier bắt đầu theo dõi các số liệu như số lần gọi. Họ xác định chức năng nào đang hoạt động, chức năng nào không được sử dụng trong thời gian dài và chức năng nào không có chủ sở hữu đang hoạt động và có thể bị xóa.\nMột trong những cơ chế chính để xác thực quyền sở hữu trong tổ chức là sử dụng thẻ tài nguyên. Các chức năng đang hoạt động nhưng không có quyền sở hữu rõ ràng sẽ được gắn cờ để xem xét thêm trước khi xóa. Các chức năng được xác nhận là không sử dụng hoặc không có chủ sở hữu đang hoạt động sẽ được đánh dấu để xóa. Việc xóa các chức năng như vậy cho phép Zapier đơn giản hóa đáng kể kiến ​​trúc của họ và giảm số lượng chức năng cần nâng cấp.\nƯu tiên nâng cấp Với số lượng chức năng cần nâng cấp ít hơn, nhóm nền tảng của Zapier đã ưu tiên nâng cấp chức năng dựa trên mô hình sử dụng, mức độ quan trọng và tác động tiềm ẩn đến khách hàng. Ba hạng mục ưu tiên chính là:\nChức năng hướng đến khách hàng – Bất kỳ chức năng nào liên quan trực tiếp đến việc thực thi Zap của người dùng đều được đánh dấu là ưu tiên cao. Những chức năng này phải được nâng cấp trước để tránh gián đoạn dịch vụ.\nCác chức năng cơ sở hạ tầng backend – Các chức năng nội bộ hỗ trợ hoạt động hệ thống được đánh giá dựa trên tầm quan trọng của chúng đối với sự ổn định của nền tảng.\nCác chức năng khối lượng lớn – Các chức năng có tần suất thực thi cao nhất được ưu tiên vì việc nâng cấp chúng sẽ có tác động lớn nhất đến việc giảm thiểu rủi ro vận hành. Sử dụng các yếu tố này, nhóm nền tảng của Zapier đã tạo ra một lộ trình nâng cấp, đảm bảo các tài sản quan trọng được xử lý trước tiên đồng thời giảm thiểu các gián đoạn tiềm ẩn.\nTham khảo mục Truy xuất dữ liệu về các chức năng Lambda sử dụng thời gian chạy đã lỗi thời trong Hướng dẫn dành cho Nhà phát triển Lambda để tìm hiểu cách xác định các chức năng Lambda được sử dụng phổ biến nhất và thường xuyên nhất trong kiến ​​trúc không máy chủ của bạn.\nTrao quyền cho các nhóm kỹ thuật bằng các công cụ và kiến ​​thức tự động Để đảm bảo quy trình nâng cấp diễn ra suôn sẻ và hiệu quả trên toàn bộ kiến ​​trúc không máy chủ, nhóm Zapier đã trao quyền cho các nhóm kỹ thuật bằng các hướng dẫn rõ ràng và các giải pháp tự động. Nền tảng kết hợp hai phương pháp chính: các chức năng do Terraform quản lý và một công cụ canary thời gian chạy Lambda được xây dựng riêng. Việc triển khai và áp dụng các công cụ và phương pháp này đã giúp giảm 95% số lượng chức năng sử dụng các thời gian chạy sắp lỗi thời.\nĐối với các chức năng được quản lý thông qua infrastructure-as-code (IaC), nhóm Zapier đã phát triển các mô-đun Terraform chuẩn hóa, chỉ định các phiên bản thời gian chạy được hỗ trợ. Các nhóm phát triển đã triển khai các mô-đun này trong cấu hình của họ:\nresource \u0026#34;aws_lambda_function\u0026#34; \u0026#34;example\u0026#34; { runtime = \u0026#34;python3.13\u0026#34; # Updated to supported runtime } Sau khi áp dụng phiên bản mô-đun mới, các nhóm đã xác thực các thay đổi bằng cách kiểm tra thời gian chạy mới trong môi trường dàn dựng và theo dõi đầu ra của Terraform plan để đảm bảo cập nhật phiên bản thời gian chạy chính xác. Để quản lý hiệu quả hầu hết các hàm Lambda trong kiến ​​trúc của mình, Zapier đã phát triển bộ công cụ Lambda runtime canary. Sử dụng giải pháp này, họ đã tự động hóa quy trình nâng cấp thời gian chạy cho hàng nghìn hàm Lambda đang hoạt động với sự can thiệp thủ công tối thiểu. Bộ công cụ triển khai một số tính năng chính:\nĐược thiết kế để chuyển đổi lưu lượng dần dần với cơ chế định tuyến tích hợp sẵn của Lambda thông qua phiên bản hàm và đặt bí danh. Công cụ có thể chuyển đổi dần dần phân phối lưu lượng từ phiên bản hàm cũ sang phiên bản hàm mới. Trong quá trình chuyển đổi lưu lượng dần dần này, hệ thống sẽ theo dõi các số liệu CloudWatch để tìm lỗi và tự động khôi phục nếu tỷ lệ lỗi vượt quá ngưỡng chấp nhận được.\nChiến lược nâng cấp tối ưu triển khai nâng cấp trực tiếp cho các hàm ít được sử dụng bằng cách sử dụng giá trị cờ được lưu trữ trong bộ nhớ đệm để phát hiện các sự cố tiềm ẩn trong lần gọi hàm đầu tiên sau khi nâng cấp. Nếu lần gọi này không thành công, mặt phẳng điều khiển sẽ thử lại bằng phiên bản hàm trước đó. Nếu lệnh gọi lại thành công, mặt phẳng điều khiển của Zapier sẽ khởi tạo lệnh khôi phục, giả định rằng lỗi rất có thể là do nâng cấp thời gian chạy. Sau khi khôi phục, nó sẽ ghi lại lỗi và cảnh báo các bên liên quan.\nViệc tích hợp với cơ sở hạ tầng hiện có sử dụng giao diện quản trị và hàng đợi tác vụ để tự động chuyển đổi lưu lượng. Sổ cái cơ sở dữ liệu duy trì việc theo dõi trạng thái chức năng và thông tin khôi phục.\nCác biện pháp kiểm soát vận hành cung cấp khả năng khôi phục thủ công và triển khai các công tắc điều khiển tập trung để quản lý quy trình. Sau khi một chức năng được nâng cấp lên thời gian chạy mới và không phát hiện hoạt động khôi phục nào trong khoảng thời gian đã đặt, một tác vụ cắt tỉa tự động sẽ dọn dẹp các phiên bản cũ hơn.\nCông cụ Lambda canary của Zapier, thông qua việc tích hợp chuyển đổi lưu lượng dần dần, giám sát CloudWatch theo thời gian thực và cơ chế khôi phục tự động, đã thiết lập một khuôn khổ bền vững để quản lý các nâng cấp thời gian chạy trên toàn bộ kiến ​​trúc không máy chủ của họ. Cách tiếp cận này không chỉ tự động hóa quy trình nâng cấp và giảm thiểu rủi ro vận hành mà còn tạo ra một giải pháp có khả năng mở rộng, cung cấp các bản nâng cấp thời gian chạy liên tục, ngăn chặn việc sử dụng các thời gian chạy đã lỗi thời tại bất kỳ thời điểm nào. Bằng cách cho phép cập nhật thời gian chạy hàm liên tục với mức độ gián đoạn tối thiểu đối với trải nghiệm người dùng cuối, Zapier duy trì tính bảo mật và ổn định trong khi yêu cầu can thiệp thủ công tối thiểu. Khung này quản lý hiệu quả cơ sở hạ tầng không máy chủ đang phát triển của họ, mang lại cả tính bảo mật và hiệu quả vận hành cho các bản cập nhật thời gian chạy trong tương lai.\nKết luận Trong bài viết này, bạn đã tìm hiểu cách Zapier thiết kế nền tảng phần mềm dưới dạng dịch vụ (SaaS) của mình để cung cấp môi trường thực thi an toàn, biệt lập bằng AWS Lambda và Amazon EKS, cho phép khách hàng tạo ra hàng trăm nghìn Zap. Bạn đã tìm hiểu cách đội ngũ Zapier triển khai quy trình nâng cấp thời gian chạy hàm trên quy mô lớn và giảm 95% số lượng hàm đang chạy trên các thời gian chạy sắp bị loại bỏ. Bạn đã thấy các phương pháp hay nhất đã được thiết lập và các kỹ thuật giúp Zapier duy trì trạng thái bảo mật cao mà không ảnh hưởng đến trải nghiệm của khách hàng.\nSử dụng các liên kết sau để tìm hiểu thêm về thời gian chạy Lambda và nâng cấp các hàm của bạn lên phiên bản thời gian chạy mới nhất:\nTài liệu về thời gian chạy Lambda Truy xuất dữ liệu về các hàm Lambda sử dụng thời gian chạy đã lỗi thời Quản lý các bản nâng cấp thời gian chạy AWS Lambda trong Blog AWS Compute Các điều khiển quản lý thời gian chạy AWS Lambda trong Blog AWS Compute "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.5-blog5/","title":"Blog 5","tags":[],"description":"","content":"Cách HashiCorp thực hiện chuyển đổi liên vùng liền mạch với Amazon Application Recovery Controller Tác giả: Dmitriy Novikov\nXuất bản: Ngày 25 JUL 2025\nAmazon Application Recovery Controller (ARC), Customer Solutions\nBài viết này được đồng sáng tác bởi Brandon Raabe, Kỹ sư Cao cấp về Độ tin cậy của Site tại HashiCorp.\nTrong các hệ thống đám mây, chỉ vài phút ngừng hoạt động cũng có thể gây ra tác động đáng kể đến hoạt động kinh doanh và làm xói mòn niềm tin của khách hàng. HashiCorp, một công ty hàng đầu về phần mềm tự động hóa cơ sở hạ tầng đa đám mây, đã phải đối mặt với thách thức quan trọng này khi Nền tảng Đám mây HashiCorp (HCP) của họ được mở rộng quy mô để phục vụ khách hàng doanh nghiệp với các yêu cầu nghiêm ngặt về tính khả dụng. Khi sự cố gián đoạn cục bộ đe dọa tính liên tục của dịch vụ, quá trình chuyển đổi dự phòng phức tạp giữa các mục DNS, khối lượng công việc và cơ sở dữ liệu trên khắp các Vùng AWS đã trở thành một quy trình dễ xảy ra lỗi, đòi hỏi sự phối hợp chặt chẽ. Bài viết này ghi lại cách nhóm Kỹ thuật Độ tin cậy Site (SRE) của HashiCorp đã chuyển đổi khả năng phục hồi sau thảm họa bằng cách triển khai Bộ điều khiển Khôi phục Ứng dụng Amazon (ARC), tạo ra một giải pháp không chỉ đơn giản hóa đáng kể việc chuyển đổi dự phòng giữa các Vùng mà còn cung cấp một phương thức chuẩn hóa để truyền tải ngữ cảnh Vùng đến các dịch vụ phân tán của họ.\nTrong bài viết này, chúng tôi thảo luận về hành trình của HashiCorp từ các quy trình chuyển đổi dự phòng thủ công, gây căng thẳng sang phương pháp hợp lý, tự tin, giúp thay đổi căn bản cách họ thực hiện các cam kết về khả năng phục hồi cấp doanh nghiệp.\nThách thức với phục hồi sau thảm họa trong cơ sở hạ tầng đa đám mây Đội ngũ SRE của HashiCorp nhận thấy rằng khi nền tảng đám mây của họ được mở rộng để phục vụ các khối lượng công việc quan trọng của doanh nghiệp, phương pháp phục hồi sau thảm họa của họ cần được nâng cấp. Các quy trình thủ công hiện tại đòi hỏi sự phối hợp chính xác trên nhiều hệ thống trong các tình huống ngừng hoạt động vốn đã căng thẳng, điều này có thể dẫn đến các biến chứng tiềm ẩn khi tốc độ và độ chính xác là yếu tố quan trọng nhất. Sự cố ngừng hoạt động theo khu vực đặt ra những thách thức đặc biệt: nếu các mặt phẳng điều khiển cho các dịch vụ quan trọng không khả dụng, chính các công cụ cần thiết để thực hiện phục hồi có thể không truy cập được.\nARC nổi lên như một giải pháp lý tưởng với kiến ​​trúc độc đáo: một mặt phẳng dữ liệu có tính khả dụng cao có thể truy cập thông qua các điểm cuối trong năm Khu Vực riêng biệt, do đó cơ chế phục hồi vẫn hoạt động ngay cả trong những gián đoạn đáng kể của Khu Vực. Bằng cách sử dụng AWS SDK để giao tiếp với ARC, HashiCorp đã đạt được một số lợi thế quan trọng. Họ có thể áp dụng các phương pháp cơ sở hạ tầng dưới dạng code (IaC) vào quy trình phục hồi sau thảm họa, tự động hóa việc kiểm tra các quy trình chuyển đổi dự phòng và tích hợp khả năng phục hồi liền mạch với các công cụ vận hành hiện có. Giải pháp này đã chuyển đổi quy trình phục hồi sau thảm họa của họ từ một quy trình thủ công chuyên biệt thành một quy trình được mã hóa, có thể lặp lại được tích hợp trong các hoạt động nền tảng của họ.\nYêu cầu và cân nhắc về kiến ​​trúc Sau khi đánh giá nhiều phương pháp phục hồi sau thảm họa, HashiCorp đã thiết lập ba yêu cầu cốt lõi cho giải pháp của mình. Thứ nhất, trong khi vẫn duy trì sự phán đoán của con người khi khởi tạo chuyển đổi dự phòng, quá trình thực thi cần được tiến hành mà không cần sự can thiệp bổ sung của người vận hành sau khi nó được kích hoạt. Thiết kế vòng lặp con người này bảo toàn việc ra quyết định có chủ đích, đồng thời giảm thiểu các bước thủ công dễ xảy ra lỗi trong quá trình triển khai.\nThứ hai, kiến ​​trúc cần có khả năng phục hồi vượt trội trước chính những lỗi mà nó được thiết kế để giảm thiểu. Các giải pháp chuyển đổi dự phòng DNS truyền thống bộc lộ một lỗ hổng nghiêm trọng: sự phụ thuộc vào các mặt phẳng điều khiển Vùng đơn lẻ có thể không khả dụng trong thời gian ngừng hoạt động. ARC đã giải quyết vấn đề này thông qua kiến ​​trúc phân tán, kết nối Amazon Route 53 với một cơ chế điều khiển linh hoạt, được kích hoạt bởi các kiểm tra tình trạng Route 53, có thể truy cập thông qua nhiều điểm cuối Vùng. Điều này có nghĩa là bản thân hệ thống chuyển đổi dự phòng vẫn khả dụng ngay cả khi Vùng chính ngừng hoạt động.\nThứ ba, giải pháp cần đáp ứng hoặc vượt quá các chỉ số Mục tiêu Điểm Phục hồi (RPO) và Mục tiêu Thời gian Phục hồi (RTO) hiện có của HashiCorp - ngưỡng mất dữ liệu và thời gian ngừng hoạt động tối đa có thể chấp nhận được. Sử dụng ARC, nhóm SRE đã lên kế hoạch không chỉ đạt được các mục tiêu này mà còn tạo ra những cải tiến đáng kể, giảm thiểu tác động tiềm ẩn đến khách hàng trong các sự kiện Khu vực và củng cố khả năng phục hồi cấp doanh nghiệp của HashiCorp.\nTổng quan về giải pháp Để chuyển đổi tư thế phục hồi sau thảm họa, nhóm SRE của HashiCorp đã thiết kế một kiến ​​trúc tập trung vào ARC và được bổ sung bởi một dịch vụ điều phối được xây dựng riêng. Kiến trúc này kết nối liền mạch quyết định khởi tạo chuyển đổi dự phòng của con người với các hoạt động kỹ thuật phức tạp cần thiết để chuyển đổi lưu lượng giữa các Khu vực với sự gián đoạn tối thiểu.\nTrọng tâm của giải pháp là một dịch vụ chuyển đổi dự phòng tùy chỉnh, đóng vai trò là lớp điều phối cho các chuyển đổi Khu vực. Dịch vụ này duy trì chi tiết cấu hình cho cụm ARC và cung cấp một giao diện duy nhất, được kiểm soát để khởi tạo các chuyển đổi Khu vực. Khi được kích hoạt, dịch vụ sẽ thiết lập kết nối an toàn đến các điểm cuối API ARC và thực hiện quy trình làm việc hai bước: đầu tiên là vô hiệu hóa các điều khiển định tuyến cho Khu vực chính, sau đó bật các điều khiển đó cho Khu vực phụ. Cách tiếp cận tuần tự này cung cấp một quá trình chuyển đổi lưu lượng sạch mà không có các tình huống phân chia bộ não hoặc mất kết nối.\nKiến trúc DNS đã trải qua một quá trình phát triển chiến lược để hỗ trợ khả năng mới này. HashiCorp đã cấu hình lại các điểm cuối đầu vào quan trọng của họ thành các cặp bản ghi dự phòng Route 53, mỗi cặp bao gồm một bản ghi chính và một bản ghi phụ. Mỗi bản ghi được liên kết với một kiểm tra tình trạng để theo dõi trạng thái của một điều khiển định tuyến ARC—kết nối hiệu quả dịch vụ DNS toàn cầu của AWS với điều khiển định tuyến ARC. Các bản ghi chính phân giải đến các điểm cuối trong Vùng chính, và các bản ghi phụ trỏ đến cơ sở hạ tầng tương ứng trong Vùng dự phòng. Khi các điều khiển định tuyến thay đổi trạng thái, các kiểm tra tình trạng liên quan sẽ tự động kích hoạt Route 53 để điều chỉnh các mẫu phân giải DNS, chuyển hướng lưu lượng đến cơ sở hạ tầng Vùng phù hợp.\nHashiCorp duy trì Vùng phụ của mình ở cấu hình dự phòng ấm, với các dịch vụ thiết yếu đang chạy nhưng không chủ động phục vụ lưu lượng máy khách cho đến khi xảy ra sự kiện chuyển đổi dự phòng. Để đảm bảo nhận thức liền mạch về trạng thái Vùng trên toàn hệ thống phân tán, nhóm đã triển khai cơ chế báo hiệu sử dụng các bản ghi DNS TXT được thiết kế đặc biệt. Các bản ghi này được liên kết với cùng các điều khiển định tuyến ARC như các điểm cuối dịch vụ chính, tạo ra một chỉ báo trạng thái toàn cầu có thể khám phá. Các dịch vụ có thể truy vấn các bản ghi TXT này để xác định động Vùng hiện đang hoạt động và điều chỉnh định tuyến nội bộ, sao chép và hành vi vận hành của chúng cho phù hợp — giảm nhu cầu về một hệ thống phân phối cấu hình riêng biệt và đảm bảo tất cả các thành phần đều có cái nhìn nhất quán về trạng thái hiện tại của Vùng.\nSơ đồ sau minh họa quy trình phục hồi sau thảm họa.\n*Image 1. *\nKiến trúc này kết hợp sự giám sát của con người để khởi tạo các chuyển đổi khu vực quan trọng với việc thực thi hoàn toàn tự động sau khi quyết định được đưa ra. Việc sử dụng mặt phẳng điều khiển phân tán toàn cầu của ARC loại bỏ các phụ thuộc vào một khu vực duy nhất, nếu không có thể gây ảnh hưởng đến cơ chế chuyển đổi dự phòng trong trường hợp mất điện khu vực.\nKhung quyết định vận hành cho chuyển đổi dự phòng khu vực Quy trình chuyển đổi dự phòng khu vực của HashiCorp cân bằng giữa việc giám sát tự động với việc ra quyết định có chủ đích của con người. Nền tảng quan sát toàn diện của họ liên tục theo dõi tình trạng của khu vực, tự động cảnh báo nhóm ứng phó sự cố khi phát hiện bất thường. Khi cảnh báo được kích hoạt, giao thức quản lý sự cố sẽ được kích hoạt, với một chỉ huy sự cố nhanh chóng tập hợp các chuyên gia để đánh giá tình hình.\nNhóm tuân theo một khung đánh giá có cấu trúc để xác định xem việc chuyển đổi dự phòng có cần thiết hay không: xác nhận sự cố là đặc thù của khu vực, xác minh rằng các thành phần dự phòng trong khu vực không thể giảm thiểu sự cố và đánh giá xem thời gian phục hồi dự kiến ​​của khu vực có vượt quá ngưỡng tác động chấp nhận được của khách hàng hay không. Cách tiếp cận này ngăn chặn các chuyển đổi khu vực không cần thiết đồng thời cung cấp hành động nhanh chóng khi thực sự cần thiết.\nSau khi quyết định chuyển đổi dự phòng được đưa ra, một nhà điều hành được ủy quyền sẽ khởi tạo quy trình thông qua một lệnh gọi API duy nhất đến dịch vụ điều phối của họ, sau đó dịch vụ này sẽ giao tiếp với ARC để thực hiện chuỗi thay đổi điều khiển định tuyến phức tạp. Thiết kế này bảo toàn sự phán đoán của con người trong các quyết định quan trọng, đồng thời sử dụng tự động hóa để thực hiện chính xác, nhờ đó HashiCorp có thể phản ứng một cách tự tin và nhất quán trong các tình huống mất điện cục bộ áp lực cao.\nKiểm thử phục hồi sau thảm họa HashiCorp duy trì khả năng sẵn sàng hoạt động thông qua chương trình kiểm thử phục hồi sau thảm họa hàng tháng được tổ chức bài bản trong môi trường tích hợp của họ. Một tuần trước mỗi bài kiểm tra theo lịch trình, nhóm sẽ thông báo cho tất cả các bên liên quan để xác nhận nhận thức và sự tham gia của toàn bộ tổ chức. Vào ngày kiểm tra, họ tuân thủ các giao thức sự cố chính thức, tạo ra các kênh liên lạc chuyên dụng để quan sát và cộng tác minh bạch.\nViệc thực hiện kiểm thử phản ánh quy trình chuyển đổi dự phòng sản xuất của họ: người vận hành khởi tạo chuỗi phục hồi thông qua API của họ, kích hoạt các điều khiển định tuyến ARC để chuyển lưu lượng sang Vùng thứ cấp. Điểm khác biệt của phương pháp tiếp cận của HashiCorp là phương pháp xác thực toàn diện. Nhóm kiểm thử xác minh các dịch vụ quan trọng trong Vùng thứ cấp và sau đó chuyển đổi dự phòng trở lại Vùng chính với xác thực tiếp theo. Kiểm thử hai chiều này xác nhận cả quy trình chuyển đổi dự phòng và quay lại dự phòng đều hoạt động đáng tin cậy.\nMỗi bài tập kết thúc bằng một cuộc hồi cứu có cấu trúc, trong đó nhóm ghi lại các quan sát và xác định các cơ hội cải tiến. Bằng cách coi những bài kiểm tra này là kinh nghiệm học tập hơn là các hoạt động tuân thủ, HashiCorp đã thiết lập một chu trình cải tiến liên tục cho khả năng phục hồi sau thảm họa của họ. Những hiểu biết sâu sắc từ các cuộc tập trận thường xuyên này đã dẫn đến nhiều cải tiến trong việc triển khai ARC và quy trình vận hành, do đó nhóm của họ có thể phản ứng tự tin trong các sự cố mất điện thực tế bằng các quy trình đã được thực hành và có thể dự đoán được.\nKết luận Sự ​​hợp tác giữa HashiCorp và AWS thông qua ARC đã cách mạng hóa khả năng phục hồi sau thảm họa của HashiCorp. Việc chuyển đổi khu vực trước đây đòi hỏi việc thao tác bản ghi DNS cẩn thận bởi các nhà điều hành chuyên biệt giờ đây được thực hiện thông qua một lệnh gọi API duy nhất, với việc chuyển đổi lưu lượng trong vòng vài giây và việc truyền tải hoàn tất trong khoảng 2 phút. Sự đơn giản hóa đáng kể này, đạt được nhờ tích hợp kiến ​​trúc ARC linh hoạt với dịch vụ điều phối tùy chỉnh của HashiCorp, không chỉ cải thiện các chỉ số phục hồi mà còn củng cố các cam kết về khả năng phục hồi cấp doanh nghiệp của họ.\nARC đã giải quyết một thách thức cơ bản của hệ thống phân tán bằng cách cung cấp một cơ chế đáng tin cậy để các dịch vụ xác định Khu vực đang hoạt động. Bằng cách liên kết các điều khiển định tuyến ARC với các bản ghi TXT chuyên biệt, HashiCorp đã tạo ra một chỉ báo toàn cầu nhất quán cho phép các dịch vụ tự động điều chỉnh hành vi của chúng mà không cần các hệ thống điều phối bổ sung—đơn giản hóa kiến ​​trúc và giảm sự phụ thuộc.\nQuan trọng nhất, việc triển khai này đã dân chủ hóa khả năng phục hồi sau thảm họa trong HashiCorp, chuyển đổi nó từ một khả năng chuyên biệt thành một quy trình chuẩn hóa có thể thực thi thông qua việc luân phiên trực thường xuyên. Các điểm cuối có tính khả dụng cao của giải pháp trên nhiều Khu vực đảm bảo cơ chế phục hồi vẫn hoạt động ngay cả trong những sự cố ngừng hoạt động nghiêm trọng - giải quyết một lỗ hổng nghiêm trọng trong phương pháp tiếp cận trước đây của họ.\nĐối với khách hàng doanh nghiệp của HashiCorp, những cải tiến này chuyển trực tiếp thành giá trị kinh doanh: giảm thời gian phục hồi trong các sự kiện Khu vực, tăng cường sự tự tin vận hành và đảm bảo rằng các công cụ quản lý cơ sở hạ tầng quan trọng của họ sẽ luôn khả dụng ngay cả trong những sự cố gián đoạn đám mây lớn. Khi HashiCorp tiếp tục tinh chỉnh phương pháp tiếp cận của mình thông qua thử nghiệm nghiêm ngặt và cải tiến liên tục, việc triển khai ARC của họ chứng minh cách phục hồi thảm họa được thiết kế chu đáo có thể phát triển từ một chính sách bảo hiểm đơn thuần thành một lợi thế cạnh tranh chiến lược.\nĐể tìm hiểu thêm, hãy truy cập Amazon Application Recovery Controller, AWS Multi-Region Capabilities và AWS Multi-Region Fundamentals.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.6-blog6/","title":"Blog 5","tags":[],"description":"","content":"Triển khai ưu tiên tin nhắn với hàng đợi số lượng trên Amazon MQ cho RabbitMQ Tác giả: Akhil Melakunta và Vinodh Kannan Sadayamuthu\nXuất bản: Ngày 23 tháng 07 năm 2025\nAdvanced (300), Amazon MQ, Serverless, Technical How-to\nHàng đợi Quorum hiện đã có sẵn trên Amazon MQ for RabbitMQ từ phiên bản 3.13. Hàng đợi Quorum là loại hàng đợi FIFO (First-In, First-Out) được sao chép, sử dụng Raft Consensus Algorithm để duy trì tính nhất quán của dữ liệu. Hàng đợi Quorum trên RabbitMQ phiên bản 3.13 thiếu một tính năng chính so với hàng đợi cổ điển: ưu tiên tin nhắn. Tuy nhiên, RabbitMQ phiên bản 4.0 đã hỗ trợ tính năng ưu tiên tin nhắn, hoạt động khác với các ưu tiên tin nhắn của hàng đợi cổ điển. Việc di chuyển các ứng dụng từ hàng đợi cổ điển với ưu tiên tin nhắn sang hàng đợi Quorum trên Amazon MQ for RabbitMQ đặt ra nhiều thách thức cho khách hàng. Bài viết này mô tả các phương pháp khác nhau để triển khai tính năng ưu tiên tin nhắn trong hàng đợi Quorum trên Amazon MQ for RabbitMQ. Amazon MQ là dịch vụ môi giới tin nhắn được quản lý dành cho Apache ActiveMQ và RabbitMQ, giúp đơn giản hóa việc thiết lập và vận hành các môi giới tin nhắn trên AWS.\nTại sao việc ưu tiên tin nhắn lại quan trọng Các hệ thống nhắn tin hiện đại yêu cầu xử lý tin nhắn khác nhau, tùy thuộc vào mức độ ưu tiên của doanh nghiệp. Một số tin nhắn nhạy cảm về thời gian hoặc quan trọng hơn những tin nhắn khác, và việc ưu tiên chúng có thể nâng cao hiệu quả và khả năng phản hồi của các ứng dụng. Việc ưu tiên tin nhắn cho phép một số tin nhắn nhất định được xử lý trước những tin nhắn khác, phù hợp với các ưu tiên của doanh nghiệp và giúp đảm bảo rằng các tin nhắn có giá trị cao hoặc quan trọng về thời gian nhận được sự chú ý cần thiết. Việc ưu tiên tin nhắn giải quyết những thách thức kinh doanh quan trọng trong nhiều ngành. Tại các công ty bảo hiểm, việc này có thể đẩy nhanh quá trình xử lý yêu cầu bồi thường khẩn cấp bằng cách ưu tiên các tin nhắn có mức độ ưu tiên cao hơn các bản cập nhật chính sách định kỳ, giảm thời gian giải quyết. Các nhà sản xuất ô tô có thể đảm bảo rằng các cảnh báo quan trọng trên dây chuyền sản xuất và thông báo an toàn được ưu tiên hơn dữ liệu đo từ xa tiêu chuẩn, ngăn ngừa thời gian ngừng hoạt động tốn kém. Các công ty điện lực có thể ưu tiên các cảnh báo về sự ổn định lưới điện theo thời gian thực và thông báo mất điện, cho phép phản hồi nhanh hơn đối với các sự cố mất điện tiềm ẩn. Bằng cách triển khai ưu tiên tin nhắn, các ngành có thể tập trung sự chú ý ngay lập tức vào các hoạt động nhạy cảm về thời gian, đồng thời quản lý hiệu quả các quy trình thường xuyên trong cơ sở hạ tầng hiện có. Bằng cách sử dụng phương pháp này để chuyển đổi chiến lược truyền thông, các tổ chức có thể phản ứng nhanh chóng và hiệu quả hơn với các sự kiện quan trọng.\nSo sánh mức độ ưu tiên tin nhắn của hàng đợi cổ điển và hàng đợi quorum Trong phần này, hãy khám phá những khác biệt cơ bản giữa hàng đợi cổ điển và hàng đợi quorum về khả năng ưu tiên tin nhắn. Xem xét cách mỗi loại hàng đợi xử lý mức độ ưu tiên tin nhắn, các tính năng tích hợp sẵn và các cân nhắc chính.\nƯu tiên tin nhắn với hàng đợi cổ điển Trong hàng đợi cổ điển, RabbitMQ hỗ trợ mức độ ưu tiên tin nhắn từ 1 đến 255, với 1 là mức độ ưu tiên thấp nhất và 255 là mức độ ưu tiên cao nhất. Tuy nhiên, thường nên sử dụng phạm vi nhỏ hơn (ví dụ: 1–5) để có hiệu suất tốt hơn, vì RabbitMQ cần duy trì một hàng đợi con nội bộ cho mỗi mức độ ưu tiên từ 1 đến giá trị tối đa được cấu hình cho một hàng đợi nhất định. Phạm vi ưu tiên rộng hơn sẽ làm tăng chi phí CPU và bộ nhớ, điều này có thể ảnh hưởng đến hiệu suất của broker. Hành vi hàng đợi ưu tiên trong hàng đợi cổ điển:\nHàng đợi cổ điển yêu cầu tham số x-max-priority để xác định số lượng ưu tiên tối đa cho một hàng đợi nhất định Một thủ tục gửi một thông điệp với giá trị thuộc tính ưu tiên Người dùng không cần cấu hình đặc biệt để xử lý các mức ưu tiên Các thông điệp có mức ưu tiên cao hơn sẽ được gửi trước các thông điệp có mức ưu tiên thấp hơn Trong cùng một mức ưu tiên, các thông điệp được gửi theo thứ tự FIFO Các thông điệp không có thuộc tính ưu tiên được coi là có mức ưu tiên thấp nhất Các thông điệp có mức ưu tiên cao hơn mức tối đa của hàng đợi được coi là có mức ưu tiên cao nhất *Hình 1. *\nVí dụ code Python cho thực thi hàng đợi cổ điển với ưu tiên tin nhắn:\n#!/usr/bin/env python import pika import ssl # Set up SSL context for secure connection context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2) # Define credentials credentials = pika.PlainCredentials(\u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;) # Replace with actual credentials # Set up connection parameters for Amazon MQ RabbitMQ broker connection_parameters = pika.ConnectionParameters( host=\u0026#39;b-example.mq.us-west-2.on.aws\u0026#39;, # Replace with actual broker endpoint port=5671, credentials=credentials, ssl_options=pika.SSLOptions(context) ) # Establish connection and create a channel connection = pika.BlockingConnection(connection_parameters) channel = connection.channel() # Declare a direct exchange # - direct exchanges route messages based on routing key channel.exchange_declare( exchange=\u0026#39;priority_exchange\u0026#39;, exchange_type=\u0026#39;direct\u0026#39;, ) # Declare a priority queue # - x-max-priority=5 sets maximum priority level (0-5) # - x-queue-type=classic specifies classic queue implementation channel.queue_declare( queue=\u0026#39;classic_priority_queue\u0026#39;, arguments={ \u0026#39;x-max-priority\u0026#39;: 5, \u0026#39;x-queue-type\u0026#39;: \u0026#34;classic\u0026#34; } ) # Bind queue to exchange with routing key # - This connects the queue to the exchange # - Messages sent to the exchange with matching routing key will be routed to this queue channel.queue_bind( queue=\u0026#39;classic_priority_queue\u0026#39;, exchange=\u0026#39;priority_exchange\u0026#39;, routing_key=\u0026#39;priority_queue\u0026#39; ) # Publish messages with different priorities # Low priority message (priority=1) channel.basic_publish( exchange=\u0026#39;priority_exchange\u0026#39;, routing_key=\u0026#39;priority_queue\u0026#39;, body=\u0026#39;Low priority message\u0026#39;, properties=pika.BasicProperties(priority=1) ) print(\u0026#34; [x] Sent \u0026#39;Low priority message\u0026#39;\u0026#34;) # Medium priority message (priority=2) channel.basic_publish( exchange=\u0026#39;priority_exchange\u0026#39;, routing_key=\u0026#39;priority_queue\u0026#39;, body=\u0026#39;Medium priority message\u0026#39;, properties=pika.BasicProperties(priority=2) ) print(\u0026#34; [x] Sent \u0026#39;Medium priority message\u0026#39;\u0026#34;) # High priority message (priority=5) channel.basic_publish( exchange=\u0026#39;priority_exchange\u0026#39;, routing_key=\u0026#39;priority_queue\u0026#39;, body=\u0026#39;High priority message\u0026#39;, properties=pika.BasicProperties(priority=5) ) print(\u0026#34; [x] Sent \u0026#39;High priority message\u0026#39;\u0026#34;) # Close the connection connection.close() Đoạn mã trên minh họa việc ưu tiên tin nhắn trong RabbitMQ sử dụng hàng đợi cổ điển với cơ chế xử lý ưu tiên tích hợp sẵn. Việc triển khai kết nối với một broker RabbitMQ bằng thư viện Python Pika và khai báo một trao đổi trực tiếp, một hàng đợi cổ điển với mức ưu tiên tối đa là 5. Tin nhắn sau đó được xuất bản vào hàng đợi duy nhất này với các giá trị ưu tiên được chỉ định rõ ràng (1 cho mức thấp, 2 cho mức trung bình và 5 cho mức ưu tiên cao). Khi người dùng truy xuất tin nhắn từ hàng đợi này, RabbitMQ sẽ gửi các tin nhắn có mức ưu tiên cao hơn trước.\nƯu tiên tin nhắn với hàng đợi Quorum Không giống như hàng đợi cổ điển, hàng đợi Quorum trong Rabbit MQ 3.13 không hỗ trợ ưu tiên tin nhắn gốc. Tuy nhiên, có những mô hình hiệu quả mà bạn có thể triển khai để đạt được mức độ ưu tiên tin nhắn với hàng đợi Quorum.\nSử dụng các hàng đợi riêng biệt cho các mức độ ưu tiên khác nhau Một phương pháp đơn giản là tạo nhiều hàng đợi Quorum, mỗi hàng đợi dành riêng cho các mức độ ưu tiên khác nhau. Ví dụ: bạn có thể có một hàng đợi có mức độ ưu tiên cao và một hàng đợi có mức độ ưu tiên thấp. Sử dụng RabbitMQ để trao đổi và liên kết các khóa định tuyến tin nhắn đến các hàng đợi thích hợp dựa trên mức độ ưu tiên của chúng, cho phép hệ thống xử lý các tin nhắn có mức độ ưu tiên cao nhanh hơn, như được hiển thị trong hình sau.\n*Hình 2. *\nVí dụ để triển khai xử lý mức độ ưu tiên bằng cách sử dụng hàng đợi quorum riêng biệt:\n#!/usr/bin/env python import pika import ssl # Set up SSL context for secure connection context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2) # Define credentials credentials = pika.PlainCredentials(\u0026#39;username\u0026#39;, \u0026#39;password\u0026#39;) #Replace with actual credentials # Set up connection parameters for Amazon MQ RabbitMQ broker connection_parameters = pika.ConnectionParameters( host=\u0026#39;b-example.mq.us-west-2.on.aws\u0026#39;, port=5671, credentials=credentials, ssl_options=pika.SSLOptions(context) ) # Establish connection and create a channel connection = pika.BlockingConnection(connection_parameters) channel = connection.channel() # Declare a direct exchange # - Direct exchanges route messages based on routing key channel.exchange_declare( exchange=\u0026#39;priority_exchange_qq\u0026#39;, exchange_type=\u0026#39;direct\u0026#39; ) # Create separate quorum queues for different priority levels # Low priority queue channel.queue_declare( queue=\u0026#39;low_priority_queue\u0026#39;, durable=True, arguments={ \u0026#39;x-queue-type\u0026#39;: \u0026#34;quorum\u0026#34; } ) # Bind the low priority queue to the exchange with a specific routing key # - This creates a rule that messages sent to \u0026#39;priority_exchange\u0026#39; with routing_key=\u0026#39;low_priority_1\u0026#39; # - will be routed to the \u0026#39;low_priority_queue\u0026#39; channel.queue_bind( queue=\u0026#39;low_priority_queue\u0026#39;, exchange=\u0026#39;priority_exchange_qq\u0026#39;, routing_key=\u0026#39;low_priority_1\u0026#39; ) # Medium priority queue channel.queue_declare( queue=\u0026#39;medium_priority_queue\u0026#39;, durable=True, arguments={ \u0026#39;x-queue-type\u0026#39;: \u0026#34;quorum\u0026#34; } ) # Bind the medium priority queue to the exchange with a specific routing key # - Messages with routing_key=\u0026#39;medium_priority_2\u0026#39; will be directed to the \u0026#39;medium_priority_queue\u0026#39; channel.queue_bind( queue=\u0026#39;medium_priority_queue\u0026#39;, exchange=\u0026#39;priority_exchange_qq\u0026#39;, routing_key=\u0026#39;medium_priority_2\u0026#39; ) # High priority queue channel.queue_declare( queue=\u0026#39;high_priority_queue\u0026#39;, durable=True, arguments={ \u0026#39;x-queue-type\u0026#39;: \u0026#34;quorum\u0026#34; } ) # Bind the high priority queue to the exchange with a specific routing key # - Messages with routing_key=\u0026#39;high_priority_2\u0026#39; will be directed to the \u0026#39;high_priority_queue\u0026#39; channel.queue_bind( queue=\u0026#39;high_priority_queue\u0026#39;, exchange=\u0026#39;priority_exchange_qq\u0026#39;, routing_key=\u0026#39;high_priority_5\u0026#39; ) # Publish messages to different priority queues print(\u0026#34; [x] Publishing messages to different priority queues\u0026#34;) # Low priority message channel.basic_publish( exchange=\u0026#39;priority_exchange_qq\u0026#39;, routing_key=\u0026#39;low_priority_1\u0026#39;, body=\u0026#39;Low priority message\u0026#39; ) print(\u0026#34; [x] Sent \u0026#39;Low priority message\u0026#39;\u0026#34;) # Medium priority message channel.basic_publish( exchange=\u0026#39;priority_exchange_qq\u0026#39;, routing_key=\u0026#39;medium_priority_2\u0026#39;, body=\u0026#39;Medium priority message\u0026#39; ) print(\u0026#34; [x] Sent \u0026#39;Medium priority message\u0026#39;\u0026#34;) # High priority message channel.basic_publish( exchange=\u0026#39;priority_exchange_qq\u0026#39;, routing_key=\u0026#39;high_priority_5\u0026#39;, body=\u0026#39;High priority message\u0026#39; ) print(\u0026#34; [x] Sent \u0026#39;High priority message\u0026#39;\u0026#34;) # Close the connection connection.close() print(\u0026#34; [x] Connection closed\u0026#34;) Đoạn mã trên minh họa phương pháp ưu tiên tin nhắn trong RabbitMQ bằng cách sử dụng các hàng đợi quorum riêng biệt cho các mức độ ưu tiên khác nhau (thấp, trung bình và cao). Việc triển khai sử dụng thư viện Python Pika để kết nối với máy chủ RabbitMQ, một trao đổi trực tiếp và ba hàng đợi quorum riêng biệt cho các mức độ ưu tiên khác nhau, đồng thời xuất bản tin nhắn đến các khóa định tuyến khác nhau với mức độ ưu tiên khác nhau.\nLogic ưu tiên tùy chỉnh trên consumer Triển khai logic tùy chỉnh trong ứng dụng của bạn để xử lý tin nhắn dựa trên mức độ ưu tiên của chúng. Ví dụ: bạn có thể sử dụng tiêu đề hoặc siêu dữ liệu để xác định mức độ ưu tiên của tin nhắn, sau đó sử dụng thông tin này để định tuyến tin nhắn đến các hàng đợi khác nhau hoặc xử lý chúng theo một thứ tự cụ thể. Hàng đợi có mức độ ưu tiên cao hơn nên sử dụng nhiều consumer hơn hoặc consumer có tài nguyên được phân bổ cao hơn để xử lý tin nhắn nhanh hơn so với hàng đợi có mức độ ưu tiên thấp hơn. Sử dụng phương thức basic.qos (prefetch) ở chế độ xác nhận thủ công trên consumer của bạn để giới hạn số lượng tin nhắn có thể được gửi đi bất cứ lúc nào và cho phép ưu tiên tin nhắn. basic.qos là một giá trị mà consumer thiết lập khi kết nối với hàng đợi. Giá trị này cho biết số lượng tin nhắn mà consumer có thể xử lý cùng một lúc. Phương pháp này được thể hiện ở hình sau.\n*Hình 3. *\nLưu ý: Giải pháp này triển khai ưu tiên tin nhắn theo cơ chế nỗ lực tối đa. Có khả năng các tin nhắn có mức độ ưu tiên thấp và trung bình sẽ được xử lý trước các tin nhắn có mức độ ưu tiên cao.\nKết luận Việc ưu tiên tin nhắn trong RabbitMQ broker trên Amazon MQ có những cân nhắc khác nhau đối với hàng đợi cổ điển và hàng đợi quorum. Việc sử dụng hàng đợi quorum đòi hỏi một cách tiếp cận thận trọng do RabbitMQ thiếu hỗ trợ gốc cho việc ưu tiên tin nhắn. Bằng cách sử dụng các hàng đợi riêng biệt và logic tùy chỉnh, bạn có thể đạt được mức độ ưu tiên hiệu quả trong khi vẫn duy trì tính khả dụng cao và tính nhất quán mà hàng đợi quorum mang lại. Hãy áp dụng các chiến lược này để tối ưu hóa cơ sở hạ tầng nhắn tin, nâng cao khả năng phản hồi của ứng dụng và đảm bảo các tin nhắn quan trọng được xử lý kịp thời. Chúng tôi khuyên bạn nên sử dụng hàng đợi quorum làm loại hàng đợi sao chép ưu tiên trên các broker RabbitMQ 3.13. Để biết thêm chi tiết, hãy xem tài liệu Amazon MQ. Để biết thêm thông tin, hãy xem hàng đợi quorum. Để tìm hiểu thêm, hãy xem Amazon MQ dành cho Rabbit MQ.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.7-blog7/","title":"Blog 7","tags":[],"description":"","content":"Tối ưu hóa quy trình làm việc Serverless trên AWS: Từ AWS Lambda orchestration đến AWS Step Functions Bài đăng trên blog này thảo luận về AWS Lambda với tư cách là mẫu chống điều phối và cách thiết kế lại các giải pháp serverless bằng cách sử dụng AWS Step Functions với tích hợp gốc.\nStep Functions là dịch vụ quy trình làm việc không có máy chủ mà bạn có thể sử dụng để xây dựng các ứng dụng phân tán, tự động hóa quy trình, điều phối các dịch vụ vi mô cũng như tạo đường dẫn dữ liệu và máy học (ML). Step Functions cung cấp khả năng tích hợp gốc với hơn 200 dịch vụ AWS bên cạnh các API bên ngoài của bên thứ ba. Bạn có thể sử dụng các tiện ích tích hợp này để triển khai các giải pháp sẵn sàng sản xuất với ít nỗ lực hơn, giảm độ phức tạp của mã, cải thiện khả năng bảo trì lâu dài và giảm thiểu nợ kỹ thuật khi vận hành ở quy mô lớn.\nThe Lambda as orchestrator anti-pattern Hãy cùng xem xét một anti-pattern phổ biến: sử dụng một Lambda function như một orchestrator để phân phối thông điệp qua nhiều kênh khác nhau. Hãy tưởng tượng tình huống thực tế sau đây — một hệ thống cần gửi thông báo (notifications) thông qua SMS hoặc email tùy theo user preferences, như được minh họa trong sơ đồ sau.\nCác ví dụ về tải trọng cho kịch bản này là:\nChỉ gửi SMS: { \u0026#34;body\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;sms\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Hello from AWS Lambda!\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;+1234567890\u0026#34;, \u0026#34;metadata\u0026#34;: { \u0026#34;priority\u0026#34;: \u0026#34;high\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;notification\u0026#34; } } } Chỉ gửi email: { \u0026#34;body\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Hello from AWS Lambda!\u0026#34;, \u0026#34;email\u0026#34;: { \u0026#34;to\u0026#34;: \u0026#34;recipient@example.com\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;Test Notification\u0026#34;, \u0026#34;from\u0026#34;: \u0026#34;sender@example.com\u0026#34; }, \u0026#34;metadata\u0026#34;: { \u0026#34;priority\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;notification\u0026#34; } } } Gửi cả SMS và email: { \u0026#34;body\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;both\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Hello from AWS Lambda!\u0026#34;, \u0026#34;phoneNumber\u0026#34;: \u0026#34;+1234567890\u0026#34;, \u0026#34;email\u0026#34;: { \u0026#34;to\u0026#34;: \u0026#34;recipient@example.com\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;Test Notification\u0026#34;, \u0026#34;from\u0026#34;: \u0026#34;sender@example.com\u0026#34; }, \u0026#34;metadata\u0026#34;: { \u0026#34;priority\u0026#34;: \u0026#34;high\u0026#34;, \u0026#34;category\u0026#34;: \u0026#34;notification\u0026#34; } } } Đây là cách nó thường bắt đầu - với hàm Lambda đóng vai trò là người điều phối:\nimport boto3 import json # Initialize Lambda client # You can specify region if needed: boto3.client(\u0026#39;lambda\u0026#39;, region_name=\u0026#39;us-east-1\u0026#39;) lambda_client = boto3.client(\u0026#39;lambda\u0026#39;) def lambda_handler(event, context): try: # Parse the incoming event body = json.loads(event[\u0026#39;body\u0026#39;]) # Validate required fields if \u0026#39;channel\u0026#39; not in body: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Missing channel parameter\u0026#39;) } if \u0026#39;message\u0026#39; not in body: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Missing message content\u0026#39;) } if body[\u0026#39;channel\u0026#39;] == \u0026#39;both\u0026#39;: # Invoke SMS Lambda function lambda_client.invoke( FunctionName=\u0026#39;send-sns\u0026#39;, InvocationType=\u0026#39;Event\u0026#39;, Payload=json.dumps(body) ) # Invoke Email Lambda function lambda_client.invoke( FunctionName=\u0026#39;send-email\u0026#39;, InvocationType=\u0026#39;Event\u0026#39;, Payload=json.dumps(body) ) else: # Validate channel value if body[\u0026#39;channel\u0026#39;] not in [\u0026#39;sms\u0026#39;, \u0026#39;email\u0026#39;]: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Invalid channel specified\u0026#39;) } # Invoke function based on specified channel function_name = \u0026#39;send-sns\u0026#39; if body[\u0026#39;channel\u0026#39;] == \u0026#39;sms\u0026#39; else \u0026#39;send-email\u0026#39; lambda_client.invoke( FunctionName=function_name, InvocationType=\u0026#39;Event\u0026#39;, Payload=json.dumps(body) ) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Messages sent successfully\u0026#39;) } except json.JSONDecodeError: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;Invalid JSON in request body\u0026#39;) } except Exception as e: return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;body\u0026#39;: json.dumps(f\u0026#39;Error: {str(e)}\u0026#39;) } Cách tiếp cận này có các vấn đề sau:\nComplex error handling: Orchestrator cần quản lý lỗi từ nhiều lần gọi function khác nhau. Tight coupling: Các function phụ thuộc trực tiếp vào nhau. Limited execution time: Orchestrator Lambda function tiếp tục chạy trong khi các sub Lambda function đang thực thi. Điều này có thể dẫn đến việc orchestrator Lambda function bị timeout. Idle resources: Bởi vì orchestrator Lambda function đang ở trạng thái nhàn rỗi trong khi chờ kết quả trả về từ các Lambda function khác, trong trường hợp này, người dùng phải trả tiền cho tài nguyên không hoạt động. Rearchitecting with Step Functions Bạn có thể xây dựng lại logic bằng cách sử dụng Step Functions và Amazon States Language để thay thế Lambda orchestrator function. Bạn có thể sử dụng Choice state trong Amazon States Language để xác định các điều kiện logic nhằm theo một nhánh cụ thể. Cách tiếp cận này giúp giảm độ phức tạp trong việc bảo trì code vì bạn định nghĩa các điều kiện bằng Amazon States Language. Bạn cũng có thể sử dụng nó để mở rộng chức năng với các thay đổi tối thiểu trong codebase.\nSơ đồ workflow Step Functions sau đây minh họa phiên bản được thiết kế lại của Orchestrator Lambda function trước đó:\nNgôn ngữ trạng thái Amazon sau đây thể hiện quy trình làm việc:\n{ \u0026#34;Comment\u0026#34;: \u0026#34;Multi-channel notification workflow\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;ValidateInput\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;ValidateInput\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;And\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.message\u0026#34;, \u0026#34;IsPresent\u0026#34;: true }, { \u0026#34;Variable\u0026#34;: \u0026#34;$.channel\u0026#34;, \u0026#34;IsPresent\u0026#34;: true } ], \u0026#34;Next\u0026#34;: \u0026#34;DetermineChannel\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ValidationError\u0026#34; }, \u0026#34;ValidationError\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Fail\u0026#34;, \u0026#34;Error\u0026#34;: \u0026#34;ValidationError\u0026#34;, \u0026#34;Cause\u0026#34;: \u0026#34;Required fields missing: message and/or channel\u0026#34; }, \u0026#34;DetermineChannel\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.channel\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;both\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParallelNotification\u0026#34; }, { \u0026#34;Variable\u0026#34;: \u0026#34;$.channel\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;sms\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;SendSMSOnly\u0026#34; }, { \u0026#34;Variable\u0026#34;: \u0026#34;$.channel\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;SendEmailOnly\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;FailState\u0026#34; }, \u0026#34;ParallelNotification\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Parallel\u0026#34;, \u0026#34;Branches\u0026#34;: [ { \u0026#34;StartAt\u0026#34;: \u0026#34;SendSMS\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;SendSMS\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::sns:publish\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Message.$\u0026#34;: \u0026#34;$.message\u0026#34;, \u0026#34;PhoneNumber.$\u0026#34;: \u0026#34;$.phoneNumber\u0026#34; }, \u0026#34;End\u0026#34;: true } } }, { \u0026#34;StartAt\u0026#34;: \u0026#34;SendEmail\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;SendEmail\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FromEmailAddress.$\u0026#34;: \u0026#34;$.email.from\u0026#34;, \u0026#34;Destination\u0026#34;: { \u0026#34;ToAddresses.$\u0026#34;: \u0026#34;States.Array($.email.to)\u0026#34;, \u0026#34;CcAddresses.$\u0026#34;: \u0026#34;States.ArrayGetItem(States.JsonToString($.email.cc), $)\u0026#34;, \u0026#34;BccAddresses.$\u0026#34;: \u0026#34;States.ArrayGetItem(States.JsonToString($.email.bcc), $)\u0026#34; }, \u0026#34;Content\u0026#34;: { \u0026#34;Simple\u0026#34;: { \u0026#34;Subject\u0026#34;: { \u0026#34;Data.$\u0026#34;: \u0026#34;$.email.subject\u0026#34;, \u0026#34;Charset\u0026#34;: \u0026#34;UTF-8\u0026#34; }, \u0026#34;Body\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;Data.$\u0026#34;: \u0026#34;$.message\u0026#34;, \u0026#34;Charset\u0026#34;: \u0026#34;UTF-8\u0026#34; }, \u0026#34;Html\u0026#34;: { \u0026#34;Data.$\u0026#34;: \u0026#34;$.email.htmlBody\u0026#34;, \u0026#34;Charset\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } }, \u0026#34;ReplyToAddresses.$\u0026#34;: \u0026#34;States.Array($.email.replyTo)\u0026#34;, \u0026#34;EmailTags\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;channel\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;email\u0026#34; }, { \u0026#34;Name\u0026#34;: \u0026#34;messageType\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.email.messageType\u0026#34; } ], \u0026#34;ConfigurationSetName.$\u0026#34;: \u0026#34;$.email.configurationSet\u0026#34;, \u0026#34;ListManagementOptions\u0026#34;: { \u0026#34;ContactListName.$\u0026#34;: \u0026#34;$.email.contactList\u0026#34;, \u0026#34;TopicName.$\u0026#34;: \u0026#34;$.email.topic\u0026#34; } }, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:sesv2:sendEmail\u0026#34;, \u0026#34;End\u0026#34;: true } } } ], \u0026#34;End\u0026#34;: true }, \u0026#34;SendSMSOnly\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::sns:publish\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Message.$\u0026#34;: \u0026#34;$.message\u0026#34;, \u0026#34;PhoneNumber.$\u0026#34;: \u0026#34;$.phoneNumber\u0026#34; }, \u0026#34;End\u0026#34;: true }, \u0026#34;SendEmailOnly\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FromEmailAddress.$\u0026#34;: \u0026#34;$.email.from\u0026#34;, \u0026#34;Destination\u0026#34;: { \u0026#34;ToAddresses.$\u0026#34;: \u0026#34;States.Array($.email.to)\u0026#34; }, \u0026#34;Content\u0026#34;: { \u0026#34;Simple\u0026#34;: { \u0026#34;Subject\u0026#34;: { \u0026#34;Data.$\u0026#34;: \u0026#34;$.email.subject\u0026#34;, \u0026#34;Charset\u0026#34;: \u0026#34;UTF-8\u0026#34; }, \u0026#34;Body\u0026#34;: { \u0026#34;Text\u0026#34;: { \u0026#34;Data.$\u0026#34;: \u0026#34;$.message\u0026#34;, \u0026#34;Charset\u0026#34;: \u0026#34;UTF-8\u0026#34; }, \u0026#34;Html\u0026#34;: { \u0026#34;Data.$\u0026#34;: \u0026#34;$.email.htmlBody\u0026#34;, \u0026#34;Charset\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } } }, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:sesv2:sendEmail\u0026#34;, \u0026#34;End\u0026#34;: true }, \u0026#34;FailState\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Fail\u0026#34;, \u0026#34;Cause\u0026#34;: \u0026#34;Invalid channel specified\u0026#34; } } } Cách triển khai Step Functions này mang lại một số lợi ích sau:\nNative service integration: Tích hợp trực tiếp với Amazon Simple Notification Service (Amazon SNS), Amazon Simple Email Service (Amazon SES), Amazon DynamoDB, và Amazon CloudWatch giúp loại bỏ nhu cầu sử dụng các wrapper Lambda functions. Visual workflow: Luồng thực thi có thể được quan sát và duy trì dễ dàng thông qua AWS Management Console. Built-in error handling: Chính sách Retry và error states có thể được định nghĩa một cách declaratively. Parallel execution: Parallel state xử lý việc gửi dữ liệu đến nhiều kênh một cách hiệu quả. Simplified logic: Choice state thay thế cho các câu lệnh if-else phức tạp. Centralized data flow: Input và output được quản lý nhất quán giữa các states. Enhanced workflow duration capabilities: Step Functions Standard workflows hỗ trợ các phiên thực thi có thể chạy lên đến một năm, so với giới hạn 15 phút của Lambda functions. Comparing Lambda function as orchestrator to Step Functions Tóm tắt các đặc điểm khác nhau được triển khai giữa Lambda function as orchestrator và Step Functions được thể hiện trong bảng sau:\nTính năng Lambda function as orchestrator Step Functions Logic điều phối Được triển khai trong Python với các câu lệnh if-else lồng nhau. Được định nghĩa khai báo bằng trạng thái Choice Phân phối đa kênh Gọi hàm tuần tự. Thực thi song song sử dụng logic của hàm. Thực thi song song sử dụng trạng thái Parallel Tích hợp dịch vụ Yêu cầu SDK calls hoặc các Lambda functions riêng biệt. Tích hợp trực tiếp với các dịch vụ AWS (Amazon SNS, DynamoDB) Xử lý lỗi Khối try-except tùy chỉnh trong Python. Trạng thái lỗi tích hợp sẵn và chính sách thử lại Duy trì dữ liệu Code tùy chỉnh để tương tác với DynamoDB. Tích hợp DynamoDB gốc với tác vụ putItem Ghi nhật ký số liệu Code tùy chỉnh để gọi CloudWatch. Tích hợp SDK CloudWatch Metrics Cân nhắc thực hiện Xem xét các yếu tố sau khi re-architecting một Lambda function orchestrator sang Step Functions:\nState machine type: Chọn giữa Standard (thời gian chạy lên đến 1 năm) và Express (thời gian chạy lên đến 5 phút) tùy theo nhu cầu của bạn. Input/output management: Việc thao tác với parameters giúp giảm khối lượng phát triển và mang lại các lựa chọn linh hoạt hơn để triển khai workflow: Parameters: Chọn các trường input cụ thể để truyền sang state tiếp theo. ResultSelector: Lọc state response để chỉ bao gồm các trường có liên quan. ResultPath: Lưu processed result vào một path cụ thể trong state input. OutputPath: Xác định dữ liệu nào sẽ được truyền sang state tiếp theo Một code snippet cho các tính năng này như sau:\n\u0026#34;ProcessOrder\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;ProcessOrderFunction\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;orderId.$\u0026#34;: \u0026#34;$.orderId\u0026#34;, \u0026#34;customerId.$\u0026#34;: \u0026#34;$.customerId\u0026#34; } }, \u0026#34;ResultSelector\u0026#34;: { \u0026#34;orderStatus.$\u0026#34;: \u0026#34;$.Payload.status\u0026#34;, \u0026#34;processedDate.$\u0026#34;: \u0026#34;$.Payload.timestamp\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.orderProcessing\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.orderProcessing\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;NotifyCustomer\u0026#34; } } Xử lý lỗi: Triển khai retry policies và bắt lỗi (catch errors) ở cả hai cấp độ: task và state machine. Giám sát: Thiết lập CloudWatch logs và metrics cho state machine của bạn để theo dõi executions và performance. Lợi ích của việc sử dụng Step Functions Việc sử dụng Step Functions trong các kịch bản rearchitecting mang lại những lợi ích sau:\nReduced code complexity: Business logic giờ đây được định nghĩa trong Amazon States Language thay vì phân tán qua nhiều Lambda functions. Improved maintainability: Các developer có thể thay đổi workflow bằng cách chỉnh sửa Amazon States Language, thay vì phải sửa đổi nhiều Lambda functions. Native AWS service integrations: Step Functions cung cấp direct integrations với hơn 200 AWS services, cho phép bạn kết nối và phối hợp các AWS resources mà không cần viết custom integration code. Cost optimization: Bằng cách sử dụng direct service integrations, số lượng Lambda invocations giảm đi, giúp tiết kiệm chi phí. Long-running processes: Step Functions có thể quản lý workflows chạy đến 1 năm, vượt xa giới hạn 15 phút của Lambda functions. Kết luận Rearchitecting các Lambda-based applications bằng Step Functions có thể cải thiện đáng kể maintainability, scalability, và operational efficiency. Bằng cách chuyển orchestration logic vào Step Functions và tận dụng native service integrations, bạn có thể tạo ra các serverless applications mạnh mẽ và dễ quản lý hơn. Mặc dù bài viết này tập trung vào message distribution workflow, nhưng các nguyên tắc được trình bày có thể áp dụng cho nhiều serverless architectures khác nhau. Khi bạn phát triển ứng dụng của mình, hãy cân nhắc cách Step Functions có thể giúp bạn xây dựng các giải pháp resilient và scalable hơn. Để tìm hiểu thêm về serverless architectures, hãy truy cập Serverless Land.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.8-blog8/","title":"Blog 8","tags":[],"description":"","content":"Tối đa hóa giá trị doanh nghiệp thông qua tối ưu hóa đám mây chiến lược Khi việc áp dụng cloud tiếp tục tăng tốc, các tổ chức nhận ra rằng hành trình lên cloud chỉ mới là bước khởi đầu. Thách thức – và cũng là cơ hội thực sự – nằm ở việc tối ưu hóa việc sử dụng cloud để mang lại giá trị kinh doanh tối đa. Tại AWS, chúng tôi cam kết giúp khách hàng điều hướng hành trình này một cách thành công. Hãy cùng khám phá một số insight và best practices quan trọng cho cloud optimization được chia sẻ trong ấn phẩm mới của MIT Technology Review, Driving business value by optimizing the cloud.\nYêu cầu tối ưu hóa đám mây Dữ liệu gần đây cho thấy chi tiêu hạ tầng cloud toàn cầu đạt 84 tỷ USD trong quý 3 năm 2024, tăng 23% so với cùng kỳ năm trước. Mức tăng trưởng này nhấn mạnh vai trò quan trọng của cloud trong việc thúc đẩy khả năng linh hoạt và đổi mới doanh nghiệp.\nTuy nhiên, để thực sự khai thác sức mạnh của cloud, các tổ chức cần đạt được cân bằng hợp lý giữa chi phí, bảo mật, khả năng phục hồi và đổi mới.\nAndré Dufour, AWS Director and General Manager for AWS Cloud Optimization, nhấn mạnh rằng tối ưu hóa đám mây không chỉ là giảm chi tiêu, mà còn là tối ưu hóa việc sử dụng cloud để giải phóng nguồn lực, từ đó có thể tái đầu tư vào các sáng kiến mới, chẳng hạn như các sáng kiến AI mang tính sáng tạo.\nTối ưu hóa đám mây nên được xem là một quá trình liên tục, không phải một sự kiện duy nhất. Nó yêu cầu đánh giá định kỳ bất cứ khi nào điều kiện kinh doanh hoặc yêu cầu kỹ thuật thay đổi đáng kể. Cách tiếp cận cần phải toàn diện, không chỉ tập trung vào chi phí mà còn bao gồm cả sáu trụ cột (hoạt động xuất sắc, bảo mật, độ tin cậy, hiệu quả hoạt động, tối ưu hóa chi phí và tính bền vững). Ngoài ra, mỗi workload cần có chiến lược tối ưu riêng, tránh cách tiếp cận “một giải pháp cho tất cả”.\nThực tiễn tốt nhất để thành công Hãy cân nhắc các thực tiễn tốt nhất sau:\nNâng cao đội ngũ của bạn – Trang bị cho nhân viên các kỹ năng về cloud, quản lý chi phí, và tối ưu hóa. Như Dufour chia sẻ: “Mỗi kỹ sư hay builder đều đóng vai trò trong tối ưu hóa đám mây.” Thiết lập một trung tâm đám mây xuất sắc – Tạo ra một bộ phận trung tâm chịu trách nhiệm phát triển và phổ biến các cloud best practices trong toàn tổ chức. Thống nhất tài chính và kinh doanh – Biến các cloud KPIs trở nên gắn liền với mục tiêu kinh doanh thay vì chỉ thuần kỹ thuật, để đảm bảo mọi nỗ lực tối ưu hóa đều hỗ trợ chiến lược tổng thể. Nắm bắt dự động hóa – Sử dụng các công cụ để tự động hóa việc cung cấp, giám sát, và tối ưu hóa, giảm thiểu lỗi con người và tiết kiệm công sức. Sử dụng các dịch vụ và giải pháp AI để đạt hiệu quả – Ứng dụng AI technologies để tự động hóa việc trực quan hóa, tăng cường ra quyết định và tối ưu hóa việc sử dụng tài nguyên. Câu chuyện thành công trong thế giới thực Nhiều khách hàng của chúng tôi đã đạt được kết quả đáng kể nhờ chiến lược tối ưu hóa đám mây:\nDreamCasino: Giảm 30% chi phí, đồng thời rút ngắn 50% thời gian phản hồi API, giúp mở rộng sang các thị trường mới. BMC Software: Giảm 25% chi phí cloud trong khi vẫn cải thiện bảo mật và độ tin cậy, tái đầu tư phần tiết kiệm vào cơ hội kinh doanh mới. Ngay cả tại AWS, việc chúng tôi sử dụng Amazon Q để hiện đại hóa ứng dụng đã giúp tiết kiệm khoảng 4.500 năm công phát triển và mang lại 260 triệu USD lợi ích hiệu suất. Tác động kinh doanh Việc tối ưu hóa cloud hiệu quả không chỉ mang lại tiết kiệm chi phí, mà còn đem lại các lợi ích sau:\nĐẩy nhanh đổi mới thông qua việc tái đầu tư nguồn lực tiết kiệm được Tăng cường bảo mật và hiệu quả vận hành Cải thiện khả năng mở rộng và thích ứng với nhu cầu kinh doanh Mang lại trải nghiệm khách hàng tốt hơn và rút ngắn thời gian ra thị trường Nâng cao năng lực đưa ra quyết định kiến trúc và thiết kế, bằng cách cân bằng giữa các AWS Well-Architected pillars Tài nguyên AWS cho hành trình tối ưu hóa cho bạn Để hỗ trợ bạn đẩy nhanh hành trình tối ưu hóa đám mây, AWS cung cấp nhiều công cụ và tài nguyên:\nAWS Cloud Adoption Framework – Đánh giá mức độ sẵn sàng của tổ chức đối với cloud AWS Well-Architected Framework – Hướng dẫn chi tiết dựa trên sáu trụ cột AWS Well-Architected Tool – Đánh giá khối lượng công việc của bạn dựa trên các biện pháp thực hành tốt nhất của AWS AWS Well-Architected Lenses – Mở rộng Framework cho từng ngành và lĩnh vực công nghệ cụ thể, bao gồm cả Generative AI lens Well-Architected IaC (Infrastructure as Code) Analyzer tool – Tự động đánh giá các IaC templates như AWS CloudFormation và Terraform theo AWS Well-Architected Framework Bắt đầu Để bắt đầu, hãy xem xét các bước sau:\nTải báo cáo MIT executive report Đánh giá mức độ sẵn sàng lên cloud bằng Cloud Adoption Framework Bắt đầu với Well-Architected Review để đánh giá trạng thái hiện tại Sử dụng AWS Trusted Advisor để tối ưu chi phí, cải thiện hiệu suất và khắc phục lỗ hổng bảo mật Theo dõi AWS Health events để cập nhật những thay đổi ảnh hưởng đến ứng dụng của bạn trên AWS Cân nhắc AWS Managed Services để mở rộng năng lực vận hành như giám sát, quản lý sự cố, AWS Incident Detection and Response, bảo mật, vá lỗi, sao lưu, và tối ưu hóa chi phí Sử dụng AWS re:Post – nền tảng chia sẻ kiến thức đáng tin cậy giúp bạn nhanh chóng giải quyết vấn đề kỹ thuật, tăng tốc đổi mới và vận hành hiệu quả hơn. Ngoài ra, bạn có thể hợp tác với AWS Cloud Optimization Success (COS) Team để nhận hướng dẫn chi tiết hơn và xác định bước đi tiếp theo trong hành trình tối ưu hóa đám mây của mình. COS Team bao gồm các Solutions Architects chuyên về Cloud Adoption Framework và Well-Architected Framework, tổ chức các buổi hội thảo và đào tạo thông qua các chương trình dành cho khách hàng và đối tác. Đội ngũ này sẽ hỗ trợ việc áp dụng các dịch vụ AWS thông qua Well-Architected và Cloud Adoption Frameworks, đồng thời hỗ trợ thêm các dịch vụ như AWS Trusted Advisor và AWS Health nhằm tối ưu hóa chi phí và kiến trúc cloud. Dù bạn mới bắt đầu hay muốn nâng cao các triển khai hiện có, AWS COS Team luôn mang đến hướng dẫn, công cụ, và chuyên môn cần thiết để bạn thành công.\nKết luận Tại AWS, chúng tôi luôn đồng hành cùng bạn trong hành trình tối ưu hóa cloud. Bằng cách áp dụng các chiến lược và thực tiễn tốt nhất, bạn có thể khai mở toàn bộ tiềm năng của cloud, thúc đẩy đổi mới và tăng trưởng, đồng thời duy trì bảo mật và hiệu quả vận hành.\nSẵn sàng nâng tầm tối ưu hóa đám mây của bạn lên một tầm cao mới chưa? Hãy tham khảo các tài nguyên được liệt kê trong bài viết này và liên hệ với AWS COS Team để tìm hiểu cách chúng tôi có thể giúp bạn tối đa hóa giá trị đầu tư cloud.\nRyan Dsouza Ryan Dsouza là Principal Solutions Architect trong Cloud Optimization Success Organization tại AWS, Ryan Dsouza (New York City) hỗ trợ khách hàng thiết kế, phát triển và vận hành các giải pháp bảo mật, linh hoạt và sáng tạo hơn, tận dụng tối đa năng lực của AWS để mang lại kết quả kinh doanh đo lường được. Anh tham gia phát triển chiến lược, hướng dẫn và công cụ giúp khách hàng xây dựng giải pháp tối ưu hiệu suất, chi phí, bảo mật, khả năng phục hồi và hiệu quả vận hành, phù hợp với AWS Cloud Adoption Framework và Well-Architected Framework.\nAnitha Selvan Anitha Selvan là Go-To-Market Lead của Cloud Optimization Success Organization, Anitha có hơn 8 năm kinh nghiệm trong lĩnh vực product marketing và triển khai go-to-market strategies cho các sản phẩm hỗ trợ của AWS. Cô chuyên về product launches, messaging, và positioning nhằm hỗ trợ phát triển kinh doanh và mở rộng mức độ ứng dụng sản phẩm.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/3.9-blog9/","title":"Blog 9","tags":[],"description":"","content":"Giới thiệu phiên bản v2 của Powertool for AWS Lambda (Java) Các ứng dụng hiện đại ngày nay ngày càng dựa vào các công nghệ Serverless như Amazon Web Services (AWS) Lambda để đạt được khả năng scalability, cost efficiency, và agility. Serverless Applications Lens trong AWS Well-Architected Framework tập trung vào cách thiết kế, triển khai, và kiến trúc hóa các ứng dụng Serverless của bạn để vượt qua những thách thức này.\nPowertools for AWS Lambda là một developer toolkit giúp bạn triển khai Serverless best practices và chuyển đổi trực tiếp các khuyến nghị trong AWS Well-Architected thành các tiện ích có thể hành động, thân thiện với developer. Sau khi cộng đồng thành công trong việc áp dụng Powertools cho AWS bằng Python, Java, TypeScript, và .NET, bài viết này công bố phiên bản chính thức của Powertools for AWS Lambda (Java) v2, đi kèm các cải tiến lớn về hiệu năng, nâng cấp các core utilities, và một Kafka utility hoàn toàn mới.\nPowertools for AWS (Java) v2 bao gồm 3 core utilities được cập nhật:\nLogging: Mô-đun logging được thiết kế lại theo phong cách Java idiomatic, cung cấp structured logging giúp dễ dàng tổng hợp và phân tích log. Metrics: Trải nghiệm metrics được cải thiện, cho phép thu thập custom metrics bằng CloudWatch Embedded Metric Format (EMF). Tracing: Cách tiếp cận dựa trên annotation để thu thập distributed tracing data với AWS X-Ray, giúp trực quan hóa và phân tích luồng request. Các tính năng mới trong v2:\nGraalVM native image support: Hỗ trợ native image cho GraalVM trên tất cả các core utilities, giúp giảm thời gian Lambda cold start lên đến 75.61% (p95). Kafka utility: Tích hợp với Amazon Managed Streaming for Apache Kafka (Amazon MSK) và self-managed Kafka event sources trên Lambda, cho phép deserialize trực tiếp thành Kafka native types như ConsumerRecords. Xem thêm chi tiết về hướng dẫn nâng cấp trong tài liệu upgrade guide.\nBắt đầu với Powertools for AWS Lambda (Java) v2 Powertools for AWS Lambda (Java) v2 có sẵn dưới dạng Java package trên Maven Central và tích hợp với các công cụ build phổ biến như Maven và Gradle. Bài viết này tập trung vào ví dụ triển khai bằng Maven để bạn có thể bắt đầu nhanh chóng. Các ví dụ về Gradle được cung cấp trong tài liệu và repository ví dụ. Toolkit này tương thích với Java 11 trở lên, đảm bảo bạn có thể sử dụng các tính năng Java hiện đại khi xây dựng ứng dụng Serverless. Hướng dẫn cài đặt từng utility được trình bày trong các phần sau, và cấu hình đầy đủ có sẵn trong tài liệu Powertools.\nLogging Utility Logging giúp triển khai structured logging khi chạy trên Lambda mà vẫn sử dụng được các thư viện logging quen thuộc của Java như slf4j, log4j, và logback. Phiên bản v2 của Logging cho phép bạn:\nXuất structured JSON logs có thêm thông tin từ Lambda context. Chọn backend logging yêu thích: log4j2 hoặc logback. Thêm structured arguments vào log, được serialize thành nested JSON objects. Thêm global log keys bằng Mapped Diagnostic Context (MDC) của slf4j. Ví dụ thêm dependency vào Maven project (log4j2 backend):\n\u0026lt;!-- In the dependencies section --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-logging-log4j\u0026lt;/artifactId\u0026gt; \u0026lt;!-- Alternatively, if you wish to use the logback backend \u0026lt;artifactId\u0026gt;powertools-logging-logback\u0026lt;/artifactId\u0026gt; --\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- In the build plugins section --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;dev.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectj-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;aspectLibraries\u0026gt; \u0026lt;aspectLibrary\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-logging\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/aspectLibrary\u0026gt; \u0026lt;/aspectLibraries\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; Tạo một ứng dụng JsonTemplateLayout tùy chỉnh trong tệp log4j2.xml của bạn:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Configuration\u0026gt; \u0026lt;Appenders\u0026gt; \u0026lt;Console name=\u0026#34;JsonAppender\u0026#34; target=\u0026#34;SYSTEM_OUT\u0026#34;\u0026gt; \u0026lt;JsonTemplateLayout eventTemplateUri=\u0026#34;classpath:LambdaJsonLayout.json\u0026#34; /\u0026gt; \u0026lt;/Console\u0026gt; \u0026lt;/Appenders\u0026gt; \u0026lt;Loggers\u0026gt; \u0026lt;Logger name=\u0026#34;JsonLogger\u0026#34; level=\u0026#34;INFO\u0026#34; additivity=\u0026#34;false\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;JsonAppender\u0026#34;/\u0026gt; \u0026lt;/Logger\u0026gt; \u0026lt;Root level=\u0026#34;info\u0026#34;\u0026gt; \u0026lt;AppenderRef ref=\u0026#34;JsonAppender\u0026#34;/\u0026gt; \u0026lt;/Root\u0026gt; \u0026lt;/Loggers\u0026gt; \u0026lt;/Configuration\u0026gt; Để thêm tính năng ghi nhật ký có cấu trúc vào các hàm của bạn, hãy áp dụng chú thích @Logging cho trình xử lý Lambda của bạn và sử dụng slf4j Java API quen thuộc khi viết câu lệnh nhật ký. Điều này cho phép bạn áp dụng tiện ích ghi nhật ký mà không cần tái cấu trúc mã chính. Powertools xử lý việc định tuyến tới chương trình phụ trợ ghi nhật ký chính xác cho bạn. Ví dụ sau đây cho thấy cách thêm khóa nhật ký chung bằng MDC và thêm đối số mục nhập có cấu trúc vào thông điệp nhật ký của bạn:\npublic class App implements RequestHandler\u0026lt;SQSEvent, String\u0026gt; { private static final Logger log = LoggerFactory.getLogger(App.class); @Logging public String handleRequest(final SQSEvent input, final Context context) { // Add a global log key using Mapped Diagnostic Context MDC MDC.put(\u0026#34;myCustomKey\u0026#34;, \u0026#34;willBeLoggedForAllLogStatements\u0026#34;); // Log a message with a structured argument (any JSON serializable Object) log.info(\u0026#34;My message\u0026#34;, entry(\u0026#34;anotherCustomKey\u0026#34;, Map.of(\u0026#34;nested\u0026#34;, \u0026#34;object\u0026#34;))); // ... return response } } Lambda gửi đầu ra có định dạng JSON sau tới Amazon CloudWatch Logs (lưu ý cách Java Map được tự động tuần tự hóa thành đối tượng JSON):\n{ \u0026#34;level\u0026#34;: \u0026#34;INFO\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;My message\u0026#34;, \u0026#34;cold_start\u0026#34;: true, \u0026#34;function_arn\u0026#34;: \u0026#34;arn:aws:lambda:us-east-1:012345678912:function:AppFunction\u0026#34;, \u0026#34;function_memory_size\u0026#34;: 512, \u0026#34;function_name\u0026#34;: \u0026#34;AppFunction\u0026#34;, \u0026#34;function_request_id\u0026#34;: \u0026#34;0150a2a4-c5aa-4277-9345-17bad039f6c0\u0026#34;, \u0026#34;function_version\u0026#34;: \u0026#34;$LATEST\u0026#34;, \u0026#34;sampling_rate\u0026#34;: 0.1, \u0026#34;service\u0026#34;: \u0026#34;powertools-java-sample\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2025-05-20T08:35:28.565Z\u0026#34;, \u0026#34;myCustomKey\u0026#34;: \u0026#34;willBeLoggedForAllLogStatements\u0026#34;, \u0026#34;anotherCustomKey\u0026#34;: { \u0026#34;nested\u0026#34;: \u0026#34;object\u0026#34; } } Metrics CloudWatch cung cấp các service metrics tích hợp sẵn giúp theo dõi throughput của ứng dụng, tỷ lệ lỗi, và mức sử dụng tài nguyên. Tuy nhiên, người dùng cũng cần thu thập các custom metrics đặc thù cho workload của họ — những metric có liên quan trực tiếp đến bài toán kinh doanh, theo đúng best practices trong AWS Well-Architected Framework.\nPowertools for AWS (Java) cho phép bạn tạo custom metrics một cách bất đồng bộ (asynchronously) bằng cách xuất dữ liệu metric theo định dạng CloudWatch EMF (Embedded Metric Format) trực tiếp ra standard output — một cách tiếp cận không yêu cầu thêm bất kỳ cấu hình nào khác. Dịch vụ Lambda sẽ tự động gửi các metric có định dạng EMF đó đến CloudWatch thay bạn.\nMetrics utility cho phép bạn:\nTạo custom metrics bất đồng bộ bằng CloudWatch EMF. Giảm độ trễ (latency) nhờ tránh việc publish metric đồng bộ. Tự động theo dõi cold starts trong một custom CloudWatch metric. Loại bỏ việc phải xác thực thủ công output của bạn so với EMF specification. Giữ code gọn gàng, không cần flush thủ công ra standard output. Để thêm Metrics utility vào project của bạn, hãy thêm dependency Maven sau đây:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-metrics\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- In the build plugins section --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;dev.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectj-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;aspectLibraries\u0026gt; \u0026lt;aspectLibrary\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-metrics\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/aspectLibrary\u0026gt; \u0026lt;/aspectLibraries\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; Để thêm số liệu tùy chỉnh vào hàm Lambda, hãy đặt chú thích @FlushMetrics trên trình xử lý Lambda của bạn. Thư viện đảm nhiệm việc xác thực và chuyển số liệu của bạn sang đầu ra tiêu chuẩn trước khi hàm Lambda kết thúc. Ví dụ sau đây cho thấy cách bạn có thể tự động nắm bắt số liệu khởi động nguội và đưa ra số liệu tùy chỉnh của riêng mình:\npublic class App implements RequestHandler\u0026lt;SQSEvent, String\u0026gt; { private static final Logger log = LoggerFactory.getLogger(App.class); private static final Metrics metrics = MetricsFactory.getMetricsInstance(); // This configures a default namespace and service dimension for all metrics @FlushMetrics(namespace = \u0026#34;ServerlessAirline\u0026#34;, service = \u0026#34;payment\u0026#34;, captureColdStart = true) public String handleRequest(final SQSEvent input, final Context context) { // The Metrics instance is a singleton metrics.addMetric(\u0026#34;CustomMetric1\u0026#34;, 1, MetricUnit.COUNT); // Publish metrics with non-default configuration options DimensionSet dimensionSet = new DimensionSet(); dimensionSet.addDimension(\u0026#34;Service\u0026#34;, \u0026#34;AnotherService\u0026#34;); metrics.flushSingleMetric(\u0026#34;CustomMetric2\u0026#34;, 1, MetricUnit.COUNT, \u0026#34;AnotherNamespace\u0026#34;, dimensionSet); // ... return response } } Hình 1. Chế độ xem biểu đồ số liệu AWS CloudWatch.\nTracing Tiện ích Tracing cung cấp khả năng tích hợp dựa trên chú thích với X-Ray để theo dõi phân tán với cấu hình tối thiểu. Truy tìm cho phép bạn:\nTheo dõi các lời gọi hàm và tương tác với AWS services trong X-Ray console. Tự động ghi nhận lỗi, phản hồi, và cold start. Thêm custom metadata để hỗ trợ debug. Bật/tắt tracing qua environment variables mà không cần chỉnh code. Để thêm tiện ích Tracing vào dự án của bạn, hãy thêm phần phụ thuộc Maven sau:\n\u0026lt;!-- In the dependencies section --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-tracing\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- In the build plugins section --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;dev.aspectj\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;aspectj-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;aspectLibraries\u0026gt; \u0026lt;aspectLibrary\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-tracing\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/aspectLibrary\u0026gt; \u0026lt;/aspectLibraries\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; Để bật tính năng theo dõi trong hàm Lambda, hãy chú thích trình xử lý Lambda và các phương thức tùy chỉnh mà bạn muốn theo dõi bằng chú thích @Tracing. Mỗi chú thích ánh xạ tới một phân đoạn phụ của trình xử lý Lambda chính của bạn trong X-Ray và hiển thị trong bảng điều khiển.\npublic class App implements RequestHandler\u0026lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent\u0026gt; { private static final Logger log = LoggerFactory.getLogger(App.class); @Tracing public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) { // ... business logic // Get calling IP with tracing String location = getCallingIp(\u0026#34;https://checkip.amazonaws.com\u0026#34;) // ... return response } @Tracing(segmentName = \u0026#34;Location service\u0026#34;) private String getCallingIp(String address) { // Implementation to get IP address log.info(\u0026#34;Retrieving caller IP address\u0026#34;); // Add custom metadata to current sub-segment URL url = new URL(address); putMetadata(\u0026#34;getCallingIp\u0026#34;, address); // ... return \u0026#34;127.0.0.1\u0026#34;; } } Bảng điều khiển X-Ray hiển thị bản đồ dịch vụ được tạo khi lưu lượng truy cập bắt đầu chảy qua ứng dụng của bạn. Việc áp dụng chú thích Truy tìm cho phương thức xử lý hàm Lambda của bạn hoặc bất kỳ phương thức nào khác trong chuỗi thực thi sẽ cung cấp cho bạn khả năng hiển thị toàn diện về các mẫu lưu lượng truy cập trong toàn bộ ứng dụng của bạn. Hình sau đây cho thấy siêu dữ liệu tùy chỉnh được thêm vào trong ví dụ được liên kết với phân đoạn phụ tùy chỉnh như thế nào.\nHình 2. Chế độ xem dấu vết thác nước AWS X-Ray.\nGiảm thời gian Lambda Cold Start Một tính năng chính trong Powertools dành cho AWS Lambda (Java) v2 là hỗ trợ hình ảnh gốc GraalVM cho tất cả các tiện ích cốt lõi. Việc biên dịch các hàm Lambda của bạn thành các tệp thực thi gốc cho phép bạn giảm đáng kể thời gian khởi động nguội và mức sử dụng bộ nhớ. Sử dụng Powertools v2 với GraalVM cho phép bạn giảm khả năng khởi động nguội lên tới 75,61% (p95) so với sử dụng thời gian chạy Java được quản lý. Điểm chuẩn sau đây so sánh thời gian khởi động nguội của một ứng dụng sử dụng tất cả các tiện ích cốt lõi (ghi nhật ký, số liệu, theo dõi) trên thời gian chạy java21 được quản lý so với thời gian chạy Lambda do Lambda provided.al2023 chạy hình ảnh gốc được biên dịch GraalVM (đi đến Lambda runtimes để được hỗ trợ):\nEnvironment p95 (ms) Min (ms) Avg (ms) Max (ms) Max Memory (MB) N Powertools for AWS (Java) v2: JVM 1682.92 1224.55 1224.55 2229.81 205.04 234 Powertools for AWS (Java) v2: GraalVM 542.86 404.92 504.77 752.85 93.46 369 Cải tiến này đặc biệt có giá trị đối với các ứng dụng và chức năng nhạy cảm với độ trễ thường xuyên mở rộng quy mô. Kiểm tra một ví dụ hoạt động đầy đủ trên GitHub.\nLambda MSK Event Source Mapping Integration Kafka utility mới được giới thiệu trong Powertools for AWS Lambda (Java) v2 giúp đơn giản hóa việc làm việc với Lambda MSK Event Source Mapping (ESM) và self-managed Kafka event sources. Nó mang lại một trải nghiệm quen thuộc cho các developer đã từng làm việc với Apache Kafka bằng cách cho phép chuyển đổi trực tiếp các Lambda events sang các kiểu dữ liệu native của Kafka. Các tính năng chính bao gồm:\nDeserialization trực tiếp thành các đối tượng Kafka ConsumerRecords\u0026lt;K, V\u0026gt; đồng thời vẫn sử dụng Lambda-native RequestHandler interface. Hỗ trợ deserialization các bản ghi được mã hóa bằng JSON, Avro, và Protobuf cho cả key và value fields, có hoặc không sử dụng Schema Registry khi tạo message. Để thêm Kafka utility vào project của bạn, hãy bao gồm thư viện powertools-kafka như một Maven dependency trong file pom.xml:\n\u0026lt;!-- In the dependencies section --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;software.amazon.lambda\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;powertools-kafka\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.1.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Kafka clients dependency - compatibility works for \u0026gt;= 3.0.0 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.kafka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;kafka-clients\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Hãy sử dụng annotation @Deserialization trên Lambda handler của bạn để deserialize các message thành các native Kafka ConsumerRecords. Đảm bảo rằng bạn chỉ định loại deserializer phù hợp. Ví dụ sau đây minh họa cách deserialize các bản ghi được mã hóa bằng Avro với String keys. Giống như trong Lambda handler thông thường, bạn chỉ cần khai báo kiểu dữ liệu đầu vào cho function của mình trong RequestHandler generic parameters, và utility sẽ tự động phát hiện các kiểu deserialization. Lớp AvroProduct trong ví dụ bên dưới là một Java class được auto-generated bằng thư viện Java org.apache.avro.avro.\npublic class App implements RequestHandler\u0026lt;ConsumerRecords\u0026lt;String, AvroProduct\u0026gt;, Void\u0026gt; { private static final Logger log = LoggerFactory.getLogger(App.class); @Deserialization(type = DeserializationType.KAFKA_AVRO) public Void handleRequest(ConsumerRecords\u0026lt;String, AvroProduct\u0026gt; consumerRecords, Context context) { log.info(\u0026#34;Deserialized {} records.\u0026#34;, consumerRecords.records().size()); // ... Business logic return null; } } Kết luận Powertools for AWS Lambda (Java) v2 đại diện cho bước tiến mới trong bộ công cụ hỗ trợ xây dựng các ứng dụng Serverless có tính ổn định, khả năng quan sát cao và hiệu suất vượt trội. Trong suốt bài viết này, chúng ta đã cùng tìm hiểu về các core observability utilities được cải tiến cùng những tính năng mới, hiệu năng vượt trội nhờ GraalVM native image support, và Kafka utility hoàn toàn mới giúp bạn làm việc với các Kafka pattern quen thuộc trong Lambda.\nPowertools còn cung cấp nhiều utility khác để xử lý các Serverless design pattern phổ biến, mỗi utility đều được thiết kế dựa trên nguyên tắc rõ ràng và tối giản overhead. Để tìm hiểu thêm:\nTruy cập tài liệu chính thức để xem các hướng dẫn chi tiết và ví dụ minh họa. Thử các sample applications được cung cấp. Tham gia cộng đồng trên GitHub để chia sẻ trải nghiệm và nhận hỗ trợ. Ứng dụng Serverless tiếp theo của bạn đang chờ đón — cùng khám phá với Powertools for AWS Lambda (Java) v2. Chúng tôi rất mong nhận được phản hồi từ bạn!\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.4-s3-onprem/5.4.1-prepare/","title":"Chuẩn bị tài nguyên","tags":[],"description":"","content":"Để chuẩn bị cho phần này của workshop, bạn sẽ cần phải:\nTriển khai CloudFormation stack Sửa đổi bảng định tuyến VPC. Các thành phần này hoạt động cùng nhau để mô phỏng DNS forwarding và name resolution.\nTriển khai CloudFormation stack Mẫu CloudFormation sẽ tạo các dịch vụ bổ sung để hỗ trợ mô phỏng môi trường truyền thống:\nMột Route 53 Private Hosted Zone lưu trữ các bản ghi Bí danh (Alias records) cho điểm cuối PrivateLink S3 Một Route 53 Inbound Resolver endpoint cho phép \u0026ldquo;VPC Cloud\u0026rdquo; giải quyết các yêu cầu resolve DNS gửi đến Private Hosted Zone Một Route 53 Outbound Resolver endpoint cho phép \u0026ldquo;VPC On-prem\u0026rdquo; chuyển tiếp các yêu cầu DNS cho S3 sang \u0026ldquo;VPC Cloud\u0026rdquo; Click link sau để mở AWS CloudFormation console. Mẫu yêu cầu sẽ được tải sẵn vào menu. Chấp nhận tất cả mặc định và nhấp vào Tạo stack. Có thể mất vài phút để triển khai stack hoàn tất. Bạn có thể tiếp tục với bước tiếp theo mà không cần đợi quá trình triển khai kết thúc.\nCập nhật bảng định tuyến private on-premise Workshop này sử dụng StrongSwan VPN chạy trên EC2 instance để mô phỏng khả năng kết nối giữa trung tâm dữ liệu truyền thống và môi trường cloud AWS. Hầu hết các thành phần bắt buộc đều được cung cấp trước khi bạn bắt đầu. Để hoàn tất cấu hình VPN, bạn sẽ sửa đổi bảng định tuyến \u0026ldquo;VPC on-prem\u0026rdquo; để hướng lưu lượng đến cloud đi qua StrongSwan VPN instance.\nMở Amazon EC2 console\nChọn instance tên infra-vpngw-test. Từ Details tab, copy Instance ID và paste vào text editor của bạn để sử dụng ở những bước tiếp theo\nĐi đến VPC menu bằng cách gõ \u0026ldquo;VPC\u0026rdquo; vào Search box\nClick vào Route Tables, chọn RT Private On-prem route table, chọn Routes tab, và click Edit Routes.\nClick Add route. Destination: CIDR block của Cloud VPC Target: ID của infra-vpngw-test instance (bạn đã lưu lại ở bước trên) Click Save changes "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"Giới thiệu về VPC Endpoint Điểm cuối VPC (endpoint) là thiết bị ảo. Chúng là các thành phần VPC có thể mở rộng theo chiều ngang, dự phòng và có tính sẵn sàng cao. Chúng cho phép giao tiếp giữa tài nguyên điện toán của bạn và dịch vụ AWS mà không gây ra rủi ro về tính sẵn sàng. Tài nguyên điện toán đang chạy trong VPC có thể truy cập Amazon S3 bằng cách sử dụng điểm cuối Gateway. Interface Endpoint PrivateLink có thể được sử dụng bởi tài nguyên chạy trong VPC hoặc tại TTDL. Tổng quan về workshop Trong workshop này, bạn sẽ sử dụng hai VPC.\n\u0026ldquo;VPC Cloud\u0026rdquo; dành cho các tài nguyên cloud như Gateway endpoint và EC2 instance để kiểm tra. \u0026ldquo;VPC On-Prem\u0026rdquo; mô phỏng môi trường truyền thống như nhà máy hoặc trung tâm dữ liệu của công ty. Một EC2 Instance chạy phần mềm StrongSwan VPN đã được triển khai trong \u0026ldquo;VPC On-prem\u0026rdquo; và được cấu hình tự động để thiết lập đường hầm VPN Site-to-Site với AWS Transit Gateway. VPN này mô phỏng kết nối từ một vị trí tại TTDL (on-prem) với AWS cloud. Để giảm thiểu chi phí, chỉ một phiên bản VPN được cung cấp để hỗ trợ workshop này. Khi lập kế hoạch kết nối VPN cho production workloads của bạn, AWS khuyên bạn nên sử dụng nhiều thiết bị VPN để có tính sẵn sàng cao. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.3-s3-vpc/5.3.1-create-gwe/","title":"Tạo một Gateway Endpoint","tags":[],"description":"","content":" Mở Amazon VPC console Trong thanh điều hướng, chọn Endpoints, click Create Endpoint: Bạn sẽ thấy 6 điểm cuối VPC hiện có hỗ trợ AWS Systems Manager (SSM). Các điểm cuối này được Mẫu CloudFormation triển khai tự động cho workshop này.\nTrong Create endpoint console: Đặt tên cho endpoint: s3-gwe Trong service category, chọn aws services Trong Services, gõ \u0026ldquo;s3\u0026rdquo; trong hộp tìm kiếm và chọn dịch vụ với loại gateway Đối với VPC, chọn VPC Cloud từ drop-down menu. Đối với Route tables, chọn bảng định tuyến mà đã liên kết với 2 subnets (lưu ý: đây không phải là bảng định tuyến chính cho VPC mà là bảng định tuyến thứ hai do CloudFormation tạo). Đối với Policy, để tùy chọn mặc định là Full access để cho phép toàn quyền truy cập vào dịch vụ. Bạn sẽ triển khai VPC endpoint policy trong phần sau để chứng minh việc hạn chế quyền truy cập vào S3 bucket dựa trên các policies. Không thêm tag vào VPC endpoint. Click Create endpoint, click x sau khi nhận được thông báo tạo thành công. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"Mục tiêu tuần 1: Kết nối, làm quen với các thành viên trong First Cloud Journey. Hiểu dịch vụ AWS cơ bản, cách dùng console \u0026amp; CLI. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các thành viên FCJ - Đọc và lưu ý các nội quy, quy định tại đơn vị thực tập 29/09/2025 29/09/2025 3 - Tìm hiểu AWS và các loại dịch vụ + Compute + Storage + Networking + Database + \u0026hellip; 30/09/2025 30/09/2025 https://cloudjourney.awsstudygroup.com/ 4 - Tạo AWS Free Tier account - Tìm hiểu AWS Console \u0026amp; AWS CLI - Thực hành: + Tạo AWS account + Cài AWS CLI \u0026amp; cấu hình + Cách sử dụng AWS CLI 01/10/2025 01/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 cơ bản: + Instance types + AMI + EBS + Security Group + \u0026hellip; - Các cách remote SSH vào EC2 - Tìm hiểu Elastic IP 02/10/2025 02/10/2025 https://cloudjourney.awsstudygroup.com/ 6 - Thực hành: + Tạo EC2 instance (T2.micro, Amazon Linux 2, Key Pair mới) + Cấu hình Security Group để mở cổng SSH + Kết nối SSH từ máy cá nhân + Gắn EBS volume \u0026amp; mount vào EC2 03/10/2025 03/10/2025 https://cloudjourney.awsstudygroup.com/ Kết quả đạt được tuần 1: Mối quan hệ: Đã làm quen và kết nối với các thành viên trong nhóm First Cloud Journey (FCJ). Kiến thức cơ bản AWS: Hiểu AWS là gì và nắm được các nhóm dịch vụ cơ bản: Compute (EC2), Storage (S3, EBS), Networking (VPC, Security Group), Database (RDS), v.v. Thực hành AWS Account \u0026amp; Tools: Đã tạo và cấu hình AWS Free Tier account thành công. Làm quen với AWS Management Console và biết cách tìm, truy cập, sử dụng dịch vụ từ giao diện web. Cài đặt và cấu hình AWS CLI trên máy tính bao gồm: Access Key, Secret Key, Region mặc định. Sử dụng EC2: Nắm được các khái niệm cơ bản về EC2 (Instance types, AMI, EBS, Security Group). Đã tạo thành công một EC2 instance (t2.micro) và thực hiện kết nối SSH từ máy cá nhân. Biết cách quản lý và gắn EBS volume vào EC2 instance. Sử dụng AWS CLI: Sử dụng AWS CLI để thực hiện các thao tác cơ bản như: Kiểm tra thông tin tài khoản \u0026amp; cấu hình (vd: aws configure list). Lấy danh sách region (vd: aws ec2 describe-regions). Xem dịch vụ EC2 (vd: aws ec2 describe-instances). Tạo và quản lý key pair. Tổng hợp: Có khả năng kết nối giữa giao diện web và CLI để quản lý tài nguyên AWS song song. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Thiết lập cơ chế export dữ liệu từ DynamoDB sang S3 phục vụ phân tích. Tiếp tục sửa lỗi và tối ưu hệ thống. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Nghiên cứu cơ chế export dữ liệu từ DynamoDB sang S3 01/12/2025 01/12/2025 https://docs.aws.amazon.com/amazondynamodb/ 3 - Viết script export dữ liệu DynamoDB sang S3 (JSON/CSV) 02/12/2025 02/12/2025 https://docs.aws.amazon.com/AmazonS3/ 4 - Thiết lập lịch trình export dữ liệu phục vụ backup \u0026amp; phân tích 03/12/2025 03/12/2025 https://docs.aws.amazon.com/scheduler/ 5 - Sửa lỗi Backend: API, xử lý dữ liệu, phân quyền 04/12/2025 04/12/2025 6 - Sửa lỗi Frontend: hiển thị dữ liệu, form, trải nghiệm người dùng 05/12/2025 05/12/2025 https://nextjs.org/docs 7 - Kiểm thử tổng thể hệ thống sau khi sửa lỗi và export dữ liệu 06/12/2025 06/12/2025 Kết quả đạt được tuần 10: Thiết lập thành công cơ chế export dữ liệu từ DynamoDB sang S3: Dữ liệu được lưu trữ dưới dạng JSON/CSV. Phục vụ backup định kỳ và phân tích dữ liệu. Hoàn thành việc sửa lỗi Backend \u0026amp; Frontend: Ổn định các API chính. Cải thiện hiển thị giao diện người dùng. Kiểm thử lại toàn hệ thống sau khi cập nhật. Kết quả tổng thể: Hệ thống vận hành ổn định hơn, dữ liệu được sao lưu an toàn và sẵn sàng cho các bước phân tích tiếp theo. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Nâng cao chất lượng hệ thống thông qua việc viết Unit Test cho Backend và E2E Test cho Frontend. Xây dựng pipeline phân tích dữ liệu và hệ thống Business Intelligence (BI) cơ bản. Hoàn thiện và tối ưu quy trình CI/CD cho cả Frontend và Backend. Rà soát và đảm bảo an toàn hệ thống thông qua việc kiểm tra quyền IAM theo nguyên tắc Least Privilege. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Viết Backend Unit Tests bằng Jest cho các Lambda cốt lõi: roomCrud.js, searchRooms.js 08/12/2025 08/12/2025 https://jestjs.io/ 3 - Viết Frontend E2E Tests bằng Cypress cho 3 luồng chính: + Đăng nhập + Tìm kiếm/Lọc + Đăng tin 09/12/2025 09/12/2025 https://www.cypress.io/ 4 - Thiết lập AWS Athena trên dữ liệu được export từ S3 - Viết file athena-queries.sql: + Giá thuê trung bình theo quận + Top 5 phòng có lượt xem cao nhất 10/12/2025 10/12/2025 https://docs.aws.amazon.com/athena/ 5 - Cấu hình Amazon QuickSight - Xây dựng một dashboard trực quan hóa kết quả truy vấn từ Athena 11/12/2025 11/12/2025 https://docs.aws.amazon.com/quicksight/ 6 - Tối ưu file deploy-frontend.yml: Build Next.js → Upload S3 → Invalidate CloudFront - Rà soát lại IAM Permissions cho các Lambda theo nguyên tắc Least Privilege 12/12/2025 12/12/2025 https://docs.github.com/en/actions Kết quả đạt được tuần 11: Hoàn thiện Unit Test cho Backend: roomCrud.js searchRooms.js Hoàn thành E2E Test cho Frontend bằng Cypress: Đăng nhập Tìm kiếm \u0026amp; Lọc Đăng tin Hệ thống ổn định hơn với tỷ lệ bao phủ test đạt khoảng 70%. Xây dựng thành công Data Pipeline \u0026amp; BI: Thiết lập AWS Athena trên dữ liệu xuất từ S3. Viết các câu truy vấn: Giá thuê trung bình theo quận Top 5 phòng có lượt xem cao nhất Xây dựng Dashboard trực quan trên Amazon QuickSight. Hoàn thiện CI/CD tự động: Deploy Frontend tự động (Build → S3 → CloudFront) Rà soát, tối ưu pipeline Backend. Đã rà soát toàn bộ IAM Permissions theo nguyên tắc đặc quyền tối thiểu (Least Privilege). Kết quả tổng thể: Hệ thống đã sẵn sàng ở mức hoàn chỉnh, có đầy đủ kiểm thử, phân tích dữ liệu và triển khai tự động. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Tìm hiểu chuyên sâu về AWS VPC. Hiểu các mô hình bảo mật mạng trong AWS. Nắm được các dịch vụ kết nối mạng nâng cao: VPN, Direct Connect, Load Balancer. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Giới thiệu và tổng quan AWS VPC - Tìm hiểu thành phần VPC: Subnet, Route Table, Internet Gateway, NAT Gateway 06/10/2025 06/10/2025 https://000003.awsstudygroup.com/ 3 - Tìm hiểu Bảo mật VPC: + Security Groups + Network ACLs + Các mô hình bảo mật Layer 3/4 07/10/2025 07/10/2025 https://000003.awsstudygroup.com/ 4 - Tìm hiểu các cơ chế kết nối vào VPC: + Site-to-Site VPN + Client VPN 08/10/2025 08/10/2025 https://000003.awsstudygroup.com/ 5 - Tìm hiểu AWS Direct Connect: + Kiến trúc + Lợi ích + Khi nào sử dụng Direct Connect 09/10/2025 09/10/2025 https://000003.awsstudygroup.com/ 6 - Tìm hiểu Elastic Load Balancer (ELB): + Classic LB + Application LB + Network LB - Kiến trúc cân bằng tải trong hệ thống 10/10/2025 10/10/2025 https://000003.awsstudygroup.com/ Kết quả đạt được tuần 2: Nắm được kiến trúc AWS VPC gồm:\nSubnet (Public / Private) Route Table Internet Gateway / NAT Gateway DHCP, VPC CIDR Hiểu các thành phần bảo mật trong VPC:\nSecurity Group (stateful) Network ACL (stateless) Mô hình phân tầng bảo mật trong hệ thống. Hiểu các phương thức kết nối vào VPC:\nSite-to-Site VPN Client VPN Ưu nhược điểm của từng loại. Hiểu AWS Direct Connect:\nKết nối vật lý chuyên dụng từ on-premises đến AWS Dùng trong hệ thống cần băng thông cao và bảo mật mạnh. Nắm được kiến thức về Load Balancer:\nApplication Load Balancer (layer 7) Network Load Balancer (layer 4) Kiến trúc High Availability \u0026amp; Fault Tolerance. Có khả năng phân tích mô hình mạng AWS và đề xuất kiến trúc phù hợp cho từng trường hợp sử dụng.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Hiểu toàn diện về Amazon EC2 và các loại instance. Biết cách sử dụng AMI, tạo backup, quản lý key pair. Nắm được EBS và các tính năng lưu trữ đi kèm. Hiểu cơ chế Auto Scaling và khả năng mở rộng tài nguyên tự động. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Giới thiệu Amazon EC2 - Tìm hiểu EC2 Instance Types (General, Compute, Memory, Storage Optimized…) 13/10/2025 13/10/2025 https://000004.awsstudygroup.com/ 3 - Tìm hiểu AMI (Amazon Machine Image) - Backup \u0026amp; Restore EC2 - Tạo \u0026amp; quản lý Key Pair 14/10/2025 14/10/2025 https://000013.awsstudygroup.com/ 4 - Tìm hiểu Elastic Block Store (EBS): + Volume types + Snapshot + Gắn/Tháo volume 15/10/2025 15/10/2025 https://cloudjourney.awsstudygroup.com/ 5 - Tìm hiểu EC2 Auto Scaling: + Launch Template + Auto Scaling Group + Scaling Policies 16/10/2025 16/10/2025 https://000006.awsstudygroup.com/ 6 - Tổng hợp kiến thức EC2 - Thực hành thiết lập Auto Scaling Group cơ bản 17/10/2025 17/10/2025 https://000006.awsstudygroup.com/ Kết quả đạt được tuần 3: Hiểu rõ các khái niệm và thành phần của EC2:\nInstance Types và use case từng loại. On-Demand, Reserved, Spot Instances. Làm chủ AMI:\nTạo AMI từ EC2 đang chạy. Sao lưu \u0026amp; phục hồi từ AMI. Xử lý lỗi khi khởi tạo từ AMI. Nắm được cơ chế quản lý Key Pair:\nSSH key pair. Khôi phục EC2 khi mất key pair. Hiểu đầy đủ về EBS:\nCác loại volume (gp2/gp3, io1/io2, st1, sc1). Snapshot \u0026amp; restore. Tăng dung lượng volume. Nắm được Auto Scaling:\nTạo Launch Template. Cấu hình Auto Scaling Group. Hiểu Scaling Policies (Target Tracking, Step Scaling…). Hiểu cơ chế tăng/giảm instance tự động. Sẵn sàng kết hợp EC2 + VPC để triển khai mô hình hạ tầng hoàn chỉnh.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Hiểu về các dịch vụ lưu trữ trên AWS Biết cách triển khai hệ thống Backup, thực hành Import/Export máy ảo và triển khai Storage Gateway Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu Amazon Simple Storage Service (S3) với tính năng Access Point và Storage Class của S3 - Tìm hiểu S3 Static Website \u0026amp; CORS, Control Access, Object Key \u0026amp; Performance, Glacier 20/10/2025 20/10/2025 https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html 3 - Tìm hiểu Snow Family, Storage Gateway, Backup 21/10/2025 21/10/2025 https://docs.aws.amazon.com/AmazonS3/latest/userguide/Welcome.html 4 - Thực hành: triển khai AWS Backup cho hệ thống + Tạo S3 Bucket và triển khai hạ tầng + Tạo Backup Plan, thiết lập thông báo, kiểm tra hoạt động 22/10/2025 22/10/2025 https://000013.awsstudygroup.com/ 5 - Thực hành: Export/Import máy ảo + Chuẩn bị máy ảo + Import máy ảo vào AWS + Export EC2 Instance từ AWS 23/10/2025 23/10/2025 https://000014.awsstudygroup.com/ 6 - Thực hành: + Triển khai file storage gateway: Tạo Storage Gateway, File Shares và kết nối File Shares ở máy On-primise + Thiết lập hệ thống lưu trữ dữ liệu chung cho hạ tầng Windows 24/10/2025 24/10/2025 https://000024.awsstudygroup.com/ Kết quả đạt được tuần 4: Hiểu Amazon Simple Storage Service (S3) là gì và nắm được các nhóm tính năng cơ bản: Amazon S3 Access Point S3 Static Website \u0026amp; CORS Control Access, Object Key \u0026amp; Performance, Glacier Hiểu các dịch vụ Snow Family, Storage Gateway, Backup Đã tạo và cấu hình S3 Bucket và triển khai hạ tầng, thiết lập thông báo và kiểm tra hoạt động thành công. Tạo Storage Gateway, File Shares thành công và có khả năng kết nối file shares ở máy On-premise Có khả năng Import máy ảo vào AWS và export EC2 Instance từ AWS Export máy ảo từ On-premise Tải máy ảo lên AWS Triển khai EC2 Instance từ AMI Có khả năng export EC2 Instance từ AWS Thiết lập ACL cho S3 Bucket Export máy ảo từ EC2 Instance Thiết lập hệ thống lưu trữ dữ liệu chung cho hạ tầng Windows: Tạo môi trường thực hành để tạo file share mới Kiểm tra và giám sát hiệu năng Kích hoạt các các thành phần để có thể triển khai FSX trên Windows như: hạn ngạch bộ nhớ của người dùng, chia sẻ truy cập liên tục,\u0026hellip; "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Hiểu các dịch vụ bảo mật cốt lõi trên AWS Thực hành cấu hình Security Hub, tối ưu EC2 và quản lý tài nguyên bằng Tag/IAM. Thiết lập IAM User/Group/Role, Permission Boundary và xác định mục tiêu – kiến trúc đề tài. Chọn đề tài dự án và xác định các yêu cầu của dự án Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Làm quen với các dịch vụ bảo mật trên AWS: + Mô hình chia sẻ trải nghiệm + Amazon Cognito + AWS Organization + AWS Identity Center (SSO) + AWS KMS 03/11/2025 03/11/2025 3 - Thực hành: + Kích hoạt Security Hub và kiểm tra đánh giá theo từng bộ tiêu chuẩn + Tối ưu chi phí EC2 với Lambda 04/11/2025 04/11/2025 https://000018.awsstudygroup.com/ https://000022.awsstudygroup.com/ 4 - Thực hành: + Quản lý tài nguyên bằng Tag và Resource Groups + Quản lý truy cập vào dịch vụ EC2 resource tag với AWS IAM 05/11/2025 05/11/2025 https://000027.awsstudygroup.com/ https://000028.awsstudygroup.com/ 5 - - Thực hành: + Giới hạn quyền của User với IAM permission boundary + Mã hóa ở trạng thái lưu trữ với AWS KMS 06/11/2025 06/11/2025 https://000030.awsstudygroup.com/ https://000033.awsstudygroup.com/ 6 - Chọn đề tài và xác định mục tiêu của đề tài - Thiết kế kiến trúc hệ thống - Thực hành: + Tạo IAM Group và IAM user và cấu hình Role Condition + Cấp quyền cho ứng dụng truy cập dịch vụ AWS với IAM Role 07/11/2025 09/11/2025 https://000044.awsstudygroup.com/ https://000048.awsstudygroup.com/ Kết quả đạt được tuần 5: Hiểu và nắm được các nhóm dịch vụ bảo mật trên AWS: Mô hình chia sẻ trải nghiệm (Share Responsibility Model) Amazon Identity and access management Amazon Cognito AWS Organization AWS Identity Center (SSO) AWS KMS Thực hành và vận hành các dịch vụ bảo mật Kích hoạt và làm quen với AWS Security Hub. Thực hiện kiểm tra, đánh giá bảo mật theo các bộ tiêu chuẩn và AWS Best Practices. Nhận diện được các nhóm cảnh báo (Findings) và mức độ ưu tiên xử lý. Thực hành tối ưu chi phí EC2 bằng cách sử dụng AWS Lambda để tự động tắt/bật EC2 theo lịch. Xác định được những tài nguyên không cần thiết có thể tối ưu. Quản lý tài nguyên AWS bằng Tag và Resource Groups Thiết lập hệ thống Tag chuẩn (Environment, Owner, Project, CostCenter). Áp dụng Tag cho EC2, S3, Lambda và các tài nguyên khác. Tạo Resource Groups để theo dõi và quản lý tài nguyên theo từng nhóm hoặc dự án Quản lý truy cập bằng IAM và điều kiện Tag Cấu hình chính sách IAM theo điều kiện (Condition) gắn với Tag. Giới hạn quyền truy cập EC2 theo Resource Tag nhằm đảm bảo phân tách môi trường và giảm rủi ro thao tác nhầm lẫn. Giới hạn quyền người dùng bằng Permission Boundary Thiết lập Permission Boundary cho IAM User/Role. Đảm bảo người dùng không thể tự cấp quyền vượt giới hạn cho phép. Mã hóa dữ liệu với AWS KMS Cấu hình mã hóa dữ liệu ở trạng thái lưu trữ (at-rest) cho S3, EBS và các dịch vụ liên quan. Tạo và quản lý Key, phân quyền sử dụng Key thông qua chính sách KMS. Lựa chọn được đề tài dự án và xác định mục tiêu, phạm vi và yêu cầu đầu ra của đề tài Phác thảo kiến trúc tổng quan ứng dụng/dự án. Xác định các dịch vụ AWS sử dụng, quy trình phân quyền, mã hóa và logging. Thực hành IAM nâng cao Tạo IAM Group và IAM User tương ứng với từng nhóm chức năng. Cấu hình IAM Role và thiết lập các điều kiện truy cập (IP/Tag/Time). Cấp quyền cho ứng dụng truy cập vào dịch vụ AWS thông qua IAM Role. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Thiết lập kiến trúc dự án theo mô hình Monorepo. Xây dựng hạ tầng ban đầu bằng IaC (Infrastructure as Code) với AWS SAM. Hoàn thiện Backend MVP cho chức năng CREATE phòng. Thiết kế giao diện mockup định hướng cho Frontend. Thiết lập CI/CD cơ bản chuẩn bị cho giai đoạn triển khai. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tạo cấu trúc Monorepo: backend/, frontend/, infrastructure/ - Hoàn thành template.yaml (IaC): DynamoDB + 2 Lambda (CRUD \u0026amp; Search) - Chạy sam build 03/11/2025 03/11/2025 https://docs.aws.amazon.com/serverless-application-model/ 3 - Viết backend MVP cho roomCrud.js: chức năng CREATE - Cấu hình package.json cho backend (aws-sdk, node-fetch) 04/11/2025 04/11/2025 https://docs.aws.amazon.com/lambda/ 4 - Thiết kế giao diện dạng wireframe/mockup cho Home, Search, Post Room (không code UI) 05/11/2025 05/11/2025 https://www.figma.com 5 - Thiết lập CI/CD: + Cấu hình AWS Secrets trên GitHub + Viết nháp deploy-backend.yml 06/11/2025 06/11/2025 https://docs.github.com/en/actions Kết quả đạt được tuần 6: Thiết lập thành công cấu trúc Monorepo chuẩn chỉnh: backend/, frontend/, infrastructure/. Hoàn thiện file IaC template.yaml: 1 DynamoDB Table: Rooms 2 Lambda Functions: roomCrud.js và searchRooms.js Chạy sam build thành công — xác nhận hạ tầng sẵn sàng triển khai. Backend MVP hoàn thành chức năng CREATE Room với Lambda roomCrud.js. Thiết kế mockup các trang Home, Search \u0026amp; Post Room → thống nhất bố cục và UI đầu tiên. Thiết lập CI/CD bước đầu: Thêm Secrets AWS trên GitHub Tạo file nháp deploy-backend.yml Kết quả chung: Nền tảng IaC hoàn thiện, backend CRUD (CREATE) hoạt động và hệ thống đã sẵn sàng để triển khai trong tuần tiếp theo. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Triển khai hạ tầng AWS cho dự án (Lambda, API Gateway, DynamoDB). Xây dựng Frontend MVP (Base UI) và hoàn thiện form đăng tin. Tích hợp API giữa Frontend ↔ API Gateway ↔ Lambda ↔ DynamoDB. Viết các chức năng backend cơ bản phục vụ tính năng tìm kiếm phòng. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Deployment hạ tầng AWS bằng sam deploy lần đầu - Tạo Lambda, API Gateway, DynamoDB - Thêm API Gateway Endpoint vào frontend/.env.local 10/11/2025 10/11/2025 https://cloudjourney.awsstudygroup.com/ 3 - Code giao diện Layout (layout.js) - Code giao diện Trang Đăng tin (post-room/page.js) - Cài đặt \u0026amp; cấu hình Tailwind CSS 11/11/2025 11/11/2025 4 - Viết API Proxy trong Next.js tại frontend/api/proxy/ 12/11/2025 12/11/2025 https://nextjs.org/docs 5 - Tích hợp form đăng tin: kết nối trang post-room với Lambda roomCrud.js thông qua API Proxy 13/11/2025 13/11/2025 https://docs.aws.amazon.com/lambda/ 6 - Viết backend cho tìm kiếm phòng: tạo file searchRooms.js (chức năng READ – lấy tất cả phòng từ DynamoDB) 14/11/2025 14/11/2025 https://docs.aws.amazon.com/amazondynamodb/ 7 - Kiểm thử toàn bộ luồng: Frontend → API Proxy → API Gateway → Lambda → DynamoDB - Fix lỗi và hoàn thiện MVP 15/11/2025 15/11/2025 Kết quả đạt được tuần 7: Triển khai hạ tầng AWS thành công bằng sam deploy (Lambda, DynamoDB, API Gateway). Cấu hình môi trường Frontend (.env.local) với API Gateway Endpoint. Hoàn thiện giao diện cơ bản (MVP): Layout Trang đăng tin (post-room) Tailwind CSS hoạt động ổn định Viết API Proxy trong Next.js để kết nối với Lambda. Tích hợp thành công form đăng tin: Gửi dữ liệu → API Proxy → API Gateway → Lambda → DynamoDB. Hoàn thiện backend xử lý tìm kiếm cơ bản (searchRooms.js – READ). Toàn bộ hệ thống đã có thể: Truy cập website Đăng tin phòng Lưu dữ liệu vào DynamoDB thành công "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Tích hợp bản đồ và geocoding vào hệ thống để hiển thị vị trí phòng. Hoàn thiện chức năng tìm kiếm \u0026amp; lọc theo nhiều tiêu chí. Kiểm thử toàn bộ chức năng chính trước khi chuyển sang giai đoạn tiếp theo. Chuẩn bị Proposal Review (nếu cần). Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Backend: Tích hợp Vietmap Geocoding API trong roomCrud.js để lưu tọa độ khi đăng tin - Frontend: Tích hợp Vietmap-gl trong RoomMap.js 17/11/2025 17/11/2025 https://maps.vietmap.vn/ 3 - Backend: Hoàn thiện logic lọc theo giá, quận, khoảng cách trong searchRooms.js 18/11/2025 18/11/2025 https://docs.aws.amazon.com/amazondynamodb/ 4 - Frontend: Xây dựng trang Search (search/page.js) hoàn chỉnh với filters - Hiển thị kết quả trên bản đồ + danh sách 19/11/2025 19/11/2025 https://nextjs.org/docs 5 - Kiểm thử thủ công: đăng tin (đã tích hợp tọa độ), tìm kiếm, lọc 20/11/2025 20/11/2025 6 - Xây dựng Proposal Review: Tổng hợp tính năng đã hoàn thành, chuẩn bị tài liệu/trình bày (nếu cần) 21/11/2025 21/11/2025 Kết quả đạt được tuần 8: Tích hợp thành công Vietmap Geocoding:\nKhi đăng tin, hệ thống tự động lấy tọa độ (lat/lng). Lưu vào DynamoDB qua Lambda. Frontend đã hiển thị bản đồ bằng Vietmap-gl, có thể hiển thị vị trí phòng trên bản đồ.\nHoàn thiện chức năng tìm kiếm \u0026amp; lọc:\nLọc theo giá Lọc theo quận Lọc theo khoảng cách Tối ưu truy vấn trong Lambda searchRooms.js Trang Search đã hoàn chỉnh:\nGiao diện filters Danh sách kết quả Hiển thị vị trí trên bản đồ Kiểm thử:\nĐăng tin → lấy tọa độ → hiển thị đúng Tìm kiếm và lọc chạy đúng logic UI + API hoạt động đồng bộ Hệ thống tìm kiếm + bản đồ đã hoạt động hoàn chỉnh — cốt lõi của ứng dụng đã chạy ổn định.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Hoàn thiện hệ thống xác thực người dùng bằng AWS Cognito. Phân quyền cơ bản giữa User và Owner. Xây dựng chức năng Chat và Favorite (Yêu thích). Tối ưu trải nghiệm người dùng với giao diện Responsive. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - AWS Cognito Setup: Tạo User Pool và App Client - Tích hợp AWS Amplify vào Next.js 24/11/2025 24/11/2025 https://docs.aws.amazon.com/cognito/ 3 - Xây dựng UI cho Sign Up / Sign In (sử dụng component/form thư viện) - Thiết lập Cognito Groups để phân quyền User vs Owner 25/11/2025 25/11/2025 https://docs.amplify.aws/ 4 - Backend: Hoàn thiện logic chatMessage.js (Lưu/Lấy tin nhắn giữa 2 user) - Backend: Hoàn thiện logic favorite.js (Thêm/Xóa phòng yêu thích) 26/11/2025 26/11/2025 https://docs.aws.amazon.com/lambda/ 5 - Frontend: Xây dựng Chat Modal/Page (ChatModal.js, chat/page.js) - Frontend: Tích hợp nút Favorite trên RoomCard.js 27/11/2025 27/11/2025 https://nextjs.org/docs 6 - Tối ưu hóa UI: đảm bảo các trang chính Responsive (Mobile-first) 28/11/2025 28/11/2025 7 - Kiểm thử toàn bộ luồng: Đăng ký → Đăng nhập → Chat → Favorite → Phân quyền 29/11/2025 29/11/2025 Kết quả đạt được tuần 9: Tích hợp thành công AWS Cognito: User có thể Đăng ký / Đăng nhập. Hoàn thiện chức năng Chat mini: Lưu và lấy tin nhắn giữa 2 người dùng. Giao diện Chat Modal hoạt động ổn định. Hoàn thiện chức năng Favorite (Yêu thích): Thêm/Xóa phòng yêu thích. Hiển thị trạng thái yêu thích trên RoomCard. Giao diện được tối ưu Responsive, hoạt động tốt trên Tablet và Desktop. Kết quả tổng thể: Hệ thống đã có đầy đủ tính năng tương tác người dùng (Auth, Chat, Favorite). "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"Roommate Giải pháp AWS Serverless hợp nhất cho quản lý và tìm kiếm phòng trọ theo thời gian thực 1. Tóm tắt điều hành RoomMate là một nền tảng tìm kiếm và quản lý phòng trọ được thiết kế cho sinh viên và chủ trọ, tận dụng tối đa kiến trúc Serverless và AWS Free Tier. Nền tảng cho phép chủ trọ dễ dàng đăng tin, quản lý dữ liệu phòng trọ (thêm, sửa, xóa) và nhận báo cáo định kỳ. Sinh viên có thể tìm kiếm, lọc theo nhiều tiêu chí (vị trí, giá, tiện ích), lưu phòng yêu thích và trò chuyện trực tiếp với chủ trọ qua tính năng chat mini tích hợp. Kiến trúc sử dụng Next.js cho giao diện người dùng, API Gateway + Lambda cho backend, DynamoDB để lưu trữ dữ liệu chính,\u0026hellip; để xác thực an toàn. Điểm khác biệt là việc tích hợp openAI để tự động hóa các tác vụ như gửi thông báo email/Telegram khi có phòng mới phù hợp hoặc tạo báo cáo thống kê, giúp tăng tính tương tác và độ tin cậy của hệ thống.\n2. Tuyên bố vấn đề Vấn đề hiện tại\nCác phương thức tìm phòng trọ truyền thống (bảng tin, nhóm mạng xã hội) thường thiếu hệ thống lọc chi tiết, thông tin không tập trung, và dễ bị nhiễu bởi tin rác. Việc liên hệ giữa sinh viên và chủ trọ thường phải qua điện thoại/Zalo, tạo ra \u0026ldquo;friction\u0026rdquo; (rào cản giao tiếp) và khó theo dõi lịch sử. Thiếu cơ chế thông báo tự động khi có phòng mới phù hợp với nhu cầu cụ thể của sinh viên. Chủ trọ thiếu công cụ phân tích về nhu cầu thị trường, số lượng người xem tin đăng để tối ưu hóa việc cho thuê. Giải pháp\nNền tảng RoomMate cung cấp một giải pháp tìm kiếm và quản lý trọ tập trung, tích hợp tính năng chat mini nội bộ và thông báo tự động (qua n8n) dựa trên tiêu chí cá nhân.\nKiến trúc Serverless AWS: Sử dụng API Gateway + Lambda, DynamoDB (cho dữ liệu phòng, user, chat), và S3 (cho hình ảnh) để đảm bảo khả năng mở rộng (scale) với chi phí tối ưu (tận dụng Free Tier). Tính năng nổi bật: Khác biệt so với các ứng dụng chat/rao vặt chung chung, RoomMate tập trung vào trải nghiệm tốt cho người thuê khi áp dụng chatbot AI để gợi ý các phòng trọ theo yêu cầu cá nhân. Lợi ích và hoàn vốn đầu tư (ROI)\nLợi ích: Cung cấp giải pháp rất thực tế cho sinh viên. Giảm rào cản giao tiếp (friction) giữa hai bên qua chat nội bộ. Tạo nền tảng có tính mở rộng cao (dễ dàng thêm bản đồ, review). Đảm bảo đạt đủ 5 mục tiêu cốt lõi của một dự án công nghệ (serverless, CI/CD, monitoring, security, data pipeline). Hoàn vốn đầu tư (ROI): Chi phí phát triển và vận hành cực thấp do tận dụng tối đa AWS Free Tier (Lambda, DynamoDB, S3), giảm thiểu chi phí quản lý server. Giá trị mang lại là một sản phẩm hoàn chỉnh, thiết thực, có khả năng nổi bật nhờ tính năng tự động hóa và chat nội bộ. 3. Kiến trúc giải pháp Nền tảng ứng dụng kiến trúc AWS Serverless để xây dựng hệ thống quản lý và phân tích dữ liệu. Hệ thống sử dụng Amazon API Gateway và AWS Lambda để xử lý nghiệp vụ. Giao diện web được phân phối toàn cầu qua CloudFront, hoạt động như điểm truy cập duy nhất cho cả nội dung tĩnh và các yêu cầu API. Dữ liệu được lưu trữ an toàn trong Amazon S3 (cho file/hình ảnh) với các bucket được bảo vệ, trong khi Amazon DynamoDB đảm nhiệm lưu trữ dữ liệu cấu trúc. Quy trình triển khai được tự động hóa hoàn toàn thông qua AWS CodePipeline lấy mã nguồn từ GitHub. Toàn bộ hoạt động được giám sát bằng Amazon CloudWatch.\nDịch vụ AWS sử dụng\nAWS Lambda: Thực thi các hàm xử lý nghiệp vụ (Backend Business Logic). Amazon API Gateway: Tiếp nhận, xác thực và định tuyến các yêu cầu API từ ứng dụng web đến AWS Lambda. Amazon S3: S3 - Frontend lưu trữ nội dung tĩnh của ứng dụng web (đích đến của CodePipeline). S3 - Image Storage lưu trữ dữ liệu file và hình ảnh với cơ chế bảo vệ (S3 - Protected). Amazon DynamoDB: Lưu trữ dữ liệu cấu trúc (NoSQL), bao gồm dữ liệu người dùng và thông tin thiết bị. AWS CodePipeline: Tự động hóa quy trình CI/CD cho toàn bộ hệ thống, triển khai giao diện web lên S3 - Frontend. Amazon Cognito: Quản lý danh tính và quyền truy cập (xác thực) cho người dùng, bảo vệ API Gateway. Amazon CloudFront: Phân phối nội dung toàn cầu cho ứng dụng web (từ S3 - Frontend) và định tuyến các yêu cầu API đến API Gateway. Amazon CloudWatch: Giám sát, ghi log và cung cấp cảnh báo cho toàn bộ hệ thống. Thiết kế thành phần\nGiao diện người dùng: Ứng dụng web được lưu trữ tại S3 - Frontend và phân phối toàn cầu thông qua CloudFront. Tầng API: API Gateway kết hợp Lambda xử lý các yêu cầu nghiệp vụ sau khi người dùng được xác thực bởi Cognito. Lưu trữ dữ liệu: Dữ liệu file và hình ảnh lưu trong S3 - Image Storage (B3 - Image Storage). Dữ liệu cấu trúc, người dùng và thiết bị lưu trong DynamoDB. Pipeline triển khai: AWS CodePipeline tự động hóa việc build, test và deploy các thay đổi từ GitHub đến S3 Frontend và các tài nguyên Lambda/API Gateway. Bảo mật \u0026amp; Giám sát: Dữ liệu trong S3 được bảo vệ. Toàn bộ hoạt động hệ thống được giám sát qua Amazon CloudWatch, và quyền truy cập được quản lý bởi Amazon Cognito. 4. Triển khai kỹ thuật Các giai đoạn triển khai\nDự án được triển khai theo 4 giai đoạn:\nNghiên cứu \u0026amp; thiết kế kiến trúc: Tìm hiểu API Gateway, Lambda, DynamoDB, S3, CloudFront, Cognito và CodePipeline. Thiết kế kiến trúc Serverless theo mô hình phân lớp (Frontend – API – Data – CI/CD). Ước tính chi phí \u0026amp; đánh giá khả thi: Sử dụng AWS Pricing Calculator để ước tính chi phí của S3, Lambda, API Gateway, DynamoDB và CloudFront. Điều chỉnh kiến trúc dựa trên chi phí dự kiến và yêu cầu bảo mật. Tối ưu kiến trúc \u0026amp; quy trình triển khai: Tối ưu luồng API Gateway → Lambda → DynamoDB, tinh chỉnh CloudFront cho phân phối toàn cầu, thiết lập S3 nhiều bucket (Frontend và Image Storage) và cấu hình CodePipeline để rút ngắn thời gian triển khai. Phát triển – kiểm thử – triển khai: Phát triển backend Lambda, xây dựng API Gateway, lập trình giao diện web và upload lên S3–Frontend, tạo DynamoDB schema, thiết lập Cognito, hoàn thiện CodePipeline, kiểm thử end-to-end và đưa hệ thống vào vận hành. Yêu cầu kỹ thuật\nỨng dụng Web \u0026amp; Phân phối nội dung\nỨng dụng web phải build dạng static để lưu trữ tại S3 – Frontend. CloudFront bắt buộc cấu hình để phân phối nội dung toàn cầu và định tuyến API đến API Gateway. File và hình ảnh người dùng phải được lưu tại S3 – Image Storage với chính sách bảo vệ. Tầng API \u0026amp; Logic xử lý\nTất cả yêu cầu API đi qua API Gateway, được xác thực bằng Cognito User Pool. AWS Lambda xử lý nghiệp vụ backend (CRUD dữ liệu, upload metadata, validate thông tin…). API phải tuân theo mô hình REST và trả về JSON. Lưu trữ dữ liệu\nDữ liệu cấu trúc phải lưu trong DynamoDB, thiết kế bảng hỗ trợ truy vấn nhanh (Partition Key / Sort Key). Bucket S3 phải cấu trúc thành 2 phần: S3 – Frontend: chứa file build của trang web. S3 – Image Storage: chứa file người dùng upload, có quyền truy cập giới hạn qua presigned URL. CI/CD và Tự động hóa\nToàn bộ quá trình build – test – deploy được tự động qua AWS CodePipeline, nguồn từ GitHub. Pipeline phải triển khai đồng thời frontend (S3–Frontend) và backend (Lambda + API Gateway). Mỗi thay đổi cần được theo dõi qua CloudWatch Logs. Bảo mật \u0026amp; Giám sát\nAmazon Cognito quản lý đăng nhập và phân quyền. CloudWatch theo dõi log Lambda, cảnh báo lỗi API Gateway, và giám sát trạng thái hệ thống. S3 phải bật chính sách bảo mật (Block Public Access). API phải yêu cầu xác thực, chỉ CloudFront được phép truy cập trực tiếp. 5. Lộ trình \u0026amp; Mốc triển khai Trước thực tập (Tháng 0): 1 tháng lên kế hoạch và đánh giá trạm cũ. Thực tập (Tháng 1–3): Tháng 1: Học các kiến thức cơ bản của AWS. Nắm vững các kiến thức cơ bản và một số dịch vụ AWS nền tảng (API Gateway, S3, Lambda,\u0026hellip; ) Hoàn thiện kiến thức về CI/CD, logging và security cơ bản. Tháng 2: Thiết kế và điều chỉnh kiến trúc. Thiết kế kiến trúc tổng thể của hệ thống. Tối ưu các thành phần: frontend hosting, backend API, storage, bảo mật. Điều chỉnh mô hình theo phản hồi từ mentor và yêu cầu thực tế. Tháng 3: Triển khai, kiểm thử, đưa vào sử dụng. Triển khai hạ tầng trên AWS theo kiến trúc đã hoàn thiện. Kiểm thử chức năng và hiệu năng (unit test, integration test). Khắc phục lỗi, tối ưu chi phí và tài nguyên. Đưa hệ thống vào vận hành thử nghiệm (pilot). Sau triển khai: Nghiên cứu thêm trong vòng 1 năm. Theo dõi, tối ưu và bảo trì hệ thống định kỳ. Nghiên cứu thêm các dịch vụ nâng cao (Auto Scaling, WAF, CloudFormation, EKS…). Đề xuất các cải tiến và tính năng mới dựa trên nhu cầu thực tế. 6. Ước tính ngân sách Có thể xem chi phí trên AWS Pricing Calculator\nHoặc tải tệp ước tính ngân sách.\nChi phí hạ tầng\nAWS CloudFront: 0.00 (20-50 GB). AWS Lambda: 0,00 USD/tháng (50.000 request, 100GB lưu trữ). S3 - Fontend bucket: 0,00 USD/tháng (6 GB). S3 - Image Storage: 0.35-0.6 USD/tháng (15-25 GB). Amazon API Gateway: 0.02 USD/tháng (20.000 request). Amazon DynamoDB: 0.00 USD/tháng (\u0026lt;10.000 read/write, \u0026lt; 1GB). Amazon Cognito: 0.00 USD ( \u0026lt; 50 User). AWS CodePipeline (CI/CD từ GitHub): 0 USD (20-50 build/tháng). Amazon CloudWatch Logs: 0.5-3.0 (2-15 GB Logs). Tổng: 0,87-1.12 USD/tháng, 10.44-13.44 USD/12 tháng.\n7. Đánh giá rủi ro Ma trận rủi ro\nMất mạng: Ảnh hưởng trung bình, xác suất trung bình. Vượt ngân sách: Ảnh hưởng trung bình, xác suất thấp. Lỗi chatbox realtime: Ảnh hưởng trung bình, xác suất trung bình Lỗi tích hợp bản đồ hoặc hết hạn key: Ảnh hưởng trung bình, xác suất thấp Chiến lược giảm thiểu\nMạng: Lưu trữ cục bộ trên Raspberry Pi với Docker. Cảm biến: Kiểm tra định kỳ, dự phòng linh kiện. Chi phí: Cảnh báo ngân sách AWS, tối ưu dịch vụ. Kế hoạch dự phòng\nQuay lại thu thập thủ công nếu AWS gặp sự cố. Sử dụng CloudFormation để khôi phục cấu hình liên quan đến chi phí. Chuyển sang chế độ hiển thị địa chỉ dạng text hoặc sử dụng API dự phòng (Mapbox / OpenStreetMap). Khi chatbox bị gián đoạn, tự động chuyển sang form liên hệ hoặc tin nhắn offline. 8. Kết quả kỳ vọng Cải tiến kỹ thuật: Dữ liệu và phân tích thời gian thực thay thế quy trình thủ công. Có thể mở rộng tới 10–15 trạm.\nGiá trị dài hạn: Nền tảng dữ liệu 1 năm cho nghiên cứu AI, có thể tái sử dụng cho các dự án tương lai.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.2-prerequiste/","title":"Các bước chuẩn bị","tags":[],"description":"","content":"IAM permissions Gắn IAM permission policy sau vào tài khoản aws user của bạn để triển khai và dọn dẹp tài nguyên trong workshop này.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;VisualEditor0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:AcceptTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:AllocateAddress\u0026#34;, \u0026#34;ec2:AssociateAddress\u0026#34;, \u0026#34;ec2:AssociateIamInstanceProfile\u0026#34;, \u0026#34;ec2:AssociateRouteTable\u0026#34;, \u0026#34;ec2:AssociateSubnetCidrBlock\u0026#34;, \u0026#34;ec2:AssociateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:AssociateVpcCidrBlock\u0026#34;, \u0026#34;ec2:AttachInternetGateway\u0026#34;, \u0026#34;ec2:AttachNetworkInterface\u0026#34;, \u0026#34;ec2:AttachVolume\u0026#34;, \u0026#34;ec2:AttachVpnGateway\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:AuthorizeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:CreateClientVpnEndpoint\u0026#34;, \u0026#34;ec2:CreateClientVpnRoute\u0026#34;, \u0026#34;ec2:CreateCustomerGateway\u0026#34;, \u0026#34;ec2:CreateDhcpOptions\u0026#34;, \u0026#34;ec2:CreateFlowLogs\u0026#34;, \u0026#34;ec2:CreateInternetGateway\u0026#34;, \u0026#34;ec2:CreateLaunchTemplate\u0026#34;, \u0026#34;ec2:CreateNetworkAcl\u0026#34;, \u0026#34;ec2:CreateNetworkInterface\u0026#34;, \u0026#34;ec2:CreateNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:CreateRoute\u0026#34;, \u0026#34;ec2:CreateRouteTable\u0026#34;, \u0026#34;ec2:CreateSecurityGroup\u0026#34;, \u0026#34;ec2:CreateSubnet\u0026#34;, \u0026#34;ec2:CreateSubnetCidrReservation\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateTransitGateway\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:CreateTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRoute\u0026#34;, \u0026#34;ec2:CreateTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:CreateTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:CreateVpc\u0026#34;, \u0026#34;ec2:CreateVpcEndpoint\u0026#34;, \u0026#34;ec2:CreateVpcEndpointConnectionNotification\u0026#34;, \u0026#34;ec2:CreateVpcEndpointServiceConfiguration\u0026#34;, \u0026#34;ec2:CreateVpnConnection\u0026#34;, \u0026#34;ec2:CreateVpnConnectionRoute\u0026#34;, \u0026#34;ec2:CreateVpnGateway\u0026#34;, \u0026#34;ec2:DeleteCustomerGateway\u0026#34;, \u0026#34;ec2:DeleteFlowLogs\u0026#34;, \u0026#34;ec2:DeleteInternetGateway\u0026#34;, \u0026#34;ec2:DeleteNetworkInterface\u0026#34;, \u0026#34;ec2:DeleteNetworkInterfacePermission\u0026#34;, \u0026#34;ec2:DeleteRoute\u0026#34;, \u0026#34;ec2:DeleteRouteTable\u0026#34;, \u0026#34;ec2:DeleteSecurityGroup\u0026#34;, \u0026#34;ec2:DeleteSubnet\u0026#34;, \u0026#34;ec2:DeleteSubnetCidrReservation\u0026#34;, \u0026#34;ec2:DeleteTags\u0026#34;, \u0026#34;ec2:DeleteTransitGateway\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPeeringAttachment\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayPrefixListReference\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRoute\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayRouteTable\u0026#34;, \u0026#34;ec2:DeleteTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:DeleteVpc\u0026#34;, \u0026#34;ec2:DeleteVpcEndpoints\u0026#34;, \u0026#34;ec2:DeleteVpcEndpointServiceConfigurations\u0026#34;, \u0026#34;ec2:DeleteVpnConnection\u0026#34;, \u0026#34;ec2:DeleteVpnConnectionRoute\u0026#34;, \u0026#34;ec2:Describe*\u0026#34;, \u0026#34;ec2:DetachInternetGateway\u0026#34;, \u0026#34;ec2:DisassociateAddress\u0026#34;, \u0026#34;ec2:DisassociateRouteTable\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:GetTransitGatewayAttachmentPropagations\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34;, \u0026#34;ec2:ModifySecurityGroupRules\u0026#34;, \u0026#34;ec2:ModifyTransitGatewayVpcAttachment\u0026#34;, \u0026#34;ec2:ModifyVpcAttribute\u0026#34;, \u0026#34;ec2:ModifyVpcEndpoint\u0026#34;, \u0026#34;ec2:ReleaseAddress\u0026#34;, \u0026#34;ec2:ReplaceRoute\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupEgress\u0026#34;, \u0026#34;ec2:RevokeSecurityGroupIngress\u0026#34;, \u0026#34;ec2:RunInstances\u0026#34;, \u0026#34;ec2:StartInstances\u0026#34;, \u0026#34;ec2:StopInstances\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsEgress\u0026#34;, \u0026#34;ec2:UpdateSecurityGroupRuleDescriptionsIngress\u0026#34;, \u0026#34;iam:AddRoleToInstanceProfile\u0026#34;, \u0026#34;iam:AttachRolePolicy\u0026#34;, \u0026#34;iam:CreateInstanceProfile\u0026#34;, \u0026#34;iam:CreatePolicy\u0026#34;, \u0026#34;iam:CreateRole\u0026#34;, \u0026#34;iam:DeleteInstanceProfile\u0026#34;, \u0026#34;iam:DeletePolicy\u0026#34;, \u0026#34;iam:DeleteRole\u0026#34;, \u0026#34;iam:DeleteRolePolicy\u0026#34;, \u0026#34;iam:DetachRolePolicy\u0026#34;, \u0026#34;iam:GetInstanceProfile\u0026#34;, \u0026#34;iam:GetPolicy\u0026#34;, \u0026#34;iam:GetRole\u0026#34;, \u0026#34;iam:GetRolePolicy\u0026#34;, \u0026#34;iam:ListPolicyVersions\u0026#34;, \u0026#34;iam:ListRoles\u0026#34;, \u0026#34;iam:PassRole\u0026#34;, \u0026#34;iam:PutRolePolicy\u0026#34;, \u0026#34;iam:RemoveRoleFromInstanceProfile\u0026#34;, \u0026#34;lambda:CreateFunction\u0026#34;, \u0026#34;lambda:DeleteFunction\u0026#34;, \u0026#34;lambda:DeleteLayerVersion\u0026#34;, \u0026#34;lambda:GetFunction\u0026#34;, \u0026#34;lambda:GetLayerVersion\u0026#34;, \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;lambda:PublishLayerVersion\u0026#34;, \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:DeleteLogGroup\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:PutRetentionPolicy\u0026#34;, \u0026#34;route53:ChangeTagsForResource\u0026#34;, \u0026#34;route53:CreateHealthCheck\u0026#34;, \u0026#34;route53:CreateHostedZone\u0026#34;, \u0026#34;route53:CreateTrafficPolicy\u0026#34;, \u0026#34;route53:DeleteHostedZone\u0026#34;, \u0026#34;route53:DisassociateVPCFromHostedZone\u0026#34;, \u0026#34;route53:GetHostedZone\u0026#34;, \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53domains:ListDomains\u0026#34;, \u0026#34;route53domains:ListOperations\u0026#34;, \u0026#34;route53domains:ListTagsForDomain\u0026#34;, \u0026#34;route53resolver:AssociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:AssociateResolverRule\u0026#34;, \u0026#34;route53resolver:CreateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:CreateResolverRule\u0026#34;, \u0026#34;route53resolver:DeleteResolverEndpoint\u0026#34;, \u0026#34;route53resolver:DeleteResolverRule\u0026#34;, \u0026#34;route53resolver:DisassociateResolverEndpointIpAddress\u0026#34;, \u0026#34;route53resolver:DisassociateResolverRule\u0026#34;, \u0026#34;route53resolver:GetResolverEndpoint\u0026#34;, \u0026#34;route53resolver:GetResolverRule\u0026#34;, \u0026#34;route53resolver:ListResolverEndpointIpAddresses\u0026#34;, \u0026#34;route53resolver:ListResolverEndpoints\u0026#34;, \u0026#34;route53resolver:ListResolverRuleAssociations\u0026#34;, \u0026#34;route53resolver:ListResolverRules\u0026#34;, \u0026#34;route53resolver:ListTagsForResource\u0026#34;, \u0026#34;route53resolver:UpdateResolverEndpoint\u0026#34;, \u0026#34;route53resolver:UpdateResolverRule\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:CreateBucket\u0026#34;, \u0026#34;s3:DeleteBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:GetAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketOwnershipControls\u0026#34;, \u0026#34;s3:GetBucketPolicy\u0026#34;, \u0026#34;s3:GetBucketPolicyStatus\u0026#34;, \u0026#34;s3:GetBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34;, \u0026#34;s3:GetBucketVersioning\u0026#34;, \u0026#34;s3:ListAccessPoints\u0026#34;, \u0026#34;s3:ListAccessPointsForObjectLambda\u0026#34;, \u0026#34;s3:ListAllMyBuckets\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:ListBucketMultipartUploads\u0026#34;, \u0026#34;s3:ListBucketVersions\u0026#34;, \u0026#34;s3:ListJobs\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34;, \u0026#34;s3:ListMultiRegionAccessPoints\u0026#34;, \u0026#34;s3:ListStorageLensConfigurations\u0026#34;, \u0026#34;s3:PutAccountPublicAccessBlock\u0026#34;, \u0026#34;s3:PutBucketAcl\u0026#34;, \u0026#34;s3:PutBucketPolicy\u0026#34;, \u0026#34;s3:PutBucketPublicAccessBlock\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;secretsmanager:CreateSecret\u0026#34;, \u0026#34;secretsmanager:DeleteSecret\u0026#34;, \u0026#34;secretsmanager:DescribeSecret\u0026#34;, \u0026#34;secretsmanager:GetSecretValue\u0026#34;, \u0026#34;secretsmanager:ListSecrets\u0026#34;, \u0026#34;secretsmanager:ListSecretVersionIds\u0026#34;, \u0026#34;secretsmanager:PutResourcePolicy\u0026#34;, \u0026#34;secretsmanager:TagResource\u0026#34;, \u0026#34;secretsmanager:UpdateSecret\u0026#34;, \u0026#34;sns:ListTopics\u0026#34;, \u0026#34;ssm:DescribeInstanceProperties\u0026#34;, \u0026#34;ssm:DescribeSessions\u0026#34;, \u0026#34;ssm:GetConnectionStatus\u0026#34;, \u0026#34;ssm:GetParameters\u0026#34;, \u0026#34;ssm:ListAssociations\u0026#34;, \u0026#34;ssm:ResumeSession\u0026#34;, \u0026#34;ssm:StartSession\u0026#34;, \u0026#34;ssm:TerminateSession\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Khởi tạo tài nguyên bằng CloudFormation Trong lab này, chúng ta sẽ dùng N.Virginia region (us-east-1).\nĐể chuẩn bị cho môi trường làm workshop, chúng ta deploy CloudFormation template sau (click link): PrivateLinkWorkshop . Để nguyên các lựa chọn mặc định.\nLựa chọn 2 mục acknowledgement Chọn Create stack Quá trình triển khai CloudFormation cần khoảng 15 phút để hoàn thành.\n2 VPCs đã được tạo 3 EC2s đã được tạo "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.3-s3-vpc/5.3.2-test-gwe/","title":"Kiểm tra Gateway Endpoint","tags":[],"description":"","content":"Tạo S3 bucket Đi đến S3 management console Trong Bucket console, chọn Create bucket Trong Create bucket console Đặt tên bucket: chọn 1 tên mà không bị trùng trong phạm vi toàn cầu (gợi ý: lab\u0026lt;số-lab\u0026gt;\u0026lt;tên-bạn\u0026gt;) Giữ nguyên giá trị của các fields khác (default) Kéo chuột xuống và chọn Create bucket Tạo thành công S3 bucket Kết nối với EC2 bằng session manager Trong workshop này, bạn sẽ dùng AWS Session Manager để kết nối đến các EC2 instances. Session Manager là 1 tính năng trong dịch vụ Systems Manager được quản lý hoàn toàn bởi AWS. System manager cho phép bạn quản lý Amazon EC2 instances và các máy ảo on-premises (VMs)thông qua 1 browser-based shell. Session Manager cung cấp khả năng quản lý phiên bản an toàn và có thể kiểm tra mà không cần mở cổng vào, duy trì máy chủ bastion host hoặc quản lý khóa SSH.\nFirst cloud journey Lab để hiểu sâu hơn về Session manager.\nTrong AWS Management Console, gõ Systems Manager trong ô tìm kiếm và nhấn Enter: Từ Systems Manager menu, tìm Node Management ở thanh bên trái và chọn Session Manager: Click Start Session, và chọn EC2 instance tên Test-Gateway-Endpoint. Phiên bản EC2 này đã chạy trong \u0026ldquo;VPC cloud\u0026rdquo; và sẽ được dùng để kiểm tra khả năng kết nối với Amazon S3 thông qua điểm cuối Cổng mà bạn vừa tạo (s3-gwe).\nSession Manager sẽ mở browser tab mới với shell prompt: sh-4.2 $\nBạn đã bắt đầu phiên kết nối đến EC2 trong VPC Cloud thành công. Trong bước tiếp theo, chúng ta sẽ tạo một S3 bucket và một tệp trong đó.\nCreate a file and upload to s3 bucket Đổi về ssm-user\u0026rsquo;s thư mục bằng lệnh \u0026ldquo;cd ~\u0026rdquo; Tạo 1 file để kiểm tra bằng lệnh \u0026ldquo;fallocate -l 1G testfile.xyz\u0026rdquo;, 1 file tên \u0026ldquo;testfile.xyz\u0026rdquo; có kích thước 1GB sẽ được tạo. Tải file mình vừa tạo lên S3 với lệnh \u0026ldquo;aws s3 cp testfile.xyz s3://your-bucket-name\u0026rdquo;. Thay your-bucket-name bằng tên S3 bạn đã tạo. Bạn đã tải thành công tệp lên bộ chứa S3 của mình. Bây giờ bạn có thể kết thúc session.\nKiểm tra object trong S3 bucket Đi đến S3 console. Click tên s3 bucket của bạn Trong Bucket console, bạn sẽ thấy tệp bạn đã tải lên S3 bucket của mình Tóm tắt Chúc mừng bạn đã hoàn thành truy cập S3 từ VPC. Trong phần này, bạn đã tạo gateway endpoint cho Amazon S3 và sử dụng AWS CLI để tải file lên. Quá trình tải lên hoạt động vì gateway endpoint cho phép giao tiếp với S3 mà không cần Internet gateway gắn vào \u0026ldquo;VPC Cloud\u0026rdquo;. Điều này thể hiện chức năng của gateway endpoint như một đường dẫn an toàn đến S3 mà không cần đi qua pub lic Internet.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS và các dịch vụ cơ bản trong AWS\nTuần 2: Làm quen AWS VPC, bảo mật mạng, và các dịch vụ kết nối mạng nâng cao.\nTuần 3: Thành thạo EC2, các instance, công cụ quản lý, EBS và Auto Scaling để vận hành tài nguyên máy ảo trên AWS.\nTuần 4: Thành thạo các dịch vụ lưu trữ AWS, bao gồm triển khai Backup, Import/Export máy ảo và sử dụng Storage Gateway.\nTuần 5: Nắm vững dịch vụ bảo mật AWS (Security Hub, IAM), tối ưu tài nguyên bằng Tag, và chọn/thiết lập kiến trúc đề tài dự án.\nTuần 6: Thiết lập kiến trúc Monorepo, xây dựng hạ tầng bằng AWS SAM (IaC), hoàn thiện Backend MVP cho chức năng CREATE phòng, thiết kế mockup và thiết lập CI/CD cơ bản.\nTuần 7: Triển khai hạ tầng AWS (Lambda, API Gateway, DynamoDB), xây dựng Frontend MVP (Base UI/Form), tích hợp API và viết chức năng tìm kiếm phòng.\nTuần 8: Tích hợp bản đồ/geocoding, hoàn thiện chức năng tìm kiếm/lọc, và tiến hành kiểm thử toàn bộ chức năng chính.\nTuần 9: Làm công việc I\u0026hellip;\nTuần 10: Làm công việc L\u0026hellip;\nTuần 11: Làm công việc M\u0026hellip;\nTuần 12: Làm công việc N\u0026hellip;\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.4-s3-onprem/5.4.2-create-interface-enpoint/","title":"Tạo một S3 Interface endpoint","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo và kiểm tra Interface Endpoint S3 bằng cách sử dụng môi trường truyền thống mô phỏng.\nQuay lại Amazon VPC menu. Trong thanh điều hướng bên trái, chọn Endpoints, sau đó click Create Endpoint.\nTrong Create endpoint console:\nĐặt tên interface endpoint Trong Service category, chọn aws services Trong Search box, gõ S3 và nhấn Enter. Chọn endpoint có tên com.amazonaws.us-east-1.s3. Đảm bảo rằng cột Type có giá trị Interface. Đối với VPC, chọn VPC Cloud từ drop-down. Đảm bảo rằng bạn chọn \u0026ldquo;VPC Cloud\u0026rdquo; và không phải \u0026ldquo;VPC On-prem\u0026rdquo;\nMở rộng Additional settings và đảm bảo rằng Enable DNS name không được chọn (sẽ sử dụng điều này trong phần tiếp theo của workshop) Chọn 2 subnets trong AZs sau: us-east-1a and us-east-1b Đối với Security group, chọn SGforS3Endpoint: Giữ default policy - full access và click Create endpoint Chúc mừng bạn đã tạo thành công S3 interface endpoint. Ở bước tiếp theo, chúng ta sẽ kiểm tra interface endpoint.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Sao lưu tài nguyên Amazon Elastic Kubernetes Service (EKS) bằng NetApp Trident Protect Bài blog này giới thiệu công cụ NetApp Trident Protect, một giải pháp miễn phí được thiết kế để bảo vệ dữ liệu, khôi phục sau thảm họa và di chuyển các khối lượng công việc container hóa trong môi trường Amazon EKS. Bài viết giải thích lý do tại sao các cụm EKS cần cơ chế sao lưu mạnh mẽ để chống lại lỗi do con người, lỗi hệ thống và lỗi khu vực (region failures), vốn là những rủi ro Kubernetes không tự bảo vệ được, bao gồm việc sao lưu các thành phần quan trọng như namespaces, Persistent Volumes và tài nguyên cấu hình. Trident Protect cho phép người dùng thực hiện sao lưu theo yêu cầu hoặc theo lịch trình các tài nguyên Kubernetes tới các bộ lưu trữ bên ngoài như Amazon S3, tận dụng API nguyên bản của Kubernetes và tridentctl-protect CLI. Cuối cùng, bài viết cung cấp hướng dẫn từng bước để triển khai môi trường mẫu bằng Terraform, tích hợp Trident Protect với Amazon FSx for NetApp ONTAP để thực hiện các tác vụ bảo vệ và di chuyển dữ liệu thực tế.\nBlog 2 - Vòng đời phát triển dựa trên AI: Tái định hình ngành kỹ thuật phần mềm Bài blog này giới thiệu AI-Driven Development Life Cycle (AI-DLC), một phương pháp luận mới do AWS đề xuất nhằm định hình lại kỹ thuật phần mềm bằng cách đặt Trí tuệ Nhân tạo (AI) làm trung tâm của toàn bộ vòng đời phát triển. AI-DLC được thiết kế để giải quyết những hạn chế của các cách tiếp cận hiện tại (AI-assisted và AI-autonomous) bằng cách kết hợp Thực thi bằng AI với sự Giám sát của Con người và Hợp tác Nhóm Động. Theo đó, AI tạo ra các kế hoạch công việc chi tiết, tìm kiếm sự làm rõ và thực hiện giải pháp chỉ sau khi nhận được sự xác thực từ con người. Quá trình phát triển được chia thành ba giai đoạn: Inception (AI chuyển đổi ý định kinh doanh thành yêu cầu), Construction (AI đề xuất kiến trúc, mô hình, code và test), và Operations (AI quản lý Infrastructure as Code và triển khai). AI-DLC cũng thay thế các \u0026ldquo;sprints\u0026rdquo; truyền thống bằng \u0026ldquo;bolts\u0026rdquo;—các chu kỳ làm việc ngắn hơn, cường độ cao hơn, được đo bằng giờ hoặc ngày. Lợi ích cốt lõi của phương pháp này là tăng tốc độ phát triển (Velocity), thúc đẩy Đổi mới (Innovation), nâng cao Chất lượng (Quality) và Cải thiện Trải nghiệm Nhà phát triển (Developer Experience), giúp các nhóm tập trung vào giải quyết vấn đề thay vì các tác vụ lặp đi lặp lại.\nBlog 3 - Khắc phục sự rối loạn trong phát triển với các tác nhân tùy chỉnh của Amazon Q Developer CLI Bài blog giới thiệu Custom Agents (Tác nhân tùy chỉnh) mới trong Amazon Q Developer CLI, một tính năng được thiết kế để giúp các nhà phát triển quản lý hiệu quả sự phức tạp và lộn xộn của các môi trường phát triển đa dạng, đặc biệt là trong các ứng dụng đa tầng (multi-tier). Vấn đề cốt lõi là các trợ lý AI truyền thống thường phải đoán bối cảnh khi sử dụng nhiều công cụ (ví dụ: nhầm lẫn \u0026ldquo;table\u0026rdquo; trong Figma với \u0026ldquo;table\u0026rdquo; trong PostgreSQL). Custom Agents cho phép nhà phát triển tạo ra các tác nhân chuyên biệt, được tối ưu hóa cấu hình với các công cụ, bối cảnh (context) và quyền truy cập (permissions) cụ thể cho từng nhiệm vụ (ví dụ: một Agent riêng cho Front-end và một Agent cho Back-end). Bằng cách dễ dàng chuyển đổi giữa các Agent bằng lệnh q chat \u0026ndash;agent [name], tính năng này giảm thiểu gánh nặng nhận thức (cognitive overhead), đảm bảo Amazon Q Developer cung cấp các câu trả lời chính xác và phù hợp hơn, từ đó tăng hiệu suất và chất lượng công việc.\nBlog 4 - Cách Zapier chạy các tác vụ riêng biệt trên AWS Lambda và nâng cấp các chức năng ở quy mô lớn Bài blog mô tả cách Zapier vận hành hàng trăm nghìn hàm AWS Lambda riêng biệt để xử lý các Zap do người dùng tạo, đảm bảo tính cô lập giữa các tenant, khả năng mở rộng cao và chi phí vận hành thấp. Dựa trên cơ chế microVM Firecracker của Lambda và mặt phẳng điều khiển xây dựng trên Amazon EKS, Zapier tự động tạo và quản lý hàm cho từng Zap. Thách thức lớn được đề cập là việc nâng cấp phiên bản runtime của Lambda ở quy mô rất lớn khi các runtime cũ bị ngừng hỗ trợ, đòi hỏi tuân thủ bảo mật nghiêm ngặt mà không được gây ảnh hưởng đến người dùng. Zapier giải quyết vấn đề bằng ba bước: dọn dẹp các hàm không sử dụng thông qua CloudWatch và Trusted Advisor, ưu tiên nâng cấp các hàm quan trọng và có lưu lượng cao, và trang bị công cụ cho đội kỹ thuật bằng mô-đun Terraform cùng hệ thống canary runtime tự phát triển. Công cụ này tự động chuyển đổi lưu lượng, giám sát lỗi và khôi phục khi cần, giúp giảm 95% số hàm sử dụng runtime sắp lỗi thời, đồng thời duy trì nền tảng serverless an toàn, ổn định và luôn được cập nhật.\nBlog 5 - Cách HashiCorp thực hiện chuyển đổi liên vùng liền mạch với Amazon Application Recovery Controller Bài blog trình bày cách HashiCorp cải tiến toàn diện quy trình phục hồi sau thảm họa bằng cách sử dụng Amazon Application Recovery Controller (ARC) để thực hiện chuyển đổi liên vùng nhanh và đáng tin cậy cho nền tảng đám mây của mình. Thay vì quy trình thủ công phức tạp và dễ sai sót, đội SRE của HashiCorp xây dựng một dịch vụ điều phối tập trung, tích hợp với ARC và hệ thống DNS Route 53 để tự động hoá chuyển hướng lưu lượng giữa các vùng. Nhờ kiến trúc mới, tín hiệu trạng thái vùng được truyền tải nhất quán, việc chuyển đổi dự phòng chỉ mất vài phút và quá trình kiểm thử DR được thực hiện thường xuyên. ARC giúp HashiCorp giảm rủi ro vận hành, cải thiện đáng kể thời gian phục hồi và nâng cao độ tin cậy cấp doanh nghiệp cho HCP.\nBlog 6 - Triển khai ưu tiên tin nhắn với hàng đợi số lượng trên Amazon MQ cho RabbitMQ Bài blog hướng dẫn cách triển khai ưu tiên tin nhắn khi chuyển ứng dụng từ hàng đợi cổ điển của RabbitMQ (có hỗ trợ ưu tiên sẵn) sang hàng đợi quorum trên Amazon MQ, vốn không hỗ trợ ưu tiên gốc. Bài viết nêu lý do ưu tiên tin nhắn quan trọng trong các hệ thống thời gian thực và đề xuất hai cách tiếp cận chính: tạo nhiều hàng đợi quorum theo từng mức ưu tiên hoặc áp dụng logic xử lý tùy chỉnh ở phía consumer dựa trên metadata. Các phương pháp này giúp duy trì khả năng sẵn sàng, tính nhất quán và đảm bảo tin nhắn quan trọng được xử lý trước trong môi trường quorum.\nBlog 7 - Tối ưu hóa quy trình làm việc Serverless trên AWS: Từ AWS Lambda orchestration đến AWS Step Functions Blog này thảo luận về AWS Lambda như một mô hình phản điều phối và cách thiết kế lại các giải pháp không máy chủ bằng AWS Step Functions với tích hợp gốc. Step Functions là một dịch vụ quy trình làm việc không máy chủ mà bạn có thể sử dụng để xây dựng các ứng dụng phân tán, tự động hóa quy trình, điều phối các dịch vụ vi mô và tạo các luồng dữ liệu và học máy (ML). Step Functions cung cấp tích hợp gốc với hơn 200 dịch vụ AWS bên cạnh các API bên thứ ba bên ngoài. Bạn có thể sử dụng các tích hợp này để triển khai các giải pháp sẵn sàng cho sản xuất với ít công sức hơn, giảm độ phức tạp của mã, cải thiện khả năng bảo trì dài hạn và giảm thiểu nợ kỹ thuật khi vận hành ở quy mô lớn.\nBlog 8 - Tối đa hóa giá trị doanh nghiệp thông qua tối ưu hóa đám mây chiến lược Blog này giới thiệu khi việc áp dụng cloud tiếp tục tăng tốc, các tổ chức nhận ra rằng hành trình lên cloud chỉ mới là bước khởi đầu. Thách thức – và cũng là cơ hội thực sự – nằm ở việc tối ưu hóa việc sử dụng cloud để mang lại giá trị kinh doanh tối đa. Tại AWS, chúng tôi cam kết giúp khách hàng điều hướng hành trình này một cách thành công. Hãy cùng khám phá một số insight và best practices quan trọng cho cloud optimization được chia sẻ trong ấn phẩm mới của MIT Technology Review, Driving business value by optimizing the cloud.\nBlog 9 - Giới thiệu phiên bản v2 của Powertool for AWS Lambda (Java) Blog này giới thiệu phiên bản mới của Powertools for AWS Lambda (Java) với hỗ trợ GraalVM native image. Bạn sẽ tìm hiểu vì sao GraalVM giúp giảm cold start lên đến 75%, cách modular design giúp giảm memory usage, và lợi ích của các core utilities như logging, metrics và tracing. Bài viết cũng hướng dẫn các bước migration từ phiên bản 1, cấu hình native compilation, và đảm bảo tương thích với các tiêu chuẩn serverless development.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.4-s3-onprem/5.4.3-test-endpoint/","title":"Kiểm tra Interface Endpoint","tags":[],"description":"","content":"Lấy regional DNS name (tên DNS khu vực) của S3 interface endpoint Trong Amazon VPC menu, chọn Endpoints.\nClick tên của endpoint chúng ta mới tạo ở mục 4.2: s3-interface-endpoint. Click details và lưu lại regional DNS name của endpoint (cái đầu tiên) vào text-editor của bạn để dùng ở các bước sau.\nKết nối đến EC2 instance ở trong \u0026ldquo;VPC On-prem\u0026rdquo; (giả lập môi trường truyền thống) Đi đến Session manager bằng cách gõ \u0026ldquo;session manager\u0026rdquo; vào ô tìm kiếm\nClick Start Session, chọn EC2 instance có tên Test-Interface-Endpoint. EC2 instance này đang chạy trên \u0026ldquo;VPC On-prem\u0026rdquo; và sẽ được sử dụng để kiểm tra kết nối đến Amazon S3 thông qua Interface endpoint. Session Manager sẽ mở 1 browser tab mới với shell prompt: sh-4.2 $\nĐi đến ssm-user\u0026rsquo;s home directory với lệnh \u0026ldquo;cd ~\u0026rdquo;\nTạo 1 file tên testfile2.xyz\nfallocate -l 1G testfile2.xyz Copy file vào S3 bucket mình tạo ở section 4.2 aws s3 cp --endpoint-url https://bucket.\u0026lt;Regional-DNS-Name\u0026gt; testfile2.xyz s3://\u0026lt;your-bucket-name\u0026gt; Câu lệnh này yêu cầu thông số \u0026ndash;endpoint-url, bởi vì bạn cần sử dụng DNS name chỉ định cho endpoint để truy cập vào S3 thông qua Interface endpoint. Không lấy \u0026rsquo; * \u0026rsquo; khi copy/paste tên DNS khu vực. Cung cấp tên S3 bucket của bạn Bây giờ tệp đã được thêm vào bộ chứa S3 của bạn. Hãy kiểm tra bộ chứa S3 của bạn trong bước tiếp theo.\nKiểm tra Object trong S3 bucket Đi đến S3 console Click Buckets Click tên bucket của bạn và bạn sẽ thấy testfile2.xyz đã được thêm vào s3 bucket của bạn "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.3-s3-vpc/","title":"Truy cập S3 từ VPC","tags":[],"description":"","content":"Sử dụng Gateway endpoint Trong phần này, bạn sẽ tạo một Gateway endpoint để truy cập Amazon S3 từ một EC2 instance. Gateway endpoint sẽ cho phép tải một object lên S3 bucket mà không cần sử dụng Internet Công cộng. Để tạo endpoint, bạn phải chỉ định VPC mà bạn muốn tạo endpoint và dịch vụ (trong trường hợp này là S3) mà bạn muốn thiết lập kết nối.\nNội dung Tạo gateway endpoint Test gateway endpoint "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":""},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.4-s3-onprem/5.4.4-dns-simulation/","title":"Mô phỏng On-premises DNS ","tags":[],"description":"","content":"AWS PrivateLink endpoint có một địa chỉ IP cố định trong từng AZ nơi chúng được triển khai, trong suốt thời gian tồn tại của endpoint (cho đến khi endpoint bị xóa). Các địa chỉ IP này được gắn vào Elastic network interface (ENI). AWS khuyến nghị sử dụng DNS để resolve địa chỉ IP cho endpoint để các ứng dụng downstream sử dụng địa chỉ IP mới nhất khi ENIs được thêm vào AZ mới hoặc bị xóa theo thời gian.\nTrong phần này, bạn sẽ tạo một quy tắc chuyển tiếp (forwarding rule) để gửi các yêu cầu resolve DNS từ môi trường truyền thống (mô phỏng) đến Private Hosted Zone trên Route 53. Phần này tận dụng cơ sở hạ tầng do CloudFormation triển khai trong phần Chuẩn bị môi trường.\nTạo DNS Alias Records cho Interface endpoint Click link để đi đến Route 53 management console (Hosted Zones section). Mẫu CloudFormation mà bạn triển khai trong phần Chuẩn bị môi trường đã tạo Private Hosted Zone này. Nhấp vào tên của Private Hosted Zone, s3.us-east-1.amazonaws.com: Tạo 1 record mới trong Private Hosted Zone: Giữ nguyên Record name và record type Alias Button: click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Add another record, và add 1 cái record thứ 2 sử dụng những thông số sau: Record name: *. Record type: giữ giá trị default (type A) Alias Button: Click để enable Route traffic to: Alias to VPC Endpoint Region: US East (N. Virginia) [us-east-1] Chọn endpoint: Paste tên (Regional VPC Endpoint DNS) bạn đã lưu lại ở phần 4.3 Click Create records Record mới xuất hiện trên giao diện Route 53.\nTạo một Resolver Forwarding Rule Route 53 Resolver Forwarding Rules cho phép bạn chuyển tiếp các DNS queries từ VPC của bạn đến các nguồn khác để resolve name. Bên ngoài môi trường workshop, bạn có thể sử dụng tính năng này để chuyển tiếp các DNS queries từ VPC của bạn đến các máy chủ DNS chạy trên on-premises. Trong phần này, bạn sẽ mô phỏng một on-premises conditional forwarder bằng cách tạo một forwarding rule để chuyển tiếp các DNS queries for Amazon S3 đến một Private Hosted Zone chạy trong \u0026ldquo;VPC Cloud\u0026rdquo; để resolve PrivateLink interface endpoint regional DNS name.\nTừ giao diện Route 53, chọn Inbound endpoints trên thanh bên trái\nTrong giao diện Inbound endpoint, Chọn ID của Inbound endpoint.\nSao chép 2 địa chỉ IP trong danh sách vào trình chỉnh sửa. Từ giao diện Route 53, chọn Resolver \u0026gt; Rules và chọn Create rule Trong giao diện Create rule Name: myS3Rule Rule type: Forward Domain name: s3.us-east-1.amazonaws.com VPC: VPC On-prem Outbound endpoint: VPCOnpremOutboundEndpoint Target IP Addresses: điền cả hai IP bạn đã lưu trữ trên trình soạn thảo (inbound endpoint addresses) và sau đó chọn Submit Bạn đã tạo thành công resolver forwarding rule.\nKiểm tra on-premises DNS mô phỏng. Kết nối đến Test-Interface-Endpoint EC2 instance với Session Manager Kiểm tra DNS resolution. Lệnh dig sẽ trả về địa chỉ IP được gán cho VPC endpoint interface đang chạy trên VPC (địa chỉ IP của bạn sẽ khác): dig +short s3.us-east-1.amazonaws.com Các địa chỉ IP được trả về là các địa chỉ IP VPC enpoint, KHÔNG phải là các địa chỉ IP Resolver mà bạn đã dán từ trình chỉnh sửa văn bản của mình. Các địa chỉ IP của Resolver endpoint và VPC endpoin trông giống nhau vì chúng đều từ khối CIDR VPC Cloud.\nTruy cập vào menu VPC (phần Endpoints), chọn S3 interface endpoint. Nhấp vào tab Subnets và xác nhận rằng các địa chỉ IP được trả về bởi lệnh Dig khớp với VPC endpoint: Hãy quay lại shell của bạn và sử dụng AWS CLI để kiểm tra danh sách các bucket S3 của bạn: aws s3 ls --endpoint-url https://s3.us-east-1.amazonaws.com Kết thúc phiên làm việc của Session Manager của bạn: Trong phần này, bạn đã tạo một Interface Endpoint cho Amazon S3. Điểm cuối này có thể được truy cập từ on-premises thông qua Site-to-Site VPN hoặc AWS Direct Connect. Các điểm cuối Route 53 Resolver outbound giả lập chuyển tiếp các yêu cầu DNS từ on-premises đến một Private Hosted Zone đang chạy trên đám mây. Các điểm cuối Route 53 inbound nhận yêu cầu giải quyết và trả về một phản hồi chứa địa chỉ IP của Interface Endpoint VPC. Sử dụng DNS để giải quyết các địa chỉ IP của điểm cuối cung cấp tính sẵn sàng cao trong trường hợp một Availability Zone gặp sự cố.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.4-s3-onprem/","title":"Truy cập S3 từ môi trường truyền thống","tags":[],"description":"","content":"Tổng quan Trong phần này, bạn sẽ tạo một Interface Endpoint để truy cập Amazon S3 từ môi trường truyền thống mô phỏng. Interface Endpoint sẽ cho phép bạn định tuyến đến Amazon S3 qua kết nối VPN từ môi trường truyền thống mô phỏng của bạn.\nTại sao nên sử dụng Interface Endpoint:\nCác Gateway endpoints chỉ hoạt động với các tài nguyên đang chạy trong VPC nơi chúng được tạo. Interface Endpoint hoạt động với tài nguyên chạy trong VPC và cả tài nguyên chạy trong môi trường truyền thống. Khả năng kết nối từ môi trường truyền thống của bạn với aws cloud có thể được cung cấp bởi AWS Site-to-Site VPN hoặc AWS Direct Connect. Interface Endpoint cho phép bạn kết nối với các dịch vụ do AWS PrivateLink cung cấp. Các dịch vụ này bao gồm một số dịch vụ AWS, dịch vụ do các đối tác và khách hàng AWS lưu trữ trong VPC của riêng họ (gọi tắt là Dịch vụ PrivateLink endpoints) và các dịch vụ Đối tác AWS Marketplace. Đối với workshop này, chúng ta sẽ tập trung vào việc kết nối với Amazon S3. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.5-policy/","title":"VPC Endpoint Policies","tags":[],"description":"","content":"Khi bạn tạo một Interface Endpoint hoặc cổng, bạn có thể đính kèm một chính sách điểm cuối để kiểm soát quyền truy cập vào dịch vụ mà bạn đang kết nối. Chính sách VPC Endpoint là chính sách tài nguyên IAM mà bạn đính kèm vào điểm cuối. Nếu bạn không đính kèm chính sách khi tạo điểm cuối, thì AWS sẽ đính kèm chính sách mặc định cho bạn để cho phép toàn quyền truy cập vào dịch vụ thông qua điểm cuối.\nBạn có thể tạo chính sách chỉ hạn chế quyền truy cập vào các S3 bucket cụ thể. Điều này hữu ích nếu bạn chỉ muốn một số Bộ chứa S3 nhất định có thể truy cập được thông qua điểm cuối.\nTrong phần này, bạn sẽ tạo chính sách VPC Endpoint hạn chế quyền truy cập vào S3 bucket được chỉ định trong chính sách VPC Endpoint.\nKết nối tới EC2 và xác minh kết nối tới S3. Bắt đầu một phiên AWS Session Manager mới trên máy chủ có tên là Test-Gateway-Endpoint. Từ phiên này, xác minh rằng bạn có thể liệt kê nội dung của bucket mà bạn đã tạo trong Phần 1: Truy cập S3 từ VPC. aws s3 ls s3://\u0026lt;your-bucket-name\u0026gt; Nội dung của bucket bao gồm hai tệp có dung lượng 1GB đã được tải lên trước đó.\nTạo một bucket S3 mới; tuân thủ mẫu đặt tên mà bạn đã sử dụng trong Phần 1, nhưng thêm \u0026lsquo;-2\u0026rsquo; vào tên. Để các trường khác là mặc định và nhấp vào Create. Tạo bucket thành công. Policy mặc định cho phép truy cập vào tất cả các S3 Buckets thông qua VPC endpoint.\nTrong giao diện Edit Policy, sao chép và dán theo policy sau, thay thế yourbucketname-2 với tên bucket thứ hai của bạn. Policy này sẽ cho phép truy cập đến bucket mới thông qua VPC endpoint, nhưng không cho phép truy cập đến các bucket còn lại. Chọn Save để kích hoạt policy. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1631305502445\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1631305501021\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::yourbucketname-2\u0026#34;, \u0026#34;arn:aws:s3:::yourbucketname-2/*\u0026#34; ], \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } Cấu hình policy thành công.\nTừ session của bạn trên Test-Gateway-Endpoint instance, kiểm tra truy cập đến S3 bucket bạn tạo ở bước đầu aws s3 ls s3://\u0026lt;yourbucketname\u0026gt; Câu lệnh trả về lỗi bởi vì truy cập vào S3 bucket không có quyền trong VPC endpoint policy.\nTrở lại home directory của bạn trên EC2 instance cd~ Tạo file fallocate -l 1G test-bucket2.xyz Sao chép file lên bucket thứ 2 aws s3 cp test-bucket2.xyz s3://\u0026lt;your-2nd-bucket-name\u0026gt; Thao tác này được cho phép bởi VPC endpoint policy.\nSau đó chúng ta kiểm tra truy cập vào S3 bucket đầu tiên\naws s3 cp test-bucket2.xyz s3://\u0026lt;your-1st-bucket-name\u0026gt;\nCâu lệnh xảy ra lỗi bởi vì bucket không có quyền truy cập bởi VPC endpoint policy.\nTrong phần này, bạn đã tạo chính sách VPC Endpoint cho Amazon S3 và sử dụng AWS CLI để kiểm tra chính sách. Các hoạt động AWS CLI liên quan đến bucket S3 ban đầu của bạn thất bại vì bạn áp dụng một chính sách chỉ cho phép truy cập đến bucket thứ hai mà bạn đã tạo. Các hoạt động AWS CLI nhắm vào bucket thứ hai của bạn thành công vì chính sách cho phép chúng. Những chính sách này có thể hữu ích trong các tình huống khi bạn cần kiểm soát quyền truy cập vào tài nguyên thông qua VPC Endpoint.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Đảm bảo truy cập Hybrid an toàn đến S3 bằng cách sử dụng VPC endpoint Tổng quan AWS PrivateLink cung cấp kết nối riêng tư đến các dịch vụ aws từ VPCs hoặc trung tâm dữ liệu (on-premise) mà không làm lộ lưu lượng truy cập ra ngoài public internet.\nTrong bài lab này, chúng ta sẽ học cách tạo, cấu hình, và kiểm tra VPC endpoints để cho phép workload của bạn tiếp cận các dịch vụ AWS mà không cần đi qua Internet công cộng.\nChúng ta sẽ tạo hai loại endpoints để truy cập đến Amazon S3: gateway vpc endpoint và interface vpc endpoint. Hai loại vpc endpoints này mang đến nhiều lợi ích tùy thuộc vào việc bạn truy cập đến S3 từ môi trường cloud hay từ trung tâm dữ liệu (on-premise).\nGateway - Tạo gateway endpoint để gửi lưu lượng đến Amazon S3 hoặc DynamoDB using private IP addresses. Bạn điều hướng lưu lượng từ VPC của bạn đến gateway endpoint bằng các bảng định tuyến (route tables) Interface - Tạo interface endpoint để gửi lưu lượng đến các dịch vụ điểm cuối (endpoints) sử dụng Network Load Balancer để phân phối lưu lượng. Lưu lượng dành cho dịch vụ điểm cuối được resolved bằng DNS. Nội dung Tổng quan về workshop Chuẩn bị Truy cập đến S3 từ VPC Truy cập đến S3 từ TTDL On-premises VPC Endpoint Policies (làm thêm) Dọn dẹp tài nguyên "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/5-workshop/5.6-cleanup/","title":"Dọn dẹp tài nguyên","tags":[],"description":"","content":"Dọn dẹp tài nguyên Xin chúc mừng bạn đã hoàn thành xong lab này! Trong lab này, bạn đã học về các mô hình kiến trúc để truy cập Amazon S3 mà không sử dụng Public Internet.\nBằng cách tạo Gateway endpoint, bạn đã cho phép giao tiếp trực tiếp giữa các tài nguyên EC2 và Amazon S3, mà không đi qua Internet Gateway. Bằng cách tạo Interface endpoint, bạn đã mở rộng kết nối S3 đến các tài nguyên chạy trên trung tâm dữ liệu trên chỗ của bạn thông qua AWS Site-to-Site VPN hoặc Direct Connect. Dọn dẹp Điều hướng đến Hosted Zones trên phía trái của bảng điều khiển Route 53. Nhấp vào tên của s3.us-east-1.amazonaws.com zone. Nhấp vào Delete và xác nhận việc xóa bằng cách nhập từ khóa \u0026ldquo;delete\u0026rdquo;. Disassociate Route 53 Resolver Rule - myS3Rule from \u0026ldquo;VPC Onprem\u0026rdquo; and Delete it. 4.Mở console của CloudFormation và xóa hai stack CloudFormation mà bạn đã tạo cho bài thực hành này:\nPLOnpremSetup PLCloudSetup Xóa các S3 bucket Mở bảng điều khiển S3 Chọn bucket chúng ta đã tạo cho lab, nhấp chuột và xác nhận là empty. Nhấp Delete và xác nhận delete. "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Công ty TNHH Amazon Web Services Vietnam từ ngày 29/9/2025 đến ngày 22/11/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia làm frontend, test backend, qua đó cải thiện kỹ năng lập trình, phân tích dữ liệu, viết báo cáo, giao tiếp với mọi người.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ✅ ☐ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ☐ ✅ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ☐ ✅ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Nâng cao tính kỹ luật, chấp hành nghiêm chỉnh nội quy của công ty hoặc bất kỳ trong một tổ chức nào Cải thiện trong cách tư duy giải quyết vấn đề Học cách giao tiếp tốt hơn trong giao tiếp hằng ngày và trong công việc, xử lý tình huống "},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nTrong suốt thời gian thực tập, tôi cảm nhận rõ ràng một môi trường làm việc thân thiện, cởi mở và tích cực. Các anh chị trong FCJ luôn sẵn sàng hỗ trợ khi tôi gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái giúp tôi tập trung tốt hơn mỗi ngày. Nếu được cải thiện thêm, tôi mong công ty có thể tổ chức nhiều hoạt động team bonding hơn để mọi người gắn kết với nhau nhiều hơn nữa.\n2. Sự hỗ trợ của mentor / team admin\nVề mentor và team admin, tôi thực sự rất biết ơn vì sự tận tâm và nhiệt tình. Mentor hướng dẫn rất dễ hiểu, kiên nhẫn giải thích khi tôi còn lúng túng và luôn khuyến khích tôi chủ động đặt câu hỏi. Điều tôi trân trọng nhất là mentor không “làm thay”, mà tạo cơ hội để tôi tự suy nghĩ và giải quyết vấn đề. Team admin cũng hỗ trợ rất tốt về tài liệu, thủ tục và tạo điều kiện thuận lợi để tôi yên tâm học tập, làm việc.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nCông việc được giao hỗ trợ rất nhiều với chuyên ngành tôi đang theo học, giúp tôi củng cố lại kiến thức nền tảng đã học ở trường, đồng thời mở ra nhiều mảng kiến thức mới mà trước đây tôi chưa từng tiếp cận. Nhờ vậy, tôi không chỉ học tốt hơn về mặt lý thuyết mà còn hiểu rõ hơn cách kiến thức được áp dụng trong thực tế.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, tôi có cơ hội học hỏi và phát triển nhiều kỹ năng quan trọng như làm việc nhóm, sử dụng công cụ quản lý dự án, giao tiếp trong môi trường công việc chuyên nghiệp. Ngoài ra, những chia sẻ thực tế từ mentor cũng giúp tôi có cái nhìn rõ ràng hơn về con đường nghề nghiệp trong tương lai.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa và tinh thần đồng đội là một điểm sáng lớn. Mọi người luôn tôn trọng lẫn nhau, làm việc nghiêm túc nhưng không hề căng thẳng hay áp lực. Khi có công việc gấp, tất cả đều sẵn sàng hỗ trợ nhau không phân biệt vị trí. Nhờ vậy, dù là thực tập sinh, tôi vẫn luôn cảm thấy tôi là một phần của tập thể.\n6. Chính sách / phúc lợi cho thực tập sinh\nVề chính sách dành cho thực tập sinh, công ty có hỗ trợ phụ cấp và linh hoạt về thời gian khi cần thiết. Đặc biệt, việc được tham gia các buổi đào tạo nội bộ giúp tôi học hỏi thêm rất nhiều kiến thức và kinh nghiệm thực tế.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong suốt thời gian thực tập là gì?\nĐiều gì khiến bạn cảm thấy chưa hài lòng trong quá trình thực tập?\nTheo bạn, công ty cần cải thiện điều gì để hỗ trợ thực tập sinh tốt hơn?\nBạn đánh giá như thế nào về môi trường làm việc tại công ty?\nBạn cảm nhận ra sao về sự hỗ trợ của mentor trong suốt quá trình thực tập?\nCông việc được giao có phù hợp với chuyên ngành bạn đang học không?\nNhững kỹ năng quan trọng nhất bạn học được trong kỳ thực tập là gì?\nBạn có gặp khó khăn nào trong quá trình làm việc không? Nếu có, đó là gì?\nBạn đánh giá thế nào về khối lượng công việc được giao?\nBạn có cảm thấy áp lực trong quá trình thực tập không? Vì sao?\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập tại đây không? Vì sao?\nĐiều gì khiến bạn sẵn sàng giới thiệu (hoặc không giới thiệu) công ty cho người khác?\nĐề xuất \u0026amp; mong muốn Mình mong trong tương lai công ty có thể tổ chức thêm các buổi chia sẻ kinh nghiệm nghề nghiệp, định hướng phát triển để thực tập sinh hiểu rõ hơn về con đường phía trước. Nếu có cơ hội, mình rất mong được tiếp tục đồng hành cùng chương trình này trong tương lai, không chỉ với vai trò thực tập sinh mà còn ở những vị trí lâu dài hơn.\n"},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://nguyenmaivy.github.io/nguyenmaivy/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]